{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:28:34.370580Z",
     "iopub.status.busy": "2024-12-05T09:28:34.369856Z",
     "iopub.status.idle": "2024-12-05T09:28:34.374986Z",
     "shell.execute_reply": "2024-12-05T09:28:34.374126Z",
     "shell.execute_reply.started": "2024-12-05T09:28:34.370534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:28:36.943957Z",
     "iopub.status.busy": "2024-12-05T09:28:36.943383Z",
     "iopub.status.idle": "2024-12-05T09:28:37.006713Z",
     "shell.execute_reply": "2024-12-05T09:28:37.005999Z",
     "shell.execute_reply.started": "2024-12-05T09:28:36.943922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s-worldv2.pt')  # You can use 'yolov8.pt' or another YOLO version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:30:16.030992Z",
     "iopub.status.busy": "2024-12-05T09:30:16.030672Z",
     "iopub.status.idle": "2024-12-05T09:30:53.303354Z",
     "shell.execute_reply": "2024-12-05T09:30:53.302646Z",
     "shell.execute_reply.started": "2024-12-05T09:30:16.030967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./NYC_500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Load amenities from certain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\osmnx\\features.py:690: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  gdf.loc[:, \"geometry\"] = gdf[\"geometry\"].make_valid()\n",
      "C:\\Users\\rudra\\AppData\\Local\\Temp\\ipykernel_12328\\2612556374.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n",
      "C:\\Users\\rudra\\AppData\\Local\\Temp\\ipykernel_12328\\2612556374.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            amenity   latitude  longitude\n",
      "element id                                               \n",
      "node    42538083              bench  40.673352 -73.970702\n",
      "        349323821         fast_food  40.762515 -73.976690\n",
      "        357588583   bicycle_parking  40.661771 -73.992858\n",
      "        357618584          post_box  40.682496 -73.962688\n",
      "        357618608          post_box  40.643833 -73.979460\n",
      "...                             ...        ...        ...\n",
      "way     1319909118            bench  40.720378 -74.010841\n",
      "        1319909119            bench  40.720343 -74.010985\n",
      "        1319909120            bench  40.720334 -74.010894\n",
      "        1319909121            bench  40.720327 -74.010823\n",
      "        1340286561        fast_food  40.707104 -73.954532\n",
      "\n",
      "[35912 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "\n",
    "# Define the bounding box or location\n",
    "place_name = \"New York City, USA\"  # Example area\n",
    "tags = {'amenity': ['post_box', 'bicycle_parking', 'bench', 'fast_food', 'waste_basket']}  # Fetch all amenities\n",
    "\n",
    "# Fetch amenities in the defined area\n",
    "gdf = ox.features_from_place(place_name, tags)\n",
    "\n",
    "# Extract latitude and longitude from the geometries\n",
    "gdf['latitude'] = gdf.geometry.centroid.y\n",
    "gdf['longitude'] = gdf.geometry.centroid.x\n",
    "\n",
    "# Filter for relevant columns\n",
    "amenities_lat_lon_df = gdf[['amenity', 'latitude', 'longitude']]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(amenities_lat_lon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m picture_coords \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Filter amenities within 30 meters radius\u001b[39;00m\n\u001b[0;32m     12\u001b[0m amenities_in_radius \u001b[38;5;241m=\u001b[39m amenities_lat_lon_df[\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mamenities_lat_lon_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create a list of amenities with their details\u001b[39;00m\n\u001b[0;32m     20\u001b[0m amenities_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     21\u001b[0m     {\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m: amenity_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, amenity_row \u001b[38;5;129;01min\u001b[39;00m amenities_in_radius\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[0;32m     27\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9554\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9556\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9558\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9563\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9564\u001b[0m )\n\u001b[1;32m-> 9565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 873\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    891\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    892\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    893\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m picture_coords \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Filter amenities within 30 meters radius\u001b[39;00m\n\u001b[0;32m     12\u001b[0m amenities_in_radius \u001b[38;5;241m=\u001b[39m amenities_lat_lon_df[\n\u001b[0;32m     13\u001b[0m     amenities_lat_lon_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmeters \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     15\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create a list of amenities with their details\u001b[39;00m\n\u001b[0;32m     20\u001b[0m amenities_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     21\u001b[0m     {\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m: amenity_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, amenity_row \u001b[38;5;129;01min\u001b[39;00m amenities_in_radius\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[0;32m     27\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:540\u001b[0m, in \u001b[0;36mgeodesic.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ellipsoid(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mellipsoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWGS-84\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    539\u001b[0m major, minor, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:276\u001b[0m, in \u001b[0;36mDistance.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m util\u001b[38;5;241m.\u001b[39mpairwise(args):\n\u001b[1;32m--> 276\u001b[0m         kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m units\u001b[38;5;241m.\u001b[39mkilometers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kilometers \u001b[38;5;241m=\u001b[39m kilometers\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:566\u001b[0m, in \u001b[0;36mgeodesic.measure\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod, Geodesic) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod \u001b[38;5;241m=\u001b[39m Geodesic(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 566\u001b[0m s12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDISTANCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s12\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:1030\u001b[0m, in \u001b[0;36mGeodesic.Inverse\u001b[1;34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lat1, lon1, lat2, lon2,\n\u001b[0;32m   1013\u001b[0m             outmask \u001b[38;5;241m=\u001b[39m GeodesicCapability\u001b[38;5;241m.\u001b[39mSTANDARD):\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Solve the inverse geodesic problem\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \n\u001b[0;32m   1016\u001b[0m \u001b[38;5;124;03m  :param lat1: latitude of the first point in degrees\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1030\u001b[0m   a12, s12, salp1,calp1, salp2,calp2, m12, M12, M21, S12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GenInverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m   outmask \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mOUT_MASK\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outmask \u001b[38;5;241m&\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mLONG_UNROLL:\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:876\u001b[0m, in \u001b[0;36mGeodesic._GenInverse\u001b[1;34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[0m\n\u001b[0;32m    870\u001b[0m salp1b \u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mtiny_; calp1b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m numit \u001b[38;5;241m<\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mmaxit2_:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# the WGS84 test set: mean = 1.47, sd = 1.25, max = 16\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# WGS84 and random input: mean = 2.85, sd = 0.60\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   (v, salp2, calp2, sig12, ssig1, csig1, ssig2, csig2,\n\u001b[1;32m--> 876\u001b[0m    eps, domg12, dv) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Lambda12\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m     \u001b[49m\u001b[43msbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m     \u001b[49m\u001b[43msalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxit1_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m     \u001b[49m\u001b[43mC1a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC2a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC3a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m   \u001b[38;5;66;03m# Reversed test to allow escape with NaNs\u001b[39;00m\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tripb \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(v) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tripn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mtol0_):\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:680\u001b[0m, in \u001b[0;36mGeodesic._Lambda12\u001b[1;34m(self, sbet1, cbet1, dn1, sbet2, cbet2, dn2, salp1, calp1, slam120, clam120, diffp, C1a, C2a, C3a)\u001b[0m\n\u001b[0;32m    678\u001b[0m k2 \u001b[38;5;241m=\u001b[39m Math\u001b[38;5;241m.\u001b[39msq(calp0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ep2\n\u001b[0;32m    679\u001b[0m eps \u001b[38;5;241m=\u001b[39m k2 \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m k2)) \u001b[38;5;241m+\u001b[39m k2)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C3f\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC3a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m B312 \u001b[38;5;241m=\u001b[39m (Geodesic\u001b[38;5;241m.\u001b[39m_SinCosSeries(\u001b[38;5;28;01mTrue\u001b[39;00m, ssig2, csig2, C3a) \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m    682\u001b[0m         Geodesic\u001b[38;5;241m.\u001b[39m_SinCosSeries(\u001b[38;5;28;01mTrue\u001b[39;00m, ssig1, csig1, C3a))\n\u001b[0;32m    683\u001b[0m domg12 \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A3f(eps) \u001b[38;5;241m*\u001b[39m salp0 \u001b[38;5;241m*\u001b[39m (sig12 \u001b[38;5;241m+\u001b[39m B312)\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:414\u001b[0m, in \u001b[0;36mGeodesic._C3f\u001b[1;34m(self, eps, c)\u001b[0m\n\u001b[0;32m    412\u001b[0m m \u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mnC3_ \u001b[38;5;241m-\u001b[39m l \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m       \u001b[38;5;66;03m# order of polynomial in eps\u001b[39;00m\n\u001b[0;32m    413\u001b[0m mult \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m eps\n\u001b[1;32m--> 414\u001b[0m c[l] \u001b[38;5;241m=\u001b[39m mult \u001b[38;5;241m*\u001b[39m \u001b[43mMath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C3x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m o \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geomath.py:67\u001b[0m, in \u001b[0;36mMath.polyval\u001b[1;34m(N, p, s, x)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolyval\u001b[39m(N, p, s, x):\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate a polynomial.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p[s]) \u001b[38;5;66;03m# make sure the returned value is a float\u001b[39;00m\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m N \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     69\u001b[0m     N \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m; s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from geopy.distance import geodesic\n",
    "\n",
    "# # Initialize an empty list to store the results\n",
    "# result_list = []\n",
    "\n",
    "# # Iterate over the rows of the train_df DataFrame\n",
    "# for _, row in train_df.iterrows():\n",
    "#     picture_coords = (row['lat'], row['lon'])\n",
    "    \n",
    "#     # Filter amenities within 30 meters radius\n",
    "#     amenities_in_radius = amenities_lat_lon_df[\n",
    "#         amenities_lat_lon_df.apply(\n",
    "#             lambda x: geodesic(picture_coords, (x['latitude'], x['longitude'])).meters <= 30,\n",
    "#             axis=1\n",
    "#         )\n",
    "#     ]\n",
    "    \n",
    "#     # Create a list of amenities with their details\n",
    "#     amenities_list = [\n",
    "#         {\n",
    "#             'amenity': amenity_row['amenity'],\n",
    "#             'latitude': amenity_row['latitude'],\n",
    "#             'longitude': amenity_row['longitude']\n",
    "#         }\n",
    "#         for _, amenity_row in amenities_in_radius.iterrows()\n",
    "#     ]\n",
    "    \n",
    "#     # Append the results to the result_list\n",
    "#     result_list.append({\n",
    "#         'id': row['bubbleId'],\n",
    "#         'latitude': row['lat'],\n",
    "#         'longitude': row['lon'],\n",
    "#         'amenities': amenities_list\n",
    "#     })\n",
    "\n",
    "# # Create a new DataFrame from the results\n",
    "# final_df = pd.DataFrame(result_list)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m picture_coords \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Filter amenities within 30 meters radius\u001b[39;00m\n\u001b[0;32m     12\u001b[0m amenities_in_radius \u001b[38;5;241m=\u001b[39m amenities_lat_lon_df[\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mamenities_lat_lon_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create a list of amenities with their details\u001b[39;00m\n\u001b[0;32m     20\u001b[0m amenities_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     21\u001b[0m     {\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m: amenity_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, amenity_row \u001b[38;5;129;01min\u001b[39;00m amenities_in_radius\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[0;32m     27\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9554\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9556\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9558\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9563\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9564\u001b[0m )\n\u001b[1;32m-> 9565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 873\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    891\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    892\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    893\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m picture_coords \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Filter amenities within 30 meters radius\u001b[39;00m\n\u001b[0;32m     12\u001b[0m amenities_in_radius \u001b[38;5;241m=\u001b[39m amenities_lat_lon_df[\n\u001b[0;32m     13\u001b[0m     amenities_lat_lon_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmeters \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     15\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create a list of amenities with their details\u001b[39;00m\n\u001b[0;32m     20\u001b[0m amenities_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     21\u001b[0m     {\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m: amenity_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, amenity_row \u001b[38;5;129;01min\u001b[39;00m amenities_in_radius\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[0;32m     27\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:540\u001b[0m, in \u001b[0;36mgeodesic.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ellipsoid(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mellipsoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWGS-84\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    539\u001b[0m major, minor, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:276\u001b[0m, in \u001b[0;36mDistance.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m util\u001b[38;5;241m.\u001b[39mpairwise(args):\n\u001b[1;32m--> 276\u001b[0m         kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m units\u001b[38;5;241m.\u001b[39mkilometers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kilometers \u001b[38;5;241m=\u001b[39m kilometers\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopy\\distance.py:564\u001b[0m, in \u001b[0;36mgeodesic.measure\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    559\u001b[0m lat2, lon2 \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mlatitude, b\u001b[38;5;241m.\u001b[39mlongitude\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod, Geodesic) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod \u001b[38;5;241m=\u001b[39m \u001b[43mGeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mELLIPSOID\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mELLIPSOID\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m s12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39mInverse(lat1, lon1, lat2, lon2,\n\u001b[0;32m    567\u001b[0m                         Geodesic\u001b[38;5;241m.\u001b[39mDISTANCE)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s12\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:320\u001b[0m, in \u001b[0;36mGeodesic.__init__\u001b[1;34m(self, a, f)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C4x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(Geodesic\u001b[38;5;241m.\u001b[39mnC4x_))\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A3coeff()\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C3coeff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C4coeff()\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geodesic.py:363\u001b[0m, in \u001b[0;36mGeodesic._C3coeff\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Geodesic\u001b[38;5;241m.\u001b[39mnC3_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, l \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m# coeff of eps^j\u001b[39;00m\n\u001b[0;32m    362\u001b[0m   m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(Geodesic\u001b[38;5;241m.\u001b[39mnC3_ \u001b[38;5;241m-\u001b[39m j \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, j) \u001b[38;5;66;03m# order of polynomial in n\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C3x[k] \u001b[38;5;241m=\u001b[39m \u001b[43mMath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m coeff[o \u001b[38;5;241m+\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    364\u001b[0m   k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    365\u001b[0m   o \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rudra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geographiclib\\geomath.py:67\u001b[0m, in \u001b[0;36mMath.polyval\u001b[1;34m(N, p, s, x)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolyval\u001b[39m(N, p, s, x):\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate a polynomial.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p[s]) \u001b[38;5;66;03m# make sure the returned value is a float\u001b[39;00m\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m N \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     69\u001b[0m     N \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m; s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate over the rows of the train_df DataFrame\n",
    "for _, row in train_df.iterrows():\n",
    "    picture_coords = (row['lat'], row['lon'])\n",
    "    \n",
    "    # Filter amenities within 30 meters radius\n",
    "    amenities_in_radius = amenities_lat_lon_df[\n",
    "        amenities_lat_lon_df.apply(\n",
    "            lambda x: geodesic(picture_coords, (x['latitude'], x['longitude'])).meters <= 30,\n",
    "            axis=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Create a list of amenities with their details\n",
    "    amenities_list = [\n",
    "        {\n",
    "            'amenity': amenity_row['amenity'],\n",
    "            'latitude': amenity_row['latitude'],\n",
    "            'longitude': amenity_row['longitude']\n",
    "        }\n",
    "        for _, amenity_row in amenities_in_radius.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Append the result only if amenities are present\n",
    "    if amenities_list:\n",
    "        result_list.append({\n",
    "            'id': row['bubbleId'],\n",
    "            'latitude': row['lat'],\n",
    "            'longitude': row['lon'],\n",
    "            'amenities': amenities_list\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame from the results\n",
    "final_df = pd.DataFrame(result_list)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenities with distances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude  longitude                id  \\\n",
      "0    40.777104 -73.963860  1033310130003330   \n",
      "1    40.763575 -73.977703  1033303222012112   \n",
      "2    40.709206 -74.017376   210002012111211   \n",
      "3    40.736916 -74.001339  1101202230002123   \n",
      "4    40.747358 -74.005428   210001333221122   \n",
      "..         ...        ...               ...   \n",
      "149  40.746594 -73.982245  1033312220332010   \n",
      "150  40.761672 -73.976693   210003303023110   \n",
      "151  40.758504 -73.970898   210003301111123   \n",
      "152  40.707779 -74.007839  1101202312120133   \n",
      "153  40.711888 -74.003873  1101123003022331   \n",
      "\n",
      "                                             amenities  \n",
      "0    [{'amenity': 'waste_basket', 'latitude': 40.77...  \n",
      "1    [{'amenity': 'fast_food', 'latitude': 40.76360...  \n",
      "2    [{'amenity': 'bench', 'latitude': 40.7093396, ...  \n",
      "3    [{'amenity': 'waste_basket', 'latitude': 40.73...  \n",
      "4    [{'amenity': 'bench', 'latitude': 40.7473199, ...  \n",
      "..                                                 ...  \n",
      "149  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "150  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "151  [{'amenity': 'fast_food', 'latitude': 40.75847...  \n",
      "152  [{'amenity': 'waste_basket', 'latitude': 40.70...  \n",
      "153  [{'amenity': 'bench', 'latitude': 40.7117666, ...  \n",
      "\n",
      "[154 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "distance_results = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in final_df.iterrows():\n",
    "    # Get the ID point coordinates\n",
    "    id_coords = (row['latitude'], row['longitude'])\n",
    "    \n",
    "    # Prepare a list to store amenities with distances\n",
    "    amenities_with_distances = []\n",
    "    \n",
    "    # Iterate over the amenities for this ID\n",
    "    for amenity in row['amenities']:\n",
    "        amenity_coords = (amenity['latitude'], amenity['longitude'])\n",
    "        distance = geodesic(id_coords, amenity_coords).meters  # Calculate distance in meters\n",
    "        \n",
    "        # Add distance information to the amenity dictionary\n",
    "        amenities_with_distances.append({\n",
    "            'amenity': amenity['amenity'],\n",
    "            'latitude': amenity['latitude'],\n",
    "            'longitude': amenity['longitude'],\n",
    "            'distance_from_id': distance  # Add distance value\n",
    "        })\n",
    "    \n",
    "    # Append the updated row to the results\n",
    "    distance_results.append({\n",
    "        'latitude': row['latitude'],\n",
    "        'longitude': row['longitude'],\n",
    "        'id': row['id'],\n",
    "        'amenities': amenities_with_distances\n",
    "    })\n",
    "\n",
    "# Create a new DataFrame with distances\n",
    "final_with_distances_df = pd.DataFrame(distance_results)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(final_with_distances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_with_distances_df.to_csv(\"Distances_etc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolov8s-worldv2.pt')  # Use the specialized model\n",
    "\n",
    "# Paths to folders\n",
    "folders = ['front', 'left', 'back', 'right']\n",
    "base_folder = \"./NYC_500/\"  # Adjust this to your folder structure\n",
    "folder_paths = {f: os.path.join(base_folder, f) for f in folders}\n",
    "\n",
    "# Target amenities\n",
    "target_amenities = {'bench', 'bicycle', 'parking_meter', 'trash_bin', 'fast_food'}\n",
    "\n",
    "# Results storage\n",
    "detection_results = []\n",
    "\n",
    "# Iterate over IDs in the dataset\n",
    "for _, row in final_with_distances_df.iterrows():\n",
    "    image_id = row['id']\n",
    "    \n",
    "    # Iterate over the four folders\n",
    "    for folder, folder_path in folder_paths.items():\n",
    "        image_path = os.path.join(folder_path, f\"{image_id}.jpg\")  # Path to the image\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            # Run YOLO inference\n",
    "            results = model(image_path)\n",
    "            \n",
    "            # Process detection results\n",
    "            for result in results:\n",
    "                for box in result.boxes.data.tolist():\n",
    "                    class_id = int(box[5])  # Class ID\n",
    "                    label = model.names[class_id]  # Get label from class ID\n",
    "                    \n",
    "                    if label in target_amenities:\n",
    "                        detection_results.append({\n",
    "                            'id': image_id,\n",
    "                            'folder': folder,  # Indicate the source folder\n",
    "                            'label': label,\n",
    "                            'confidence': box[4],  # Confidence score\n",
    "                            'x_min': box[0],\n",
    "                            'y_min': box[1],\n",
    "                            'x_max': box[2],\n",
    "                            'y_max': box[3]\n",
    "                        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "detection_df = pd.DataFrame(detection_results)\n",
    "\n",
    "# Save or display the results\n",
    "print(detection_df)\n",
    "# detection_df.to_csv(\"detection_results_by_folder.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013000333001_x2.jpg: 640x640 1 car, 1 toilet, 26.0ms\n",
      "Speed: 5.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013000333010_x2.jpg: 640x640 2 buss, 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013000333003_x2.jpg: 640x640 4 cars, 1 bus, 1 truck, 1 traffic light, 28.0ms\n",
      "Speed: 4.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013000333002_x2.jpg: 640x640 3 persons, 1 car, 1 bus, 1 traffic light, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322201211201_x2.jpg: 640x640 2 cars, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322201211210_x2.jpg: 640x640 3 persons, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322201211203_x2.jpg: 640x640 1 bicycle, 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322201211202_x2.jpg: 640x640 4 persons, 1 bus, 1 traffic light, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120223000212301_x2.jpg: 640x640 1 person, 3 cars, 1 truck, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120223000212310_x2.jpg: 640x640 1 person, 5 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120223000212303_x2.jpg: 640x640 5 cars, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120223000212302_x2.jpg: 640x640 2 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301023210001_x2.jpg: 640x640 2 persons, 1 car, 2 traffic lights, 1 fire hydrant, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301023210010_x2.jpg: 640x640 1 person, 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301023210003_x2.jpg: 640x640 2 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301023210002_x2.jpg: 640x640 1 car, 1 potted plant, 1 vase, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330330331300201_x2.jpg: 640x640 1 person, 5 cars, 1 toilet, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330330331300210_x2.jpg: 640x640 2 persons, 2 bicycles, 1 car, 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330330331300203_x2.jpg: 640x640 3 persons, 1 car, 1 motorcycle, 2 trucks, 1 frisbee, 1 potted plant, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330330331300202_x2.jpg: 640x640 1 person, 2 cars, 20.0ms\n",
      "Speed: 6.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301033102301_x2.jpg: 640x640 3 cars, 1 motorcycle, 1 traffic light, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301033102310_x2.jpg: 640x640 1 person, 1 car, 3 traffic lights, 2 handbags, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301033102303_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301033102302_x2.jpg: 640x640 2 persons, 3 cars, 1 traffic light, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301031233001_x2.jpg: 640x640 1 person, 2 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301031233010_x2.jpg: 640x640 1 car, 1 boat, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301031233003_x2.jpg: 640x640 1 person, 1 bicycle, 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301031233002_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301031323301_x2.jpg: 640x640 8 persons, 5 cars, 1 handbag, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301031323310_x2.jpg: 640x640 2 persons, 4 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301031323303_x2.jpg: 640x640 5 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301031323302_x2.jpg: 640x640 3 persons, 4 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331231311031201_x2.jpg: 640x640 5 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331231311031210_x2.jpg: 640x640 2 cars, 1 bench, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331231311031203_x2.jpg: 640x640 6 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331231311031202_x2.jpg: 640x640 1 person, 1 car, 1 fire hydrant, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110112300222223301_x2.jpg: 640x640 1 person, 5 cars, 1 traffic light, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110112300222223310_x2.jpg: 640x640 4 persons, 1 car, 2 traffic lights, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110112300222223303_x2.jpg: 640x640 3 cars, 2 umbrellas, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110112300222223302_x2.jpg: 640x640 8 persons, 2 cars, 1 umbrella, 1 handbag, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330330131002201_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 1 bus, 1 truck, 2 traffic lights, 1 toilet, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330330131002210_x2.jpg: 640x640 4 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330330131002203_x2.jpg: 640x640 5 cars, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330330131002202_x2.jpg: 640x640 3 persons, 1 truck, 1 fire hydrant, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331012333000001_x2.jpg: 640x640 2 cars, 1 toilet, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331012333000010_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331012333000003_x2.jpg: 640x640 1 car, 1 truck, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331012333000002_x2.jpg: 640x640 1 person, 1 car, 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331302211101201_x2.jpg: 640x640 1 person, 1 car, 2 trucks, 16.0ms\n",
      "Speed: 7.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331302211101210_x2.jpg: 640x640 6 cars, 1 bus, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331302211101203_x2.jpg: 640x640 1 person, 6 cars, 1 bus, 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331302211101202_x2.jpg: 640x640 1 person, 2 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322122233001_x2.jpg: 640x640 3 persons, 1 bicycle, 6 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322122233010_x2.jpg: 640x640 2 persons, 3 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322122233003_x2.jpg: 640x640 6 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322122233002_x2.jpg: 640x640 4 persons, 2 cars, 1 umbrella, 1 handbag, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332323013031101_x2.jpg: 640x640 3 persons, 1 car, 1 umbrella, 1 potted plant, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332323013031110_x2.jpg: 640x640 4 persons, 2 cars, 1 bus, 1 traffic light, 2 handbags, 1 clock, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332323013031103_x2.jpg: 640x640 2 persons, 1 handbag, 1 frisbee, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332323013031102_x2.jpg: 640x640 4 persons, 1 bicycle, 4 potted plants, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330300132002101_x2.jpg: 640x640 3 persons, 1 car, 1 bus, 1 backpack, 2 potted plants, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330300132002110_x2.jpg: 640x640 3 persons, 1 umbrella, 3 potted plants, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330300132002103_x2.jpg: 640x640 2 persons, 2 bicycles, 5 cars, 1 bus, 2 potted plants, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330300132002102_x2.jpg: 640x640 2 persons, 2 cars, 2 motorcycles, 1 bus, 2 trucks, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332223121123001_x2.jpg: 640x640 3 persons, 1 car, 1 bus, 1 traffic light, 2 clocks, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332223121123010_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332223121123003_x2.jpg: 640x640 1 car, 1 mouse, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332223121123002_x2.jpg: 640x640 1 person, 1 bicycle, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332223110312101_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332223110312110_x2.jpg: 640x640 1 car, 1 bus, 1 truck, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332223110312103_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332223110312102_x2.jpg: 640x640 1 person, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110121033133331301_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110121033133331310_x2.jpg: 640x640 1 car, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110121033133331303_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110121033133331302_x2.jpg: 640x640 (no detections), 22.0ms\n",
      "Speed: 6.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120222332000301_x2.jpg: 640x640 1 person, 4 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120222332000310_x2.jpg: 640x640 4 cars, 1 clock, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120222332000303_x2.jpg: 640x640 2 cars, 1 train, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120222332000302_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330313100321301_x2.jpg: 640x640 2 persons, 1 bicycle, 4 cars, 1 motorcycle, 1 truck, 1 sink, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330313100321310_x2.jpg: 640x640 4 persons, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330313100321303_x2.jpg: 640x640 1 person, 2 cars, 1 bus, 1 boat, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330313100321302_x2.jpg: 640x640 1 car, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332302033221001_x2.jpg: 640x640 1 person, 3 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332302033221010_x2.jpg: 640x640 3 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332302033221003_x2.jpg: 640x640 5 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332302033221002_x2.jpg: 640x640 1 car, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120213233301001_x2.jpg: 640x640 1 person, 5 cars, 1 umbrella, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120213233301010_x2.jpg: 640x640 4 persons, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120213233301003_x2.jpg: 640x640 1 person, 3 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120213233301002_x2.jpg: 640x640 1 car, 1 truck, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110112300021212101_x2.jpg: 640x640 2 persons, 4 cars, 1 clock, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110112300021212110_x2.jpg: 640x640 2 cars, 2 potted plants, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110112300021212103_x2.jpg: 640x640 1 person, 6 cars, 1 potted plant, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110112300021212102_x2.jpg: 640x640 2 persons, 1 truck, 1 backpack, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013012301001_x2.jpg: 640x640 4 persons, 2 cars, 2 traffic lights, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013012301010_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013012301003_x2.jpg: 640x640 6 cars, 13.0ms\n",
      "Speed: 5.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013012301002_x2.jpg: 640x640 1 person, 4 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013022010301_x2.jpg: 640x640 1 person, 5 cars, 1 toilet, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013022010310_x2.jpg: 640x640 1 person, 4 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013022010303_x2.jpg: 640x640 7 cars, 26.0ms\n",
      "Speed: 4.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013022010302_x2.jpg: 640x640 1 person, 2 cars, 19.0ms\n",
      "Speed: 6.0ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332313022220201_x2.jpg: 640x640 2 persons, 1 bicycle, 2 cars, 2 trucks, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332313022220210_x2.jpg: 640x640 2 persons, 1 car, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332313022220203_x2.jpg: 640x640 1 person, 2 cars, 1 traffic light, 15.0ms\n",
      "Speed: 6.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332313022220202_x2.jpg: 640x640 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103333120100202001_x2.jpg: 640x640 4 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103333120100202010_x2.jpg: 640x640 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103333120100202003_x2.jpg: 640x640 1 person, 5 cars, 1 boat, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103333120100202002_x2.jpg: 640x640 2 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013030311201_x2.jpg: 640x640 2 persons, 6 cars, 1 toilet, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013030311210_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013030311203_x2.jpg: 640x640 5 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013030311202_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331310123122201_x2.jpg: 640x640 1 person, 3 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331310123122210_x2.jpg: 640x640 1 umbrella, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331310123122203_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331310123122202_x2.jpg: 640x640 1 person, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330313102000301_x2.jpg: 640x640 3 persons, 2 cars, 2 motorcycles, 1 truck, 2 traffic lights, 1 toilet, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330313102000310_x2.jpg: 640x640 3 persons, 1 car, 1 bus, 1 backpack, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330313102000303_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330313102000302_x2.jpg: 640x640 6 persons, 2 buss, 2 trucks, 1 traffic light, 1 backpack, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222103301101_x2.jpg: 640x640 1 person, 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222103301110_x2.jpg: 640x640 4 persons, 3 cars, 1 bus, 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222103301103_x2.jpg: 640x640 3 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 1 boat, 3 traffic lights, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222103301102_x2.jpg: 640x640 7 persons, 2 cars, 1 handbag, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331220023012001_x2.jpg: 640x640 3 persons, 4 cars, 1 traffic light, 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331220023012010_x2.jpg: 640x640 3 persons, 5 cars, 2 trucks, 2 umbrellas, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331220023012003_x2.jpg: 640x640 2 persons, 1 car, 1 bus, 2 trucks, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331220023012002_x2.jpg: 640x640 2 persons, 1 car, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013001211001_x2.jpg: 640x640 1 person, 2 cars, 1 motorcycle, 1 bus, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013001211010_x2.jpg: 640x640 1 car, 1 bus, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013001211003_x2.jpg: 640x640 6 cars, 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013001211002_x2.jpg: 640x640 2 cars, 1 motorcycle, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332303022330301_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332303022330310_x2.jpg: 640x640 2 cars, 1 truck, 1 potted plant, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332303022330303_x2.jpg: 640x640 1 car, 1 train, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332303022330302_x2.jpg: 640x640 1 bicycle, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330330131030201_x2.jpg: 640x640 2 cars, 1 truck, 1 traffic light, 1 toilet, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330330131030210_x2.jpg: 640x640 4 cars, 2 traffic lights, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330330131030203_x2.jpg: 640x640 5 cars, 1 bus, 1 truck, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330330131030202_x2.jpg: 640x640 2 persons, 4 cars, 1 motorcycle, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332103032113101_x2.jpg: 640x640 2 persons, 5 cars, 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332103032113110_x2.jpg: 640x640 3 persons, 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332103032113103_x2.jpg: 640x640 7 persons, 1 bicycle, 1 car, 1 bus, 1 bench, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332103032113102_x2.jpg: 640x640 1 car, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332323011233301_x2.jpg: 640x640 1 car, 1 truck, 1 umbrella, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332323011233310_x2.jpg: 640x640 3 persons, 2 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332323011233303_x2.jpg: 640x640 1 person, 2 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332323011233302_x2.jpg: 640x640 1 person, 19.0ms\n",
      "Speed: 7.0ms preprocess, 19.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322201323301_x2.jpg: 640x640 3 persons, 2 cars, 1 traffic light, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322201323310_x2.jpg: 640x640 1 person, 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322201323303_x2.jpg: 640x640 3 persons, 3 cars, 1 bus, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322201323302_x2.jpg: 640x640 4 persons, 1 car, 1 bus, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120213230201201_x2.jpg: 640x640 1 person, 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120213230201210_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120213230201203_x2.jpg: 640x640 4 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120213230201202_x2.jpg: 640x640 1 person, 1 car, 16.0ms\n",
      "Speed: 5.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331302211300101_x2.jpg: 640x640 1 person, 2 cars, 1 truck, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331302211300110_x2.jpg: 640x640 3 persons, 3 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331302211300103_x2.jpg: 640x640 3 persons, 6 cars, 1 bus, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331302211300102_x2.jpg: 640x640 3 persons, 1 car, 1 bus, 2 trucks, 1 fire hydrant, 1 potted plant, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330311031112101_x2.jpg: 640x640 1 person, 1 truck, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330311031112110_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330311031112103_x2.jpg: 640x640 1 person, 1 car, 1 train, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330311031112102_x2.jpg: 640x640 3 persons, 1 potted plant, 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332231302212101_x2.jpg: 640x640 1 person, 5 cars, 1 clock, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332231302212110_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332231302212103_x2.jpg: 640x640 2 persons, 5 cars, 2 traffic lights, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332231302212102_x2.jpg: 640x640 4 persons, 2 cars, 1 backpack, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322131013001_x2.jpg: 640x640 1 person, 1 car, 1 truck, 1 toilet, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322131013010_x2.jpg: 640x640 (no detections), 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322131013003_x2.jpg: 640x640 1 person, 1 bus, 52.0ms\n",
      "Speed: 4.0ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322131013002_x2.jpg: 640x640 5 persons, 1 bicycle, 2 motorcycles, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120222330331301_x2.jpg: 640x640 2 persons, 2 cars, 1 truck, 16.0ms\n",
      "Speed: 5.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120222330331310_x2.jpg: 640x640 2 cars, 1 bus, 1 truck, 2 traffic lights, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120222330331303_x2.jpg: 640x640 2 persons, 4 cars, 2 buss, 3 trucks, 1 handbag, 1 frisbee, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120222330331302_x2.jpg: 640x640 2 persons, 2 bicycles, 1 truck, 1 traffic light, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120213233023201_x2.jpg: 640x640 1 person, 6 cars, 1 potted plant, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120213233023210_x2.jpg: 640x640 3 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120213233023203_x2.jpg: 640x640 2 persons, 2 cars, 1 fire hydrant, 1 frisbee, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120213233023202_x2.jpg: 640x640 3 persons, 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331310122101101_x2.jpg: 640x640 1 person, 2 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331310122101110_x2.jpg: 640x640 2 persons, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331310122101103_x2.jpg: 640x640 2 cars, 1 bus, 1 boat, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331310122101102_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330313103102001_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330313103102010_x2.jpg: 640x640 8 persons, 2 cars, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330313103102003_x2.jpg: 640x640 4 cars, 1 train, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330313103102002_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331301111130201_x2.jpg: 640x640 1 toilet, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331301111130210_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331301111130203_x2.jpg: 640x640 1 person, 2 cars, 1 boat, 1 frisbee, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331301111130202_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301020103001_x2.jpg: 640x640 1 person, 2 cars, 1 truck, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301020103010_x2.jpg: 640x640 5 persons, 1 bicycle, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301020103003_x2.jpg: 640x640 4 cars, 1 bus, 1 frisbee, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301020103002_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330330322323101_x2.jpg: 640x640 2 persons, 1 bicycle, 2 cars, 2 buss, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330330322323110_x2.jpg: 640x640 2 persons, 3 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330330322323103_x2.jpg: 640x640 5 cars, 1 bus, 1 truck, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330330322323102_x2.jpg: 640x640 3 persons, 4 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332223111211101_x2.jpg: 640x640 3 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332223111211110_x2.jpg: 640x640 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332223111211103_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332223111211102_x2.jpg: 640x640 1 train, 19.0ms\n",
      "Speed: 4.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110121033202233201_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110121033202233210_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110121033202233203_x2.jpg: 640x640 (no detections), 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110121033202233202_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332322313033001_x2.jpg: 640x640 2 persons, 3 cars, 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332322313033010_x2.jpg: 640x640 1 person, 3 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332322313033003_x2.jpg: 640x640 1 car, 1 bus, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332322313033002_x2.jpg: 640x640 1 truck, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332103100222201_x2.jpg: 640x640 4 cars, 1 bus, 1 truck, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332103100222210_x2.jpg: 640x640 2 persons, 1 car, 1 fire hydrant, 23.0ms\n",
      "Speed: 7.0ms preprocess, 23.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332103100222203_x2.jpg: 640x640 4 cars, 14.0ms\n",
      "Speed: 6.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332103100222202_x2.jpg: 640x640 6 persons, 2 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222101120001_x2.jpg: 640x640 1 person, 1 bicycle, 1 car, 1 bus, 1 truck, 2 potted plants, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222101120010_x2.jpg: 640x640 3 persons, 1 suitcase, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222101120003_x2.jpg: 640x640 1 person, 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222101120002_x2.jpg: 640x640 1 person, 1 potted plant, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331301111310001_x2.jpg: 640x640 3 cars, 1 truck, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331301111310010_x2.jpg: 640x640 3 persons, 1 bicycle, 1 car, 2 traffic lights, 1 backpack, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331301111310003_x2.jpg: 640x640 2 persons, 4 cars, 1 frisbee, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331301111310002_x2.jpg: 640x640 2 persons, 2 cars, 1 truck, 1 traffic light, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332303102131001_x2.jpg: 640x640 4 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332303102131010_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332303102131003_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332303102131002_x2.jpg: 640x640 1 car, 1 clock, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332322301332001_x2.jpg: 640x640 1 car, 1 bus, 2 trucks, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332322301332010_x2.jpg: 640x640 6 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332322301332003_x2.jpg: 640x640 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332322301332002_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322133303201_x2.jpg: 640x640 1 person, 4 cars, 1 toilet, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322133303210_x2.jpg: 640x640 1 person, 5 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322133303203_x2.jpg: 640x640 2 bicycles, 5 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322133303202_x2.jpg: 640x640 2 cars, 1 truck, 1 fire hydrant, 22.0ms\n",
      "Speed: 7.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331302230102301_x2.jpg: 640x640 2 persons, 4 cars, 1 backpack, 1 umbrella, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331302230102310_x2.jpg: 640x640 3 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331302230102303_x2.jpg: 640x640 3 persons, 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331302230102302_x2.jpg: 640x640 1 person, 1 handbag, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331233200302201_x2.jpg: 640x640 3 cars, 1 toilet, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331233200302210_x2.jpg: 640x640 1 car, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331233200302203_x2.jpg: 640x640 4 cars, 1 bus, 1 truck, 1 frisbee, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331233200302202_x2.jpg: 640x640 3 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332103031311001_x2.jpg: 640x640 1 bicycle, 3 cars, 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332103031311010_x2.jpg: 640x640 1 person, 1 car, 1 bus, 1 truck, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332103031311003_x2.jpg: 640x640 1 person, 1 car, 1 bus, 1 traffic light, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332103031311002_x2.jpg: 640x640 3 persons, 2 cars, 1 motorcycle, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332303122032301_x2.jpg: 640x640 6 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332303122032310_x2.jpg: 640x640 3 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332303122032303_x2.jpg: 640x640 6 cars, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332303122032302_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330313111032001_x2.jpg: 640x640 3 cars, 2 trucks, 1 toilet, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330313111032010_x2.jpg: 640x640 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330313111032003_x2.jpg: 640x640 2 persons, 1 bicycle, 2 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330313111032002_x2.jpg: 640x640 2 persons, 1 car, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331302210030001_x2.jpg: 640x640 2 cars, 1 truck, 1 toilet, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331302210030010_x2.jpg: 640x640 2 persons, 1 car, 18.0ms\n",
      "Speed: 7.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331302210030003_x2.jpg: 640x640 3 persons, 2 cars, 1 handbag, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331302210030002_x2.jpg: 640x640 1 person, 1 car, 1 fire hydrant, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332323020101001_x2.jpg: 640x640 2 persons, 4 cars, 1 bus, 1 truck, 1 traffic light, 1 potted plant, 16.0ms\n",
      "Speed: 5.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332323020101010_x2.jpg: 640x640 4 persons, 1 bicycle, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332323020101003_x2.jpg: 640x640 4 cars, 1 fire hydrant, 1 potted plant, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332323020101002_x2.jpg: 640x640 4 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331233123033201_x2.jpg: 640x640 2 cars, 2 buss, 1 truck, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331233123033210_x2.jpg: 640x640 3 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331233123033203_x2.jpg: 640x640 2 persons, 3 cars, 2 trucks, 2 traffic lights, 1 frisbee, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331233123033202_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 1 motorcycle, 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120222333331201_x2.jpg: 640x640 1 bus, 1 stop sign, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120222333331210_x2.jpg: 640x640 4 persons, 1 car, 2 traffic lights, 1 umbrella, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120222333331203_x2.jpg: 640x640 2 persons, 1 car, 1 traffic light, 1 umbrella, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120222333331202_x2.jpg: 640x640 7 persons, 1 traffic light, 1 stop sign, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331223123233101_x2.jpg: 640x640 4 cars, 1 truck, 1 toilet, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331223123233110_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331223123233103_x2.jpg: 640x640 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331223123233102_x2.jpg: 640x640 1 car, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322121122301_x2.jpg: 640x640 4 cars, 1 toilet, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322121122310_x2.jpg: 640x640 1 person, 5 cars, 14.0ms\n",
      "Speed: 9.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322121122303_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322121122302_x2.jpg: 640x640 2 persons, 6 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330331032010201_x2.jpg: 640x640 1 person, 4 cars, 1 truck, 1 toilet, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330331032010210_x2.jpg: 640x640 1 person, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330331032010203_x2.jpg: 640x640 1 bicycle, 1 car, 1 motorcycle, 1 fire hydrant, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330331032010202_x2.jpg: 640x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331220023133201_x2.jpg: 640x640 2 persons, 2 cars, 1 truck, 1 toilet, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331220023133210_x2.jpg: 640x640 1 person, 1 car, 2 potted plants, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331220023133203_x2.jpg: 640x640 1 bicycle, 2 cars, 1 motorcycle, 1 traffic light, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331220023133202_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331103322012201_x2.jpg: 640x640 1 truck, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331103322012210_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331103322012203_x2.jpg: 640x640 2 cars, 1 frisbee, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331103322012202_x2.jpg: 640x640 1 person, 3 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330323100113301_x2.jpg: 640x640 3 cars, 1 toilet, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330323100113310_x2.jpg: 640x640 1 person, 2 cars, 1 motorcycle, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330323100113303_x2.jpg: 640x640 5 cars, 1 traffic light, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330323100113302_x2.jpg: 640x640 1 person, 2 cars, 1 umbrella, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222102002101_x2.jpg: 640x640 5 cars, 1 truck, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222102002110_x2.jpg: 640x640 1 car, 44.0ms\n",
      "Speed: 4.0ms preprocess, 44.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222102002103_x2.jpg: 640x640 4 persons, 2 cars, 1 motorcycle, 1 truck, 15.0ms\n",
      "Speed: 7.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222102002102_x2.jpg: 640x640 5 persons, 4 umbrellas, 5 potted plants, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110112331233223101_x2.jpg: 640x640 4 persons, 1 bicycle, 3 cars, 1 clock, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110112331233223110_x2.jpg: 640x640 1 person, 1 bicycle, 1 motorcycle, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110112331233223103_x2.jpg: 640x640 4 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110112331233223102_x2.jpg: 640x640 6 persons, 3 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013031200101_x2.jpg: 640x640 8 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013031200110_x2.jpg: 640x640 1 person, 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013031200103_x2.jpg: 640x640 5 cars, 1 boat, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013031200102_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301031031301_x2.jpg: 640x640 1 bus, 1 truck, 2 fire hydrants, 1 umbrella, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301031031310_x2.jpg: 640x640 1 car, 2 potted plants, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301031031303_x2.jpg: 640x640 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301031031302_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330233121312301_x2.jpg: 640x640 1 person, 4 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330233121312310_x2.jpg: 640x640 5 persons, 1 bicycle, 2 cars, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330233121312303_x2.jpg: 640x640 3 persons, 1 bicycle, 4 cars, 2 buss, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330233121312302_x2.jpg: 640x640 1 person, 3 bicycles, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330333133202101_x2.jpg: 640x640 2 cars, 1 bus, 1 frisbee, 1 toilet, 52.0ms\n",
      "Speed: 4.0ms preprocess, 52.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330333133202110_x2.jpg: 640x640 4 persons, 1 bicycle, 3 cars, 2 motorcycles, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330333133202103_x2.jpg: 640x640 6 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330333133202102_x2.jpg: 640x640 2 persons, 2 cars, 1 traffic light, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013000201101_x2.jpg: 640x640 6 cars, 1 bus, 1 toilet, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013000201110_x2.jpg: 640x640 1 car, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013000201103_x2.jpg: 640x640 2 persons, 5 cars, 1 motorcycle, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013000201102_x2.jpg: 640x640 2 cars, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120213230210301_x2.jpg: 640x640 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120213230210310_x2.jpg: 640x640 1 bicycle, 2 cars, 1 potted plant, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120213230210303_x2.jpg: 640x640 1 potted plant, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120213230210302_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332323012130301_x2.jpg: 640x640 3 persons, 2 bicycles, 4 cars, 1 traffic light, 1 potted plant, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332323012130310_x2.jpg: 640x640 2 persons, 2 bicycles, 1 motorcycle, 1 truck, 1 traffic light, 2 potted plants, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332323012130303_x2.jpg: 640x640 4 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332323012130302_x2.jpg: 640x640 4 persons, 3 cars, 1 fire hydrant, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110112233311212301_x2.jpg: 640x640 6 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110112233311212310_x2.jpg: 640x640 4 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110112233311212303_x2.jpg: 640x640 8 cars, 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110112233311212302_x2.jpg: 640x640 2 persons, 1 car, 43.0ms\n",
      "Speed: 4.0ms preprocess, 43.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331233133301201_x2.jpg: 640x640 4 cars, 13.0ms\n",
      "Speed: 7.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331233133301210_x2.jpg: 640x640 3 cars, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331233133301203_x2.jpg: 640x640 3 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331233133301202_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120231211122201_x2.jpg: 640x640 3 persons, 2 cars, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120231211122210_x2.jpg: 640x640 2 persons, 1 bicycle, 1 potted plant, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120231211122203_x2.jpg: 640x640 2 persons, 1 bicycle, 3 cars, 1 fire hydrant, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120231211122202_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322131320001_x2.jpg: 640x640 2 cars, 1 toilet, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322131320010_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322131320003_x2.jpg: 640x640 2 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322131320002_x2.jpg: 640x640 5 persons, 1 backpack, 1 handbag, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330230310221101_x2.jpg: 640x640 1 person, 9 cars, 1 boat, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330230310221110_x2.jpg: 640x640 1 person, 4 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330230310221103_x2.jpg: 640x640 5 persons, 4 cars, 1 truck, 1 traffic light, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330230310221102_x2.jpg: 640x640 1 person, 4 cars, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332303120302301_x2.jpg: 640x640 5 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332303120302310_x2.jpg: 640x640 1 person, 5 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332303120302303_x2.jpg: 640x640 3 persons, 3 cars, 1 traffic light, 1 clock, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332303120302302_x2.jpg: 640x640 3 cars, 17.0ms\n",
      "Speed: 6.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222103223001_x2.jpg: 640x640 2 persons, 4 cars, 1 bus, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222103223010_x2.jpg: 640x640 1 person, 2 cars, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222103223003_x2.jpg: 640x640 1 person, 4 cars, 1 truck, 1 chair, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222103223002_x2.jpg: 640x640 2 persons, 1 car, 1 bench, 1 backpack, 2 potted plants, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330300132103101_x2.jpg: 640x640 3 persons, 2 bicycles, 1 car, 1 bus, 3 trucks, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330300132103110_x2.jpg: 640x640 1 person, 1 bicycle, 1 motorcycle, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330300132103103_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 1 motorcycle, 1 bus, 1 clock, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330300132103102_x2.jpg: 640x640 2 persons, 1 bus, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332103033120301_x2.jpg: 640x640 1 person, 4 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332103033120310_x2.jpg: 640x640 3 cars, 1 traffic light, 1 horse, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332103033120303_x2.jpg: 640x640 4 persons, 1 bicycle, 4 cars, 1 fire hydrant, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332103033120302_x2.jpg: 640x640 3 persons, 1 car, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301030101201_x2.jpg: 640x640 1 bicycle, 5 cars, 1 toilet, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301030101210_x2.jpg: 640x640 1 person, 3 cars, 1 traffic light, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301030101203_x2.jpg: 640x640 2 persons, 3 cars, 1 traffic light, 1 fire hydrant, 1 backpack, 1 surfboard, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301030101202_x2.jpg: 640x640 1 person, 1 clock, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330231002322101_x2.jpg: 640x640 (no detections), 33.0ms\n",
      "Speed: 8.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330231002322110_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 6.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330231002322103_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330231002322102_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322132313201_x2.jpg: 640x640 2 cars, 1 toilet, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322132313210_x2.jpg: 640x640 1 car, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322132313203_x2.jpg: 640x640 3 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322132313202_x2.jpg: 640x640 2 persons, 1 bicycle, 1 car, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331233121312101_x2.jpg: 640x640 2 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331233121312110_x2.jpg: 640x640 1 bicycle, 1 car, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331233121312103_x2.jpg: 640x640 2 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331233121312102_x2.jpg: 640x640 2 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331131133011301_x2.jpg: 640x640 1 person, 2 cars, 2 traffic lights, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331131133011310_x2.jpg: 640x640 1 person, 2 cars, 1 truck, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331131133011303_x2.jpg: 640x640 1 person, 2 cars, 1 bus, 3 trucks, 2 umbrellas, 1 frisbee, 13.0ms\n",
      "Speed: 5.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331131133011302_x2.jpg: 640x640 2 persons, 1 car, 1 traffic light, 1 handbag, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330323002121301_x2.jpg: 640x640 4 cars, 1 bus, 1 toilet, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330323002121310_x2.jpg: 640x640 2 persons, 3 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330323002121303_x2.jpg: 640x640 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 25.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330323002121302_x2.jpg: 640x640 1 car, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330322132012001_x2.jpg: 640x640 1 person, 2 cars, 1 motorcycle, 1 potted plant, 1 toilet, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330322132012010_x2.jpg: 640x640 1 person, 3 cars, 1 traffic light, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330322132012003_x2.jpg: 640x640 1 bicycle, 2 cars, 1 motorcycle, 1 bus, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330322132012002_x2.jpg: 640x640 3 persons, 2 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222103331301_x2.jpg: 640x640 2 cars, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222103331310_x2.jpg: 640x640 1 person, 1 car, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222103331303_x2.jpg: 640x640 2 persons, 2 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222103331302_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330323002201201_x2.jpg: 640x640 1 person, 3 cars, 1 bus, 1 truck, 1 umbrella, 1 toilet, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330323002201210_x2.jpg: 640x640 2 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330323002201203_x2.jpg: 640x640 1 person, 3 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330323002201202_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330323023231001_x2.jpg: 640x640 2 cars, 1 toilet, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330323023231010_x2.jpg: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330323023231003_x2.jpg: 640x640 2 cars, 1 motorcycle, 1 boat, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330323023231002_x2.jpg: 640x640 (no detections), 28.0ms\n",
      "Speed: 7.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330323100203101_x2.jpg: 640x640 2 cars, 1 toilet, 14.0ms\n",
      "Speed: 6.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330323100203110_x2.jpg: 640x640 2 bicycles, 3 cars, 1 motorcycle, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330323100203103_x2.jpg: 640x640 5 cars, 1 motorcycle, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330323100203102_x2.jpg: 640x640 3 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110121100303010001_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110121100303010010_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110121100303010003_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110121100303010002_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301013023101_x2.jpg: 640x640 1 car, 1 umbrella, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301013023110_x2.jpg: 640x640 3 cars, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301013023103_x2.jpg: 640x640 3 cars, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301013023102_x2.jpg: 640x640 2 cars, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332303123011301_x2.jpg: 640x640 1 person, 1 bicycle, 3 cars, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332303123011310_x2.jpg: 640x640 4 cars, 2 trucks, 2 traffic lights, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332303123011303_x2.jpg: 640x640 5 cars, 1 bus, 1 truck, 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332303123011302_x2.jpg: 640x640 4 persons, 2 cars, 1 fire hydrant, 20.0ms\n",
      "Speed: 5.0ms preprocess, 20.0ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330233002222201_x2.jpg: 640x640 2 persons, 4 cars, 3 trucks, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330233002222210_x2.jpg: 640x640 2 persons, 1 car, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330233002222203_x2.jpg: 640x640 3 persons, 7 cars, 2 buss, 2 trucks, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330233002222202_x2.jpg: 640x640 1 person, 1 car, 1 truck, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331223122033301_x2.jpg: 640x640 3 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331223122033310_x2.jpg: 640x640 (no detections), 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331223122033303_x2.jpg: 640x640 2 cars, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331223122033302_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103332323013123201_x2.jpg: 640x640 1 bicycle, 1 car, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103332323013123210_x2.jpg: 640x640 6 persons, 1 bicycle, 1 car, 2 traffic lights, 1 stop sign, 1 potted plant, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103332323013123203_x2.jpg: 640x640 1 person, 1 car, 2 potted plants, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103332323013123202_x2.jpg: 640x640 1 car, 1 truck, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120121222232001_x2.jpg: 640x640 (no detections), 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120121222232010_x2.jpg: 640x640 (no detections), 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120121222232003_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120121222232002_x2.jpg: 640x640 (no detections), 25.0ms\n",
      "Speed: 7.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330231132131301_x2.jpg: 640x640 3 cars, 1 bus, 1 truck, 1 traffic light, 1 potted plant, 20.0ms\n",
      "Speed: 5.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330231132131310_x2.jpg: 640x640 3 persons, 1 car, 2 traffic lights, 1 bench, 1 backpack, 3 potted plants, 11.0ms\n",
      "Speed: 5.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330231132131303_x2.jpg: 640x640 2 cars, 1 bus, 1 train, 1 bench, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330231132131302_x2.jpg: 640x640 5 persons, 2 cars, 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103333120100120001_x2.jpg: 640x640 3 cars, 1 bus, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103333120100120010_x2.jpg: 640x640 1 car, 12.0ms\n",
      "Speed: 5.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103333120100120003_x2.jpg: 640x640 1 person, 4 cars, 1 motorcycle, 1 airplane, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103333120100120002_x2.jpg: 640x640 4 persons, 1 bicycle, 1 car, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331012332301201_x2.jpg: 640x640 3 persons, 3 cars, 2 trucks, 1 toilet, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331012332301210_x2.jpg: 640x640 2 persons, 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331012332301203_x2.jpg: 640x640 3 cars, 1 bus, 1 bottle, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331012332301202_x2.jpg: 640x640 1 bicycle, 1 car, 1 motorcycle, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331012000321301_x2.jpg: 640x640 3 persons, 5 cars, 1 truck, 1 toilet, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331012000321310_x2.jpg: 640x640 4 persons, 1 dog, 1 handbag, 20.0ms\n",
      "Speed: 4.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331012000321303_x2.jpg: 640x640 4 persons, 5 cars, 1 boat, 30.0ms\n",
      "Speed: 8.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331012000321302_x2.jpg: 640x640 2 persons, 1 handbag, 12.0ms\n",
      "Speed: 5.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301031101101_x2.jpg: 640x640 4 persons, 2 cars, 1 truck, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301031101110_x2.jpg: 640x640 1 car, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301031101103_x2.jpg: 640x640 1 person, 2 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301031101102_x2.jpg: 640x640 1 person, 4 cars, 1 traffic light, 1 bench, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120301013020301_x2.jpg: 640x640 1 person, 1 bicycle, 4 cars, 1 bus, 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120301013020310_x2.jpg: 640x640 2 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120301013020303_x2.jpg: 640x640 2 persons, 6 cars, 1 bus, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120301013020302_x2.jpg: 640x640 2 persons, 2 cars, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330233121232101_x2.jpg: 640x640 1 person, 4 cars, 1 toilet, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330233121232110_x2.jpg: 640x640 1 person, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330233121232103_x2.jpg: 640x640 2 persons, 1 bicycle, 6 cars, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330233121232102_x2.jpg: 640x640 2 persons, 1 bicycle, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103333133332033001_x2.jpg: 640x640 1 car, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103333133332033010_x2.jpg: 640x640 1 car, 1 bus, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103333133332033003_x2.jpg: 640x640 1 car, 26.0ms\n",
      "Speed: 6.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103333133332033002_x2.jpg: 640x640 1 car, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331013002332201_x2.jpg: 640x640 5 cars, 1 traffic light, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331013002332210_x2.jpg: 640x640 1 person, 5 cars, 14.0ms\n",
      "Speed: 5.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331013002332203_x2.jpg: 640x640 2 persons, 5 cars, 1 truck, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331013002332202_x2.jpg: 640x640 1 person, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331131133123301_x2.jpg: 640x640 2 persons, 1 bicycle, 2 cars, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331131133123310_x2.jpg: 640x640 1 car, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331131133123303_x2.jpg: 640x640 4 cars, 1 frisbee, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331131133123302_x2.jpg: 640x640 2 persons, 1 car, 1 bench, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103330310000321101_x2.jpg: 640x640 2 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103330310000321110_x2.jpg: 640x640 1 person, 2 cars, 1 motorcycle, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103330310000321103_x2.jpg: 640x640 2 persons, 4 cars, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103330310000321102_x2.jpg: 640x640 2 persons, 1 bench, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\103331222033201001_x2.jpg: 640x640 1 person, 3 cars, 1 truck, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\103331222033201010_x2.jpg: 640x640 1 car, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\103331222033201003_x2.jpg: 640x640 1 bus, 1 train, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\103331222033201002_x2.jpg: 640x640 (no detections), 25.0ms\n",
      "Speed: 4.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110120231212013301_x2.jpg: 640x640 3 cars, 1 truck, 1 fire hydrant, 16.0ms\n",
      "Speed: 6.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110120231212013310_x2.jpg: 640x640 4 persons, 3 cars, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110120231212013303_x2.jpg: 640x640 3 cars, 1 fire hydrant, 1 frisbee, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110120231212013302_x2.jpg: 640x640 3 persons, 2 cars, 1 handbag, 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\front\\110112300302233101_x2.jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\left\\110112300302233110_x2.jpg: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\back\\110112300302233103_x2.jpg: 640x640 2 cars, 11.0ms\n",
      "Speed: 4.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Data5M\\NYC_500\\right\\110112300302233102_x2.jpg: 640x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "                  id folder    label  confidence       x_min       y_min  \\\n",
      "0   1033303222012112   back  bicycle    0.388180    0.124617  293.920654   \n",
      "1   1033303303313002   left  bicycle    0.849753    1.488733  369.913330   \n",
      "2   1033303303313002   left  bicycle    0.378081  271.877655  312.262268   \n",
      "3   1101203010331023   back  bicycle    0.635595  366.345856  341.598846   \n",
      "4   1101203010312330   back  bicycle    0.313510  148.088120  293.193207   \n",
      "..               ...    ...      ...         ...         ...         ...   \n",
      "70  1033302331212321   back  bicycle    0.388748    0.000000  329.153137   \n",
      "71  1033302331212321  right  bicycle    0.628196  481.682220  322.690247   \n",
      "72  1033311311331233  front  bicycle    0.378173  132.184814  267.543579   \n",
      "73  1033311311331233  right    bench    0.264469   14.500350  292.043610   \n",
      "74  1033303100003211  right    bench    0.520282  143.815170  308.001282   \n",
      "\n",
      "         x_max       y_max  \n",
      "0    24.239565  329.305511  \n",
      "1    80.614311  442.194489  \n",
      "2   297.945007  352.643616  \n",
      "3   402.086914  401.643494  \n",
      "4   171.988754  312.907074  \n",
      "..         ...         ...  \n",
      "70   39.748127  380.175385  \n",
      "71  512.000000  374.511139  \n",
      "72  150.208160  287.875458  \n",
      "73   40.253231  319.526703  \n",
      "74  194.154175  322.889618  \n",
      "\n",
      "[75 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolov8s-worldv2.pt')  # Use the specialized model\n",
    "\n",
    "#Load Dataset\n",
    "final_with_distances_df = pd.read_csv(\"./Distances_etc.csv\")\n",
    "\n",
    "# Paths to folders\n",
    "folders = ['front', 'left', 'back', 'right']\n",
    "base_folder = \"./NYC_500/\"  # Adjust this to your folder structure\n",
    "folder_paths = {f: os.path.join(base_folder, f) for f in folders}\n",
    "\n",
    "# Define suffixes for each folder\n",
    "suffixes = {\n",
    "    'front': '01_x2.jpg',\n",
    "    'left': '10_x2.jpg',\n",
    "    'back': '03_x2.jpg',\n",
    "    'right': '02_x2.jpg'\n",
    "}\n",
    "\n",
    "# # Target amenities\n",
    "target_amenities = {'bench', 'bicycle_parking', 'post_box', 'waste_basket', 'fast_food', 'bicycle'}\n",
    "\n",
    "# Results storage\n",
    "detection_results = []\n",
    "\n",
    "# Iterate over IDs in the dataset\n",
    "for _, row in final_with_distances_df.iterrows():\n",
    "    image_id = row['id']\n",
    "    \n",
    "    # Iterate over the four folders\n",
    "    for folder, suffix in suffixes.items():\n",
    "        # Construct the image filename with suffix\n",
    "        image_filename = f\"{image_id}{suffix}\"\n",
    "        image_path = os.path.join(folder_paths[folder], image_filename)  # Path to the image\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            # Run YOLO inference\n",
    "            results = model(image_path)\n",
    "            \n",
    "            # Process detection results\n",
    "            for result in results:\n",
    "                for box in result.boxes.data.tolist():\n",
    "                    class_id = int(box[5])  # Class ID\n",
    "                    label = model.names[class_id]  # Get label from class ID\n",
    "                    \n",
    "                    if label in target_amenities:\n",
    "                        detection_results.append({\n",
    "                            'id': image_id,\n",
    "                            'folder': folder,  # Indicate the source folder\n",
    "                            'label': label,\n",
    "                            'confidence': box[4],  # Confidence score\n",
    "                            'x_min': box[0],\n",
    "                            'y_min': box[1],\n",
    "                            'x_max': box[2],\n",
    "                            'y_max': box[3]\n",
    "                        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "detection_df = pd.DataFrame(detection_results)\n",
    "\n",
    "# Save or display the results\n",
    "print(detection_df)\n",
    "detection_df.to_csv(\"detection_results_by_folder.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Inference"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6198997,
     "sourceId": 10059532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
