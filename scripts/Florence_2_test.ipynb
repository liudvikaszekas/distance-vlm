{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:28:34.370580Z",
     "iopub.status.busy": "2024-12-05T09:28:34.369856Z",
     "iopub.status.idle": "2024-12-05T09:28:34.374986Z",
     "shell.execute_reply": "2024-12-05T09:28:34.374126Z",
     "shell.execute_reply.started": "2024-12-05T09:28:34.370534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:28:36.943957Z",
     "iopub.status.busy": "2024-12-05T09:28:36.943383Z",
     "iopub.status.idle": "2024-12-05T09:28:37.006713Z",
     "shell.execute_reply": "2024-12-05T09:28:37.005999Z",
     "shell.execute_reply.started": "2024-12-05T09:28:36.943922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s-worldv2.pt')  # You can use 'yolov8.pt' or another YOLO version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-12-05T09:30:16.030992Z",
     "iopub.status.busy": "2024-12-05T09:30:16.030672Z",
     "iopub.status.idle": "2024-12-05T09:30:53.303354Z",
     "shell.execute_reply": "2024-12-05T09:30:53.302646Z",
     "shell.execute_reply.started": "2024-12-05T09:30:16.030967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./NYC_500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Load amenities from certain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/7kcjbmm92wv4f2ldlmlw82r40000gn/T/ipykernel_94388/2612556374.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['latitude'] = gdf.geometry.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 amenity   latitude  longitude\n",
      "element_type osmid                                            \n",
      "node         42538083              bench  40.673352 -73.970702\n",
      "             349323821         fast_food  40.762515 -73.976690\n",
      "             357588583   bicycle_parking  40.661771 -73.992858\n",
      "             357618584          post_box  40.682496 -73.962688\n",
      "             357618608          post_box  40.643833 -73.979460\n",
      "...                                  ...        ...        ...\n",
      "way          1340286561        fast_food  40.707104 -73.954532\n",
      "             1340573916        fast_food  40.692865 -73.757128\n",
      "             1342240422  bicycle_parking  40.723798 -74.007727\n",
      "relation     4549669           fast_food  40.709871 -73.859180\n",
      "             17722706              bench  40.753779 -74.007661\n",
      "\n",
      "[35988 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/7kcjbmm92wv4f2ldlmlw82r40000gn/T/ipykernel_94388/2612556374.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['longitude'] = gdf.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "\n",
    "# Define the bounding box or location\n",
    "place_name = \"New York City, USA\"  # Example area\n",
    "tags = {'amenity': ['post_box', 'bicycle_parking', 'bench', 'fast_food', 'waste_basket']}  # Fetch all amenities\n",
    "\n",
    "# Fetch amenities in the defined area\n",
    "gdf = ox.features_from_place(place_name, tags)\n",
    "\n",
    "# Extract latitude and longitude from the geometries\n",
    "gdf['latitude'] = gdf.geometry.centroid.y\n",
    "gdf['longitude'] = gdf.geometry.centroid.x\n",
    "\n",
    "# Filter for relevant columns\n",
    "amenities_lat_lon_df = gdf[['amenity', 'latitude', 'longitude']]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(amenities_lat_lon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from geopy.distance import geodesic\n",
    "\n",
    "# # Initialize an empty list to store the results\n",
    "# result_list = []\n",
    "\n",
    "# # Iterate over the rows of the train_df DataFrame\n",
    "# for _, row in train_df.iterrows():\n",
    "#     picture_coords = (row['lat'], row['lon'])\n",
    "    \n",
    "#     # Filter amenities within 30 meters radius\n",
    "#     amenities_in_radius = amenities_lat_lon_df[\n",
    "#         amenities_lat_lon_df.apply(\n",
    "#             lambda x: geodesic(picture_coords, (x['latitude'], x['longitude'])).meters <= 30,\n",
    "#             axis=1\n",
    "#         )\n",
    "#     ]\n",
    "    \n",
    "#     # Create a list of amenities with their details\n",
    "#     amenities_list = [\n",
    "#         {\n",
    "#             'amenity': amenity_row['amenity'],\n",
    "#             'latitude': amenity_row['latitude'],\n",
    "#             'longitude': amenity_row['longitude']\n",
    "#         }\n",
    "#         for _, amenity_row in amenities_in_radius.iterrows()\n",
    "#     ]\n",
    "    \n",
    "#     # Append the results to the result_list\n",
    "#     result_list.append({\n",
    "#         'id': row['bubbleId'],\n",
    "#         'latitude': row['lat'],\n",
    "#         'longitude': row['lon'],\n",
    "#         'amenities': amenities_list\n",
    "#     })\n",
    "\n",
    "# # Create a new DataFrame from the results\n",
    "# final_df = pd.DataFrame(result_list)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id   latitude  longitude  \\\n",
      "0    1033310130003330  40.777104 -73.963860   \n",
      "1    1033303222012112  40.763575 -73.977703   \n",
      "2     210002012111211  40.709206 -74.017376   \n",
      "3    1101202230002123  40.736916 -74.001339   \n",
      "4     210001333221122  40.747358 -74.005428   \n",
      "..                ...        ...        ...   \n",
      "149  1033312220332010  40.746594 -73.982245   \n",
      "150   210003303023110  40.761672 -73.976693   \n",
      "151   210003301111123  40.758504 -73.970898   \n",
      "152  1101202312120133  40.707779 -74.007839   \n",
      "153  1101123003022331  40.711888 -74.003873   \n",
      "\n",
      "                                             amenities  \n",
      "0    [{'amenity': 'waste_basket', 'latitude': 40.77...  \n",
      "1    [{'amenity': 'fast_food', 'latitude': 40.76360...  \n",
      "2    [{'amenity': 'bench', 'latitude': 40.7093396, ...  \n",
      "3    [{'amenity': 'waste_basket', 'latitude': 40.73...  \n",
      "4    [{'amenity': 'bench', 'latitude': 40.7473199, ...  \n",
      "..                                                 ...  \n",
      "149  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "150  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "151  [{'amenity': 'fast_food', 'latitude': 40.75847...  \n",
      "152  [{'amenity': 'waste_basket', 'latitude': 40.70...  \n",
      "153  [{'amenity': 'bench', 'latitude': 40.7117666, ...  \n",
      "\n",
      "[154 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import math\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Define approximate degree deltas for ~30 meters:\n",
    "# Latitude: ~111 km per degree, so 30 m ~ 0.00027 degrees\n",
    "lat_delta = 0.0003  # A slightly larger buffer than 0.00027 for safety\n",
    "\n",
    "# We'll dynamically compute longitude delta to be safe:\n",
    "# longitude degrees change with latitude, so we compute for each point.\n",
    "def get_lon_delta(lat):\n",
    "    return 0.0003 / math.cos(math.radians(lat))  # small approximate buffer\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    pic_lat = row['lat']\n",
    "    pic_lon = row['lon']\n",
    "\n",
    "    # Compute bounding box around the picture\n",
    "    lon_delta = get_lon_delta(pic_lat)\n",
    "    lat_min = pic_lat - lat_delta\n",
    "    lat_max = pic_lat + lat_delta\n",
    "    lon_min = pic_lon - lon_delta\n",
    "    lon_max = pic_lon + lon_delta\n",
    "\n",
    "    # Filter amenities by bounding box\n",
    "    subset = amenities_lat_lon_df[\n",
    "        (amenities_lat_lon_df['latitude'] >= lat_min) &\n",
    "        (amenities_lat_lon_df['latitude'] <= lat_max) &\n",
    "        (amenities_lat_lon_df['longitude'] >= lon_min) &\n",
    "        (amenities_lat_lon_df['longitude'] <= lon_max)\n",
    "    ]\n",
    "    \n",
    "    # Now compute geodesic distance on this filtered subset\n",
    "    pic_coords = (pic_lat, pic_lon)\n",
    "    amenities_in_radius = []\n",
    "    for _, amenity_row in subset.iterrows():\n",
    "        amenity_coords = (amenity_row['latitude'], amenity_row['longitude'])\n",
    "        dist = geodesic(pic_coords, amenity_coords).meters\n",
    "        if dist <= 30:\n",
    "            amenities_in_radius.append({\n",
    "                'amenity': amenity_row['amenity'],\n",
    "                'latitude': amenity_row['latitude'],\n",
    "                'longitude': amenity_row['longitude']\n",
    "            })\n",
    "    \n",
    "    if amenities_in_radius:\n",
    "        result_list.append({\n",
    "            'id': row['bubbleId'],\n",
    "            'latitude': pic_lat,\n",
    "            'longitude': pic_lon,\n",
    "            'amenities': amenities_in_radius\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame from the results\n",
    "final_df = pd.DataFrame(result_list)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenities with distances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      latitude  longitude                id  \\\n",
      "0    40.777104 -73.963860  1033310130003330   \n",
      "1    40.763575 -73.977703  1033303222012112   \n",
      "2    40.709206 -74.017376   210002012111211   \n",
      "3    40.736916 -74.001339  1101202230002123   \n",
      "4    40.747358 -74.005428   210001333221122   \n",
      "..         ...        ...               ...   \n",
      "149  40.746594 -73.982245  1033312220332010   \n",
      "150  40.761672 -73.976693   210003303023110   \n",
      "151  40.758504 -73.970898   210003301111123   \n",
      "152  40.707779 -74.007839  1101202312120133   \n",
      "153  40.711888 -74.003873  1101123003022331   \n",
      "\n",
      "                                             amenities  \n",
      "0    [{'amenity': 'waste_basket', 'latitude': 40.77...  \n",
      "1    [{'amenity': 'fast_food', 'latitude': 40.76360...  \n",
      "2    [{'amenity': 'bench', 'latitude': 40.7093396, ...  \n",
      "3    [{'amenity': 'waste_basket', 'latitude': 40.73...  \n",
      "4    [{'amenity': 'bench', 'latitude': 40.7473199, ...  \n",
      "..                                                 ...  \n",
      "149  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "150  [{'amenity': 'bicycle_parking', 'latitude': 40...  \n",
      "151  [{'amenity': 'fast_food', 'latitude': 40.75847...  \n",
      "152  [{'amenity': 'waste_basket', 'latitude': 40.70...  \n",
      "153  [{'amenity': 'bench', 'latitude': 40.7117666, ...  \n",
      "\n",
      "[154 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "distance_results = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, row in final_df.iterrows():\n",
    "    # Get the ID point coordinates\n",
    "    id_coords = (row['latitude'], row['longitude'])\n",
    "    \n",
    "    # Prepare a list to store amenities with distances\n",
    "    amenities_with_distances = []\n",
    "    \n",
    "    # Iterate over the amenities for this ID\n",
    "    for amenity in row['amenities']:\n",
    "        amenity_coords = (amenity['latitude'], amenity['longitude'])\n",
    "        distance = geodesic(id_coords, amenity_coords).meters  # Calculate distance in meters\n",
    "        \n",
    "        # Add distance information to the amenity dictionary\n",
    "        amenities_with_distances.append({\n",
    "            'amenity': amenity['amenity'],\n",
    "            'latitude': amenity['latitude'],\n",
    "            'longitude': amenity['longitude'],\n",
    "            'distance_from_id': distance  # Add distance value\n",
    "        })\n",
    "    \n",
    "    # Append the updated row to the results\n",
    "    distance_results.append({\n",
    "        'latitude': row['latitude'],\n",
    "        'longitude': row['longitude'],\n",
    "        'id': row['id'],\n",
    "        'amenities': amenities_with_distances\n",
    "    })\n",
    "\n",
    "# Create a new DataFrame with distances\n",
    "final_with_distances_df = pd.DataFrame(distance_results)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(final_with_distances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'amenity': 'waste_basket', 'latitude': 40.7769217, 'longitude': -73.9640435, 'distance_from_id': 25.49109292574657}]\n"
     ]
    }
   ],
   "source": [
    "print(str(final_with_distances_df.amenities[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import requests\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'microsoft/Florence-2-large-ft'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval()\n",
    "model = model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image, task_prompt, text_input=None):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        pixel_values=inputs[\"pixel_values\"],\n",
    "        max_new_tokens=1024,\n",
    "        early_stopping=False,\n",
    "        do_sample=False,\n",
    "        num_beams=3,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text,\n",
    "        task=task_prompt,\n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "    return parsed_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id folder  \\\n",
      "0    1101203010232100   back   \n",
      "1    1101203010232100  right   \n",
      "2    1033303303313002   back   \n",
      "3    1101203010312330  front   \n",
      "4    1101203010312330   left   \n",
      "..                ...    ...   \n",
      "97   1101202312120133   back   \n",
      "98   1101123003022331  front   \n",
      "99   1101123003022331   left   \n",
      "100  1101123003022331   back   \n",
      "101  1101123003022331  right   \n",
      "\n",
      "                                                 label confidence       x_min  \\\n",
      "0                                   bench waste_basket       None  120.576004   \n",
      "1                                   bench waste_basket       None  434.432007   \n",
      "2    bicycle_parking post_box waste_basket bicycle_...       None  136.448013   \n",
      "3    bench bench bench bench waste_basket bench ben...       None   31.488001   \n",
      "4    bench bench bench bench waste_basket bench ben...       None  327.936005   \n",
      "..                                                 ...        ...         ...   \n",
      "97   waste_basket waste_basket bench bench bench wa...       None  121.600006   \n",
      "98                                               bench       None  257.792023   \n",
      "99                                               bench       None    0.256000   \n",
      "100                                              bench       None  314.624023   \n",
      "101                                              bench       None  345.856018   \n",
      "\n",
      "          y_min       x_max       y_max  \n",
      "0    430.336029  375.552032  511.232025  \n",
      "1    298.240021  472.320007  325.888000  \n",
      "2    446.720032  409.856018  511.232025  \n",
      "3    314.624023  110.848007  365.824005  \n",
      "4    366.336029  511.232025  511.232025  \n",
      "..          ...         ...         ...  \n",
      "97   395.520020  511.232025  511.232025  \n",
      "98   272.640015  272.128021  284.928009  \n",
      "99   312.576019  263.936005  371.968018  \n",
      "100  279.808014  371.968018  307.456024  \n",
      "101  332.544006  511.232025  355.072021  \n",
      "\n",
      "[102 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "suffixes = {\n",
    "    'front': '01_x2.jpg',\n",
    "    'left': '10_x2.jpg',\n",
    "    'back': '03_x2.jpg',\n",
    "    'right': '02_x2.jpg'\n",
    "}\n",
    "# Base folder and subfolders\n",
    "folders = ['front', 'left', 'back', 'right']\n",
    "base_folder = \"./NYC_500/\"  # Adjust this path\n",
    "folder_paths = {f: os.path.join(base_folder, f) for f in folders}\n",
    "\n",
    "detection_results = []\n",
    "\n",
    "task_prompt = '<OPEN_VOCABULARY_DETECTION>'\n",
    "\n",
    "for _, row in final_with_distances_df.iterrows():\n",
    "    image_id = row['id']\n",
    "\n",
    "    # The \"amenities\" column is assumed to be a list of dicts like:\n",
    "    # [{'amenity': 'waste_basket', 'latitude': ..., 'longitude': ..., 'distance_from_id': ...}, ... ]\n",
    "    amenities_list = row['amenities']\n",
    "\n",
    "    # Extract just the amenity names\n",
    "    amenities_to_detect = [d['amenity'] for d in amenities_list if 'amenity' in d]\n",
    "\n",
    "    # Skip if there are no amenities to detect\n",
    "    if not amenities_to_detect:\n",
    "        continue\n",
    "\n",
    "    # Construct the text input (e.g. \"waste_basket bench bicycle_parking ...\")\n",
    "    text_input = \" \".join(amenities_to_detect)\n",
    "\n",
    "    for folder, suffix in suffixes.items():\n",
    "        # Construct image path\n",
    "        image_filename = f\"{image_id}{suffix}\"\n",
    "        image_path = os.path.join(folder_paths[folder], image_filename)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        with Image.open(image_path) as img:\n",
    "            # Run Florence 2 inference\n",
    "            parsed_answer = run_inference(img, task_prompt, text_input=text_input)\n",
    "\n",
    "            # Extract the open vocabulary detection data\n",
    "            ovd_data = parsed_answer.get(\"<OPEN_VOCABULARY_DETECTION>\", {})\n",
    "\n",
    "            # Focus on bboxes and bboxes_labels only\n",
    "            bboxes = ovd_data.get(\"bboxes\", [])\n",
    "            bboxes_labels = ovd_data.get(\"bboxes_labels\", [])\n",
    "\n",
    "            # If the length of bboxes and bboxes_labels are mismatched, handle or skip\n",
    "            if len(bboxes) != len(bboxes_labels):\n",
    "                print(f\"Warning: Mismatched bboxes and labels for {image_id} in {folder}.\")\n",
    "                continue\n",
    "\n",
    "            # Go through each bounding box\n",
    "            for bbox, label in zip(bboxes, bboxes_labels):\n",
    "                # bbox is [x_min, y_min, x_max, y_max]\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "                # Append to detection results\n",
    "                detection_results.append({\n",
    "                    'id': image_id,\n",
    "                    'folder': folder,\n",
    "                    'label': label,\n",
    "                    'confidence': None,  # If Florence doesn't provide a confidence score\n",
    "                    'x_min': x_min,\n",
    "                    'y_min': y_min,\n",
    "                    'x_max': x_max,\n",
    "                    'y_max': y_max\n",
    "                })\n",
    "\n",
    "# Convert detection results to a DataFrame\n",
    "detection_df = pd.DataFrame(detection_results)\n",
    "\n",
    "# Display or save the detection results\n",
    "print(detection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>folder</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101203010232100</td>\n",
       "      <td>back</td>\n",
       "      <td>bench waste_basket</td>\n",
       "      <td>None</td>\n",
       "      <td>120.576004</td>\n",
       "      <td>430.336029</td>\n",
       "      <td>375.552032</td>\n",
       "      <td>511.232025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101203010232100</td>\n",
       "      <td>right</td>\n",
       "      <td>bench waste_basket</td>\n",
       "      <td>None</td>\n",
       "      <td>434.432007</td>\n",
       "      <td>298.240021</td>\n",
       "      <td>472.320007</td>\n",
       "      <td>325.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1033303303313002</td>\n",
       "      <td>back</td>\n",
       "      <td>bicycle_parking post_box waste_basket bicycle_...</td>\n",
       "      <td>None</td>\n",
       "      <td>136.448013</td>\n",
       "      <td>446.720032</td>\n",
       "      <td>409.856018</td>\n",
       "      <td>511.232025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101203010312330</td>\n",
       "      <td>front</td>\n",
       "      <td>bench bench bench bench waste_basket bench ben...</td>\n",
       "      <td>None</td>\n",
       "      <td>31.488001</td>\n",
       "      <td>314.624023</td>\n",
       "      <td>110.848007</td>\n",
       "      <td>365.824005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101203010312330</td>\n",
       "      <td>left</td>\n",
       "      <td>bench bench bench bench waste_basket bench ben...</td>\n",
       "      <td>None</td>\n",
       "      <td>327.936005</td>\n",
       "      <td>366.336029</td>\n",
       "      <td>511.232025</td>\n",
       "      <td>511.232025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1101202312120133</td>\n",
       "      <td>back</td>\n",
       "      <td>waste_basket waste_basket bench bench bench wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>121.600006</td>\n",
       "      <td>395.520020</td>\n",
       "      <td>511.232025</td>\n",
       "      <td>511.232025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1101123003022331</td>\n",
       "      <td>front</td>\n",
       "      <td>bench</td>\n",
       "      <td>None</td>\n",
       "      <td>257.792023</td>\n",
       "      <td>272.640015</td>\n",
       "      <td>272.128021</td>\n",
       "      <td>284.928009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1101123003022331</td>\n",
       "      <td>left</td>\n",
       "      <td>bench</td>\n",
       "      <td>None</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>312.576019</td>\n",
       "      <td>263.936005</td>\n",
       "      <td>371.968018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1101123003022331</td>\n",
       "      <td>back</td>\n",
       "      <td>bench</td>\n",
       "      <td>None</td>\n",
       "      <td>314.624023</td>\n",
       "      <td>279.808014</td>\n",
       "      <td>371.968018</td>\n",
       "      <td>307.456024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1101123003022331</td>\n",
       "      <td>right</td>\n",
       "      <td>bench</td>\n",
       "      <td>None</td>\n",
       "      <td>345.856018</td>\n",
       "      <td>332.544006</td>\n",
       "      <td>511.232025</td>\n",
       "      <td>355.072021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id folder  \\\n",
       "0    1101203010232100   back   \n",
       "1    1101203010232100  right   \n",
       "2    1033303303313002   back   \n",
       "3    1101203010312330  front   \n",
       "4    1101203010312330   left   \n",
       "..                ...    ...   \n",
       "97   1101202312120133   back   \n",
       "98   1101123003022331  front   \n",
       "99   1101123003022331   left   \n",
       "100  1101123003022331   back   \n",
       "101  1101123003022331  right   \n",
       "\n",
       "                                                 label confidence       x_min  \\\n",
       "0                                   bench waste_basket       None  120.576004   \n",
       "1                                   bench waste_basket       None  434.432007   \n",
       "2    bicycle_parking post_box waste_basket bicycle_...       None  136.448013   \n",
       "3    bench bench bench bench waste_basket bench ben...       None   31.488001   \n",
       "4    bench bench bench bench waste_basket bench ben...       None  327.936005   \n",
       "..                                                 ...        ...         ...   \n",
       "97   waste_basket waste_basket bench bench bench wa...       None  121.600006   \n",
       "98                                               bench       None  257.792023   \n",
       "99                                               bench       None    0.256000   \n",
       "100                                              bench       None  314.624023   \n",
       "101                                              bench       None  345.856018   \n",
       "\n",
       "          y_min       x_max       y_max  \n",
       "0    430.336029  375.552032  511.232025  \n",
       "1    298.240021  472.320007  325.888000  \n",
       "2    446.720032  409.856018  511.232025  \n",
       "3    314.624023  110.848007  365.824005  \n",
       "4    366.336029  511.232025  511.232025  \n",
       "..          ...         ...         ...  \n",
       "97   395.520020  511.232025  511.232025  \n",
       "98   272.640015  272.128021  284.928009  \n",
       "99   312.576019  263.936005  371.968018  \n",
       "100  279.808014  371.968018  307.456024  \n",
       "101  332.544006  511.232025  355.072021  \n",
       "\n",
       "[102 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# The suffixes you provided for each folder (direction)\n",
    "suffixes = {\n",
    "    'front': '01_x2.jpg',\n",
    "    'left': '10_x2.jpg',\n",
    "    'back': '03_x2.jpg',\n",
    "    'right': '02_x2.jpg'\n",
    "}\n",
    "\n",
    "def plot_all_detections(detection_df, base_folder=\"./NYC_500/\"):\n",
    "    \"\"\"\n",
    "    Plots all bounding box detections from detection_df using Matplotlib.\n",
    "    Each row in detection_df must have these columns:\n",
    "      - id\n",
    "      - folder (one of: front, left, back, right)\n",
    "      - label\n",
    "      - confidence\n",
    "      - x_min, y_min, x_max, y_max\n",
    "\n",
    "    base_folder is where your directional subfolders (front, left, back, right) live.\n",
    "    \"\"\"\n",
    "    # Group the DataFrame by (id, folder) so that we can plot all boxes\n",
    "    # belonging to the same image on a single figure.\n",
    "    grouped = detection_df.groupby(['id', 'folder'], as_index=False)\n",
    "\n",
    "    for (image_id, folder), group_rows in grouped:\n",
    "        # Build the full path to the image, using the suffixes dict\n",
    "        suffix = suffixes.get(folder, \"\")\n",
    "        image_filename = f\"{image_id}{suffix}\"\n",
    "        image_path = os.path.join(base_folder, folder, image_filename)\n",
    "\n",
    "        # Check if the image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load the image\n",
    "        img = Image.open(image_path)\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # Plot each detection (bounding box)\n",
    "        for _, row in group_rows.iterrows():\n",
    "            x_min, y_min, x_max, y_max = row['x_min'], row['y_min'], row['x_max'], row['y_max']\n",
    "\n",
    "            # Draw the rectangle\n",
    "            rect = plt.Rectangle(\n",
    "                (x_min, y_min),\n",
    "                (x_max - x_min),\n",
    "                (y_max - y_min),\n",
    "                fill=False,\n",
    "                edgecolor='red',\n",
    "                linewidth=2\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            # Create a label string\n",
    "            label_str = str(row['label'])\n",
    "            if row['confidence'] is not None:\n",
    "                # In case your confidence is None or not numeric, handle gracefully\n",
    "                try:\n",
    "                    label_str += f\" ({float(row['confidence']):.2f})\"\n",
    "                except ValueError:\n",
    "                    # Confidence not numeric\n",
    "                    pass\n",
    "\n",
    "            # Place label text just above bounding box\n",
    "            ax.text(\n",
    "                x_min,\n",
    "                y_min - 5,\n",
    "                label_str,\n",
    "                color='red',\n",
    "                fontsize=10,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5, edgecolor='none')\n",
    "            )\n",
    "\n",
    "        # Optional title\n",
    "        plt.title(f\"Detections for ID = {image_id}, Folder = {folder}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_all_detections(detection_df, base_folder=\"./NYC_500/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO World Model (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolov8s-worldv2.pt')  # Use the specialized model\n",
    "\n",
    "# Define suffixes for each folder\n",
    "suffixes = {\n",
    "    'front': '01_x2.jpg',\n",
    "    'left': '10_x2.jpg',\n",
    "    'back': '03_x2.jpg',\n",
    "    'right': '02_x2.jpg'\n",
    "}\n",
    "\n",
    "# Paths to folders\n",
    "folders = ['front', 'left', 'back', 'right']\n",
    "base_folder = \"./NYC_500/\"  # Adjust this to your folder structure\n",
    "folder_paths = {f: os.path.join(base_folder, f) for f in folders}\n",
    "\n",
    "# Target amenities\n",
    "target_amenities = {'post_box', 'bicycle_parking', 'bench', 'waste_basket'}\n",
    "\n",
    "# Results storage\n",
    "detection_results = []\n",
    "\n",
    "# Iterate over IDs in the dataset\n",
    "for _, row in final_with_distances_df.iterrows():\n",
    "    image_id = row['id']\n",
    "    \n",
    "    for folder, suffix in suffixes.items():\n",
    "        # Construct the image filename with suffix\n",
    "        image_filename = f\"{image_id}{suffix}\"\n",
    "        image_path = os.path.join(folder_paths[folder], image_filename)  # Path to the image\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            # Run YOLO inference\n",
    "            results = model(image_path)\n",
    "            \n",
    "            # Process detection results\n",
    "            for result in results:\n",
    "                for box in result.boxes.data.tolist():\n",
    "                    class_id = int(box[5])  # Class ID\n",
    "                    label = model.names[class_id]  # Get label from class ID\n",
    "                    \n",
    "                    if label in target_amenities:\n",
    "                        detection_results.append({\n",
    "                            'id': image_id,\n",
    "                            'folder': folder,  # Indicate the source folder\n",
    "                            'label': label,\n",
    "                            'confidence': box[4],  # Confidence score\n",
    "                            'x_min': box[0],\n",
    "                            'y_min': box[1],\n",
    "                            'x_max': box[2],\n",
    "                            'y_max': box[3]\n",
    "                        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "detection_df = pd.DataFrame(detection_results)\n",
    "\n",
    "# Save or display the results\n",
    "print(detection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id folder  label  confidence       x_min       y_min  \\\n",
      "0  1033312313110312   left  bench    0.370045  448.528168  301.353638   \n",
      "1  1033321030321131   back  bench    0.509984  338.523834  343.717712   \n",
      "2  1033312221032230  right  bench    0.308314   89.116806  320.609619   \n",
      "3  1033302311321313   left  bench    0.591969    0.000000  316.001801   \n",
      "4  1033302311321313   back  bench    0.421387  450.672546  314.855133   \n",
      "5  1101203010311011  right  bench    0.292347  364.066101  341.255371   \n",
      "6  1033311311331233  right  bench    0.264469   14.500369  292.043610   \n",
      "7  1033303100003211  right  bench    0.520286  143.815155  308.001282   \n",
      "\n",
      "        x_max       y_max  \n",
      "0  482.541443  325.961548  \n",
      "1  399.499603  381.025726  \n",
      "2  121.303612  337.528137  \n",
      "3   21.816593  346.805328  \n",
      "4  512.000000  344.377533  \n",
      "5  446.445007  482.324127  \n",
      "6   40.253227  319.526703  \n",
      "7  194.154160  322.889587  \n"
     ]
    }
   ],
   "source": [
    "print(detection_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Inference"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6198997,
     "sourceId": 10059532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
