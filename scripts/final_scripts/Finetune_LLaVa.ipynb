{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7081bd11-a3f3-4e83-9852-141995d1b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/hpi/fs00/scratch/liudvikas.zekas/.cache\n"
     ]
    }
   ],
   "source": [
    "%env HF_HOME=/hpi/fs00/scratch/liudvikas.zekas/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3819fac7-56de-4aa7-a34b-9472f5f0327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from transformers import LlavaNextForConditionalGeneration, LlavaNextProcessor, AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "def extract_meter(text):\n",
    "    \"\"\"\n",
    "    Extracts the first occurrence of a number (optionally followed by 'meters', 'meter', or 'm')\n",
    "    from the given text and returns it as a float.\n",
    "    \"\"\"\n",
    "    # This regex matches a number (integer or decimal) and ignores an optional \"meters\", \"meter\" or \"m\"\n",
    "    match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*(?:meters?|m)?\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            value = float(match.group(1))\n",
    "            return value\n",
    "        except Exception as e:\n",
    "            print(\"Error converting extracted value:\", e)\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def inference_image(model, processor, image_path, human_text):\n",
    "    \"\"\"\n",
    "    Run inference on a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: The Llava model.\n",
    "        processor: The processor for formatting the prompt and image.\n",
    "        image_path (str): Path to the image file.\n",
    "        human_text (str): The human prompt text from the test JSON.\n",
    "    \n",
    "    Returns:\n",
    "        output (str): The generated answer from the model.\n",
    "    \"\"\"\n",
    "    # Build the conversation prompt including text and an image placeholder.\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": human_text},\n",
    "                {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    \n",
    "    # Load the image in RGB mode.\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Process the text prompt and image (wrap image in a list).\n",
    "    inputs = processor(text=prompt, images=image, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate the model's output.\n",
    "    output = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "\n",
    "    return processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def run_inference_on_dataset(model, processor, dataset_path, image_root, save_name):\n",
    "    \"\"\"\n",
    "    Iterate over all items in the test JSON file, perform inference, extract the predicted meter,\n",
    "    compute the error compared to the ground truth, and save the results in a DataFrame and CSV.\n",
    "    \n",
    "    Args:\n",
    "        model: The Llava model.\n",
    "        processor: The Llava processor.\n",
    "        dataset_path (str): Path to the JSON file (e.g., \"./dataset/test.json\").\n",
    "        image_root (str): Directory where the image files are stored.\n",
    "        save_name (str): Name for the output CSV file (without extension).\n",
    "    \n",
    "    Returns:\n",
    "        df: A pandas DataFrame with columns: id, predicted_meter, ground_truth_meter, and error.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for item in data:\n",
    "        item_id = item.get(\"id\")\n",
    "        image_file = item[\"image\"]\n",
    "        image_path = os.path.join(image_root, image_file)\n",
    "        \n",
    "        # Extract the human prompt (first \"human\" message).\n",
    "        human_text = \"\"\n",
    "        for conv in item.get(\"conversations\", []):\n",
    "            if conv.get(\"from\", \"\").lower() == \"human\":\n",
    "                human_text = conv.get(\"value\", \"\")\n",
    "                break\n",
    "        \n",
    "        # Remove the \"<image>\" part from the beginning, if present.\n",
    "        if human_text.startswith(\"<image>\"):\n",
    "            human_text = human_text[len(\"<image>\"):].strip()\n",
    "        \n",
    "        # Extract the ground truth answer (first \"gpt\" message).\n",
    "        ground_truth_str = \"\"\n",
    "        for conv in item.get(\"conversations\", []):\n",
    "            if conv.get(\"from\", \"\").lower() == \"gpt\":\n",
    "                ground_truth_str = conv.get(\"value\", \"\")\n",
    "                break\n",
    "        \n",
    "        # Run inference.\n",
    "        model_output = inference_image(model, processor, image_path, human_text)\n",
    "        print(model_output)\n",
    "        \n",
    "        # Extract predicted meter from model output and ground truth meter.\n",
    "        pred_meter = extract_meter(model_output)\n",
    "        gt_meter = extract_meter(ground_truth_str)\n",
    "        \n",
    "        # Compute the absolute error if both numbers are available.\n",
    "        error = None\n",
    "        if pred_meter is not None and gt_meter is not None:\n",
    "            error = abs(pred_meter - gt_meter)\n",
    "        \n",
    "        # Print the results.\n",
    "        print(f\"Item ID: {item_id}\")\n",
    "        print(\"Predicted Meter:\", pred_meter)\n",
    "        print(\"Ground Truth:\", gt_meter)\n",
    "        print(\"Error:\", error)\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Save results.\n",
    "        results.append({\n",
    "            \"id\": item_id,\n",
    "            \"predicted_meter\": pred_meter,\n",
    "            \"ground_truth_meter\": gt_meter,\n",
    "            \"error\": error\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame from the results and save to CSV.\n",
    "    df = pd.DataFrame(results)\n",
    "    csv_filename = f\"res/{save_name}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a83dd1-0b07-4c3e-aac4-33d57fb1fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from transformers import LlavaNextForConditionalGeneration, LlavaNextProcessor, AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "def extract_meter(text):\n",
    "    \"\"\"\n",
    "    Extracts the first occurrence of a number (optionally followed by 'meters', 'meter', or 'm')\n",
    "    from the given text and returns it as a float.\n",
    "    \"\"\"\n",
    "    # This regex matches a number (integer or decimal) and ignores an optional \"meters\", \"meter\" or \"m\"\n",
    "    match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*(?:meters?|m)?\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            value = float(match.group(1))\n",
    "            return value\n",
    "        except Exception as e:\n",
    "            print(\"Error converting extracted value:\", e)\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def inference_image(model, processor, image_path, human_text):\n",
    "    \"\"\"\n",
    "    Run inference on a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: The Llava model.\n",
    "        processor: The processor for formatting the prompt and image.\n",
    "        image_path (str): Path to the image file.\n",
    "        human_text (str): The human prompt text from the test JSON.\n",
    "    \n",
    "    Returns:\n",
    "        output (str): The generated answer from the model.\n",
    "    \"\"\"\n",
    "    # Build the conversation prompt including text and an image placeholder.\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": human_text},\n",
    "                {\"type\": \"image\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    \n",
    "    # Load the image in RGB mode.\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Process the text prompt and image (wrap image in a list).\n",
    "    inputs = processor(text=prompt, images=image, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate the model's output.\n",
    "    #output = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "    #print(processor.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    # Run the forward pass to get regression output.\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    # Assuming the output is a tensor of shape (batch_size, 1), convert it to a float.\n",
    "    predicted_meter = output.item()\n",
    "    return predicted_meter\n",
    "\n",
    "def run_inference_on_dataset(model, processor, dataset_path, image_root, save_name):\n",
    "    \"\"\"\n",
    "    Iterate over all items in the test JSON file, perform inference, compare the predicted meter \n",
    "    against the ground truth, and save the results in a DataFrame and CSV.\n",
    "    \n",
    "    Args:\n",
    "        model: The Llava regression model.\n",
    "        processor: The processor.\n",
    "        dataset_path (str): Path to the JSON file (e.g., \"./dataset/test.json\").\n",
    "        image_root (str): Directory where the image files are stored.\n",
    "        save_name (str): Name for the output CSV file (without extension).\n",
    "    \n",
    "    Returns:\n",
    "        df: A pandas DataFrame with columns: id, predicted_meter, ground_truth_meter, and error.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for item in data:\n",
    "        item_id = item.get(\"id\")\n",
    "        image_file = item[\"image\"]\n",
    "        image_path = os.path.join(image_root, image_file)\n",
    "        \n",
    "        # Extract the human prompt (first \"human\" message).\n",
    "        human_text = \"\"\n",
    "        for conv in item.get(\"conversations\", []):\n",
    "            if conv.get(\"from\", \"\").lower() == \"human\":\n",
    "                human_text = conv.get(\"value\", \"\")\n",
    "                break\n",
    "        \n",
    "        # Remove the \"<image>\" part from the beginning, if present.\n",
    "        if human_text.startswith(\"<image>\"):\n",
    "            human_text = human_text[len(\"<image>\"):].strip()\n",
    "        \n",
    "        # Extract the ground truth answer (first \"gpt\" message).\n",
    "        ground_truth_str = \"\"\n",
    "        for conv in item.get(\"conversations\", []):\n",
    "            if conv.get(\"from\", \"\").lower() == \"gpt\":\n",
    "                ground_truth_str = conv.get(\"value\", \"\")\n",
    "                break\n",
    "        \n",
    "        # Run inference using the regression head.\n",
    "        predicted_meter = inference_image(model, processor, image_path, human_text)\n",
    "        print(f\"Predicted meter: {predicted_meter}\")\n",
    "        \n",
    "        # Extract ground truth meter from the ground truth text.\n",
    "        gt_meter = extract_meter(ground_truth_str)\n",
    "        \n",
    "        # Compute the absolute error if both numbers are available.\n",
    "        error = None\n",
    "        if predicted_meter is not None and gt_meter is not None:\n",
    "            error = abs(predicted_meter - gt_meter)\n",
    "        \n",
    "        # Print the results.\n",
    "        print(f\"Item ID: {item_id}\")\n",
    "        print(\"Predicted Meter:\", predicted_meter)\n",
    "        print(\"Ground Truth:\", gt_meter)\n",
    "        print(\"Error:\", error)\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Save results.\n",
    "        results.append({\n",
    "            \"id\": item_id,\n",
    "            \"predicted_meter\": predicted_meter,\n",
    "            \"ground_truth_meter\": gt_meter,\n",
    "            \"error\": error\n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame from the results and save to CSV.\n",
    "    df = pd.DataFrame(results)\n",
    "    csv_filename = f\"res/{save_name}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb44b31-78b4-4276-94e7-2b88890a43db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSON test file and the directory where images are stored.\n",
    "test_json_path = \"./dataset_new/test.json\"  # Adjust if necessary.\n",
    "image_root = \"/\"                # Adjust if your images are located elsewhere.\n",
    "\n",
    "# Load the processor (ensure this is the one that supports image input).\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe05f2a7-6b64-4f54-9c04-c703f3194733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json_path = \"./dataset_new/train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3caf1a-dd92-44b1-84d4-63fb577c26d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Original Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ugebwzaohO3D7XbW343_qA_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: qz33ZhqXW5DY-2hPzv2CMQ_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 10.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Tx4CWkxiDU1xV7-uZ6lLrw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8QVoY6NmGZBiZz1qi5irCQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: r-yGTE7GDoTFE49DyCJOQw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: eC7O22NYV9d6KWGMa4vR7A_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mGq1XR8eBPbK9_J0gOAOlQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8oe-e2AHXuj3E1JMMp7LUQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Aita8sR2NtHUJE-mmnR5eA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: UFsdG3hTkVymziyC-ZxMYQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: R9dD-rTZG17YN-mnL9kvpQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: iGoMMW3J_lxftnHeOXACmA_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: YJHBrKidMhT7l8QarqnQiQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Q5uPvNi_9o7WZoOzLpPs3A_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 2k_tvKZMASA2E5VbB0GaXQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: eQ-gEUsyOXA85uoFC-ftWQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: BCLppoUZzUo1hHwOXlMFdw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: -3SAmGjbIQXzZTfUtGeakw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: WSAWFRhBUpcfb5K_IyDjmQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 15.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ls5vsLksz2FGrtiX4pXcjw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: _G_-fkVxInuOL_gh1TCkAw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: KsAhdawvyYxlqfej-gzUsA_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 11.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: lIJcDFhNquz9zvnRLHqWbA_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 72ebTpipZnU1ZlSBp2nSuQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 23.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: A3DdT3R0Me5Thr0jZ3vqbA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: s8b27kdyBAl_sotzHJ5wYA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1TTgoWtPcUDu1ii-0vUysA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: xNuPeVv3Ean47MOZXJzdgQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 17.0\n",
      "Error: 83.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: IM5Tg5Vs_XNKPB0Y6bXQJA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: wnCjh-4PWBDlednovnwurQ_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: UQu9TdfMPsz6HgCBXwm_OA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JralPklJ9gCp4EA_RyeWRA_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: M9wYWkddYwPsS8bOAAnVQA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 3cTQXFxHQ4AaC7aogs4uKg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: rdd9lAv469KKItvAGNOOJg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera.\n",
      "Item ID: XIaYmJKv1Oh2TzOBENycvA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: DGpCRwXAFtuzOCxiC3AJXQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Z_0D8JCx3LqmbelS6LwBlg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: pvgzxAkbpGBsYQInYsWhgg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 2lGYlEsaQ03StY5XLBIJlQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 26.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: YSHVBBGad1bvL78FosZqIw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: eb8MU6EB-Ab6zkw8w6l07Q_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: LHSWcIZo86wt0-3Axz6h_g_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: lUCB-zSdG5v8e7f6yo9hFw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: mc_oZOlXyr9sItAXp-EEFQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Qo2aUtgdEnZ96pkpYNEmAg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: W1GOhAzbdnwjlJ-RrP8UDg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: lRA5rE4hSeIS8cLCmczXQw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 11.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: TmAJ0zQ2uIyhpj81qDsyHg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 23.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: OaoCpdsxh259v77mvTPhLQ_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: wc0EvjsWIVV8WUXMYA9u4Q_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 5Rl3jytWkaTOiWLr7PDwdQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: cf8_ef6XCqNOI3lj5KzjOA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 23.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: AWdJTbKEf5HBdRXHzGGC3A_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: eJIgtiIzNQ7478dhnPH2lQ_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Cx59xrGyKeRhAqomop17yg_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: qn-fWttcGKIJ7Zc4c1pkqw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: zSP4L1e2ilC2jV9kuwrNaw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: jbUqNAyorVVwMczpYlOnug_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: jfz76Ye8P1tRIX5j6Y_MFw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: d4hQ_xl8nHeMaP6R97uNgg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: n8NSRWP5PY_ECNUo4guX3g_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: J0RU4yu-NC93sJo4XZ20qw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 9WZaNAcZKK0CG_6Ti6MOBw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: u9Kokx_8X1UHcThQufdKBQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 16.0\n",
      "Error: 84.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: N32bZK7jAraafCM7dRXRVg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: q4OI0Scwi1i0HkqRTAJKKA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 12.0\n",
      "Error: 88.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: hx5M3hRQSuMVV3BzCAegCg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 3ixcETgziLCGAjvOEqWM7g_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: OArBY4CDcYgtKL89eIzkWw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: xb9LiT2Y_dUww_PC0NOLOQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 15.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: iib8V4vSPpts_FtmuxH4tg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 6v1-hhiayJy7DoBpfpN6wA_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: _vO63qpalTD-pyBTLFdy1g_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: qq8iXTbkO_iEK4mJLC1xgA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: SIQOuGqlTXsiqwfDq6zoCg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: eRQ_lSJa8rZ3LFZ9s36v7A_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 12.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: ODpq7KBrQltTE1PM9XsymA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: Uo4CGPMzPzMx-A8Mjp6ziw_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: a3CD8WKIaMh74X_w1hp7sQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: dcRWrKzhakwQYNJVjRTTDw_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ggLlWlPCXTY3fRqkhBUoLw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: I4dohtV49xeb159_Ng8Umw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: W-gBkV3CvuaiXTp8ypzwJA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: QrzepgRmPP6RvB-5DCKDOw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: KuSK5cvU7kUtZVVnQmfMMQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 29.0\n",
      "Error: 19.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: jn4zEaguUF85vtddS9591A_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 2-FSObqDy2OGHRS-oLXpIA_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 9.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: KxKRZzRg654ggxD9Un5qhw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: pvA1fuCApUKCE1EAb1Xgig_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Rv3VUBBBNctDraTzS2RI3g_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 26.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: The ATM is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 19vgVzfNilUW-ZOFDTBU3w_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: sW81gMtDmZH5rH6dKD2Kgg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: e72VAs__5et9iblG7Jzbkg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JBh4Q90EGzF9bfNWNEx_yQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: UK2rWp3Bd4YrFtzB7sqlvA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: _O0jxrZYJf_QSDnbrH3_2g_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Ym3CPMFWgLQgwLP7MoZerw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8naUjoF8o0pkX_YlDQHcCQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: P46zszgViyt-C8o6lET3Ow_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 3owL9LAboiuqRM_8xI8c5w_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: a4pv7J1rC3HwrnQWaugEAA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: pahz2YZlAB_f80CoGzLtSA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: aniYGD6kiz9Gtf0l-70f2Q_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: TTV6SfcooODCtltjtgSdSg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: vcaFbHdSXrGksEiMGrQLrQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: dWF-5O9XfAEky8SiZKOgRg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: MPBnrxKHyNuVDqVLQuyG9g_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: k2YBj5MKBV4ZN_iwZ4aCEQ_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 13.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QsUUe_r6kLQGpz0mMQJItQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 14.0\n",
      "Error: 86.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: cAjf-qb2WlKMgLqdL9nDKg_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Z53S5bnyH7mNGBg_vJQcmA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: k2bp2EYvD4dBPteB1oLO8A_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: F5BsVFC7xaJOKxCpu8yTPw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: WwPPUkMasXt-Z4ABU64n5Q_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Y-tv1UuQOqcdTwdkKu3ynA_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: WEoRVaCevfKMUZ-ZrcT7cg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: DvhPeyRQJhMg3UHrlbW2-w_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Q2OBeuPzC1Q72afMqUePsg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: JE2OCpze2DtiqLnRi5HHJg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: vTWkIglCRmG2TnGkIFHM7Q_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: jvZukHq03jbMHllXrubKrg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: XW-9W9p2AVcQ77RIlngbtw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: cFIOqI5tHirjVFr43ORP9A_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 3bxRhzHjh-cWBHE3fS-JcA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 7XSkktf9ACvkRIyMeQc03Q_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 8.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: AT91nZn9t9ftyX4ZUaT7ig_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Rrfkhr-SlT5F6hHpq4CLPQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 5Ey4TG-gAsmi1ua7pm6wkg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Z4Mm-TnKHDlaZxWdKO_1hg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 5l1iitQtnhauPWpB68_jFQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 7FeZIFjcQAL-3ci60J3EFQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 8HdhRsrE8MmqEgcq3vttxw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JwmZvLLBilTA-5jI2gTazw_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: NqpFTRtqj2fUyQyQYhFSzQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Ce0tHCxNMDi6wPRp-s47jw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: nVAA5-GdotO9RbO9NjI-qw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QrMeDQ9jdGJJ0rV2PVJEiw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8pEZHqbN5u8_yG8_dfXbwg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 6-mgzznPhuvGSSjQkq6Jcw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 13.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Pfii6WqCwWdlp5FC-V4-tg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8b9HdmvIET8ZzN25BPoAqg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: XBZ7vig2eHnbKujbK0YrKw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 3.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 7ek2uD1SadiiO7S_CiCaFQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: zSYaKhsUunxd2HieLw--Bw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ooonkaHPxwqhujFUqM5pxw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: euF84E5dXEqouOs2QXcQvw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: sBvClBUQk7xVDK-zZ7cJsg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 6nJTO2TykG9p_u6nqNIDfw_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 30.0\n",
      "Error: 20.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: vIIbBr4Zyvw5iE2qnXkDFw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QjGIJdW81n-QPSYKVx9yeg_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Tn4uYOv0Lgp7BJQXxWgu0A_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: The ATM is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: eK6GR-zlSKodjUThcJH4UA_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: MCsrah6QrlrSsMR4q-bdrg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 29.0\n",
      "Error: 19.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: gyO5-qLWE4VT16crnReokw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: gcev0hxtltoqCuqDffc1Ig_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QarynNyW6wNqfaYJwWl8mw_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: vqLP0uk2AgSU1smrbC9Kvg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 12.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: KcU4SrBPYpdOKOg1GG6tLQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: fq9dHETPobs-9ThuB39XIA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: De-ve_jLpQ2Qtp8TdV1B7w_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 0zUQyjBxNCgr2m5DcaFD7g_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 9aAQN3uUShfw9hrpyhlJPQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 23K2mFVzbr6lgTCY23RSyA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ZtEPmOuKRrXgxN530WjKcQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: MCT0I-phnpTIdJSHxPtY-g_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mgrFIGd_29iyc-W2Ss-5jw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mlYvnxD8afYF5Nk-OF586Q_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: TiowKAVmIDB9vomUrCEavA_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 5SVYauUAV9ZXo2j86RG9Nw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Hb7GT5BfydzVAky33nEYWw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 28.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: n_-sAWzo-dL9XYZ3UzaYqA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8IFkUwxQ62DDv-tOHhqTQg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: t-ObecRVp4gxHXU-c2LqWA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: yX3nYikBoHLy4CRAPIzBug_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: nwRZPegKQEcE9K_vk69Z9Q_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ysT0A7MmG8MHyY5MFjgfzg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: hUKSWoNyPXipTtKRMMVNpw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: P11gxo_aHViVXuN2TI1OHg_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 20.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: yk32zNW_DJiLkXyl-tAW1Q_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: rn5P8mSyhi_XnmRqx6nBKQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: f6f84yNmkf8dSKmA1WLL7g_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 6rMd7Pu3dPDxfKH2hLr2cg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 13.0\n",
      "Error: 87.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: The vending machine is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: gfnR0b6W1zb84NAfdD8sLQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: IC6kW3S7XTym0qyTt0JbHQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: dONIwocp2GAJUXZYYG83Kw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: jzPv_XRZOHrODSl7I9CQ3g_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 26.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 3DIZja3YjsiL-kIvWohenw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: fPyAVSl8mmbPEKbvzZXbtQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mjFLZisPjatDeki9c5acEg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: SA7K9gTIMdwmXDTsDcBM6Q_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ELejaWw7AULkc0v0Of43yQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: bIHH-_IXF2ik1ynh9n06zQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mzltktb5OGPPKPAWlC_fCA_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: A9S-KxBLUmMgIGQZMvhxBw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: gmliVFMV0b8_cmZ-QyDEAQ_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 7gGp2SI0dsnSkN-JuQiesw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 4UYo98GXL__fsXn5Hx4CPQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QArcg6Bp7lO81QVYjAfhPg_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: O45aphvvSoBaD8agtIVz7w_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: _nYEhvKAIDtrvoRFpCSuBQ_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: gLMnHJfMVfS176MkMVYWxA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: uixXcPpyT06jWktX7LvdUg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 2qEcuuJ-XtAJsGDEnh0VYg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1CFhl2zw8_wpjV8SaYekZA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: TrZtzGlvyG_QmyhBJBma4A_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Y1OMmLWmRqjyAP7zn4TGNA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: CzHuqJTBB29Mj10Tf-vG_A_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 3k16AWQgqv40UC3T2pxpRA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: pksYc6IzkoN8GUhDj0LDpQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 9vadzEjIYIdbpVS1SXgiuA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 5NGOlsI3ydBDw0VOZ79c2A_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 24.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: 9jetR7KxoqyH2uA45eUhZA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 13.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: The ATM is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: fNup96_l6Q9_7sMN3jSYSA_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 17.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: StE2fFKWlxq5oOY9TLzqaQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 14.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Qz18uRHUrVtSIBcwaI6big_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 26.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera.\n",
      "Item ID: 1N4oepZ2Tdx0RiMNW70Emg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Wwz8TuQs25BR7pV6ZLxHIA_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: w7E4-o_FBl46aJR4nygWKA_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 27.0\n",
      "Error: 17.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: EJyxn_BdvstB7aQW5qtXHA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: hPHfaOJAMuZoaAeHKwGt0Q_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 23.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: Y2LqquXdxkG6CERz_G6Nlg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: VKDduK1sl3OF7ekMGjEI_Q_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: pVT3i-VC8DKKHxxGzGM1Gw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: QByx_5dPkZWspXNMrVlJCQ_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: sAX1efN-2Q1WTVF2Slt0Vg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: B2xQQNnGkZTxyQWXhWUjjA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 18.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: PSXKhfo_2-cixnRnrkWgug_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 20.0\n",
      "Error: 80.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 60vORc94qejRLoePlhyhoA_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: trCU9ky8rsxm4mMv4NGTxg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: yqPszzxqxHCcIjL-v3WSWA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: LpCUToI7Cvgkq0ILdMjfqQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: h9fvBHcx4BJ4zNUEwixmOw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: AJz20_6wSjeKoUZmfq-X2A_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 18.0\n",
      "Error: 82.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: i5WVC6hZreMrj25W7QzYRw_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: ZdiVojc1dtotNExOp58x5A_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 26.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 60vORc94qejRLoePlhyhoA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 8vYyJMHE_ay2QBvq6RIX5g_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the electric charging station away from the camera in meters, rounded to the next meter? ASSISTANT: The electric charging station is approximately 10 meters away from the camera.\n",
      "Item ID: ycFZ9QwrUeciEE2HSrFAeQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 12.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1Y7B1JQtBHVe2iPrAiM-eg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: 7UXQIVV4UHo3-oDPm7qELQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: axGFVJ1krhsn6mC28ooKVA_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 2M7SYVOfLnMuDXYnW8FfEQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 30.0\n",
      "Error: 70.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: MS8ZruXv6pKGYFtg62uMpg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 27.0\n",
      "Error: 73.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: q57H2cmymr1Ixjb9MbCfPQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: EdEUoTTAcuM9cNcu08a1nw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: NkjfX-IG5Qw8M_p_clCO4A_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: dInyxmFH1E4YJXjzmHFDHg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: cTPFfgZ4KkUXKHzMddF7Bg_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1LGPz7B3vJ2IT1Qm_2nytw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: JpCaP2v70FtqJJGeXyjDdw_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 19.0\n",
      "Error: 81.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: KP7OmYZuuX5T0O8CQGFFWg_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 15.0\n",
      "Error: 85.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: KtvPeGrsVIBkeHq8DsJfhQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 28.0\n",
      "Error: 72.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 2pj56we2AFhPUcV36gq4dw_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: yKjJVY-QcL8B72FWucki9A_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: X7F2k-IYYxWQONqJvKFAUA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: D-QBRj4cortWyDiYEUHvsw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 6.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: b9NFY5tRuunJ3jBmVf7UBA_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: dGxsDZMbA6DXA4d1Pq0Bjg_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: ZpIKRM0lVXkIYHKNeJ-PSw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 24.0\n",
      "Error: 76.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 21.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1C1eS9jrHwDToiIteIZqgQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 17.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: The large waste dumpster is approximately 10 meters away from the camera.\n",
      "Item ID: luxAA4b_ND2ueb7anI88BA_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 21.0\n",
      "Error: 79.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: Qy7K-TboLcgUyUupDtMgKQ_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: mqpRUiJoeyjpoVAjiEiKMQ_front\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 22.0\n",
      "Error: 78.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: cE0sa5qCriI6GUBYMcyKeg_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 25.0\n",
      "Error: 15.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera.\n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_back\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 25.0\n",
      "Error: 75.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: sw8Il_kg3VTkg4hfRAqhgg_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 29.0\n",
      "Error: 19.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: wNMjdSqgpzj6j72V6oMMUg_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 29.0\n",
      "Error: 71.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: The post box is approximately 10 meters away from the camera, rounded to the next meter.\n",
      "Item ID: C72ymm34PyRc2OruySafpQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 15.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 10 meters away from the camera.\n",
      "Item ID: tL1cMj27xoKEUPU8emSdSQ_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 22.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: 1KKSCQJLKYDDK3KSdFkHdw_right\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 23.0\n",
      "Error: 77.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: The gas station is approximately 100 meters away from the camera, rounded to the next meter.\n",
      "Item ID: l7wQW6Nrj2lN4nrgHrVA0g_left\n",
      "Predicted Meter: 100.0\n",
      "Ground Truth: 26.0\n",
      "Error: 74.0\n",
      "==================================================\n",
      "Results saved to res/llava1.5_no_finetune.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the original model.\n",
    "old_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-1.5-7b-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "#old_model = old_model.to_empty(0)  # moves model from meta to GPU 0\n",
    "\n",
    "\n",
    "print(\"=== Inference using the Original Model ===\")\n",
    "df_no_train = run_inference_on_dataset(old_model, processor, test_json_path, image_root, \"llava1.5_no_finetune\")\n",
    "del old_model  # Clean up if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19203df-c040-4bbc-a135-3d053843d150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Finetuned Model ===\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: ugebwzaohO3D7XbW343_qA_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 30.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: qz33ZhqXW5DY-2hPzv2CMQ_back\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 10.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 27.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: Tx4CWkxiDU1xV7-uZ6lLrw_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 8QVoY6NmGZBiZz1qi5irCQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: r-yGTE7GDoTFE49DyCJOQw_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: eC7O22NYV9d6KWGMa4vR7A_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mGq1XR8eBPbK9_J0gOAOlQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 8oe-e2AHXuj3E1JMMp7LUQ_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Aita8sR2NtHUJE-mmnR5eA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: UFsdG3hTkVymziyC-ZxMYQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: R9dD-rTZG17YN-mnL9kvpQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 28.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: iGoMMW3J_lxftnHeOXACmA_front\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 24.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: YJHBrKidMhT7l8QarqnQiQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: Q5uPvNi_9o7WZoOzLpPs3A_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 25.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 2k_tvKZMASA2E5VbB0GaXQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: eQ-gEUsyOXA85uoFC-ftWQ_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 28.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: BCLppoUZzUo1hHwOXlMFdw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 24.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: -3SAmGjbIQXzZTfUtGeakw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: WSAWFRhBUpcfb5K_IyDjmQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 15.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ls5vsLksz2FGrtiX4pXcjw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: _G_-fkVxInuOL_gh1TCkAw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: KsAhdawvyYxlqfej-gzUsA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 11.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: lIJcDFhNquz9zvnRLHqWbA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 72ebTpipZnU1ZlSBp2nSuQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: A3DdT3R0Me5Thr0jZ3vqbA_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: s8b27kdyBAl_sotzHJ5wYA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 1TTgoWtPcUDu1ii-0vUysA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: xNuPeVv3Ean47MOZXJzdgQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 17.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: IM5Tg5Vs_XNKPB0Y6bXQJA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: wnCjh-4PWBDlednovnwurQ_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 20.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: UQu9TdfMPsz6HgCBXwm_OA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: JralPklJ9gCp4EA_RyeWRA_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: M9wYWkddYwPsS8bOAAnVQA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3cTQXFxHQ4AaC7aogs4uKg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: rdd9lAv469KKItvAGNOOJg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: XIaYmJKv1Oh2TzOBENycvA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: DGpCRwXAFtuzOCxiC3AJXQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Z_0D8JCx3LqmbelS6LwBlg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pvgzxAkbpGBsYQInYsWhgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 2lGYlEsaQ03StY5XLBIJlQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: YSHVBBGad1bvL78FosZqIw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: eb8MU6EB-Ab6zkw8w6l07Q_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 22.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: LHSWcIZo86wt0-3Axz6h_g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: lUCB-zSdG5v8e7f6yo9hFw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: mc_oZOlXyr9sItAXp-EEFQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Qo2aUtgdEnZ96pkpYNEmAg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: W1GOhAzbdnwjlJ-RrP8UDg_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: lRA5rE4hSeIS8cLCmczXQw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 11.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: TmAJ0zQ2uIyhpj81qDsyHg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 23.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: OaoCpdsxh259v77mvTPhLQ_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: wc0EvjsWIVV8WUXMYA9u4Q_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5Rl3jytWkaTOiWLr7PDwdQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: cf8_ef6XCqNOI3lj5KzjOA_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 23.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: AWdJTbKEf5HBdRXHzGGC3A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: eJIgtiIzNQ7478dhnPH2lQ_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 28.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Cx59xrGyKeRhAqomop17yg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: qn-fWttcGKIJ7Zc4c1pkqw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: zSP4L1e2ilC2jV9kuwrNaw_right\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 20.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: jbUqNAyorVVwMczpYlOnug_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: jfz76Ye8P1tRIX5j6Y_MFw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: d4hQ_xl8nHeMaP6R97uNgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: n8NSRWP5PY_ECNUo4guX3g_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: J0RU4yu-NC93sJo4XZ20qw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 9WZaNAcZKK0CG_6Ti6MOBw_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 21.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: u9Kokx_8X1UHcThQufdKBQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 16.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: N32bZK7jAraafCM7dRXRVg_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: q4OI0Scwi1i0HkqRTAJKKA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 12.0\n",
      "Error: 17.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: hx5M3hRQSuMVV3BzCAegCg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3ixcETgziLCGAjvOEqWM7g_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: OArBY4CDcYgtKL89eIzkWw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: xb9LiT2Y_dUww_PC0NOLOQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 15.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: iib8V4vSPpts_FtmuxH4tg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: 6v1-hhiayJy7DoBpfpN6wA_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 18.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _vO63qpalTD-pyBTLFdy1g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: qq8iXTbkO_iEK4mJLC1xgA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: SIQOuGqlTXsiqwfDq6zoCg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: eRQ_lSJa8rZ3LFZ9s36v7A_back\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 12.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ODpq7KBrQltTE1PM9XsymA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Uo4CGPMzPzMx-A8Mjp6ziw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: a3CD8WKIaMh74X_w1hp7sQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: dcRWrKzhakwQYNJVjRTTDw_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 25.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ggLlWlPCXTY3fRqkhBUoLw_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: I4dohtV49xeb159_Ng8Umw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: W-gBkV3CvuaiXTp8ypzwJA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: QrzepgRmPP6RvB-5DCKDOw_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 21.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: KuSK5cvU7kUtZVVnQmfMMQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: jn4zEaguUF85vtddS9591A_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 16.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: 2-FSObqDy2OGHRS-oLXpIA_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 9.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: KxKRZzRg654ggxD9Un5qhw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pvA1fuCApUKCE1EAb1Xgig_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: Rv3VUBBBNctDraTzS2RI3g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 26.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 19vgVzfNilUW-ZOFDTBU3w_left\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 19.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: sW81gMtDmZH5rH6dKD2Kgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: e72VAs__5et9iblG7Jzbkg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: JBh4Q90EGzF9bfNWNEx_yQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: UK2rWp3Bd4YrFtzB7sqlvA_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _O0jxrZYJf_QSDnbrH3_2g_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Ym3CPMFWgLQgwLP7MoZerw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: 8naUjoF8o0pkX_YlDQHcCQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: P46zszgViyt-C8o6lET3Ow_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3owL9LAboiuqRM_8xI8c5w_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: a4pv7J1rC3HwrnQWaugEAA_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 20.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pahz2YZlAB_f80CoGzLtSA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: aniYGD6kiz9Gtf0l-70f2Q_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: TTV6SfcooODCtltjtgSdSg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: vcaFbHdSXrGksEiMGrQLrQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 21.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dWF-5O9XfAEky8SiZKOgRg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: MPBnrxKHyNuVDqVLQuyG9g_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 20.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: k2YBj5MKBV4ZN_iwZ4aCEQ_back\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: QsUUe_r6kLQGpz0mMQJItQ_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 14.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: cAjf-qb2WlKMgLqdL9nDKg_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Z53S5bnyH7mNGBg_vJQcmA_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: k2bp2EYvD4dBPteB1oLO8A_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: F5BsVFC7xaJOKxCpu8yTPw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: WwPPUkMasXt-Z4ABU64n5Q_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Y-tv1UuQOqcdTwdkKu3ynA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: WEoRVaCevfKMUZ-ZrcT7cg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: DvhPeyRQJhMg3UHrlbW2-w_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 22.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Q2OBeuPzC1Q72afMqUePsg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: JE2OCpze2DtiqLnRi5HHJg_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: vTWkIglCRmG2TnGkIFHM7Q_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: jvZukHq03jbMHllXrubKrg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 18.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: XW-9W9p2AVcQ77RIlngbtw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: cFIOqI5tHirjVFr43ORP9A_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 18.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 3bxRhzHjh-cWBHE3fS-JcA_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 19.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 11 \n",
      "Item ID: 7XSkktf9ACvkRIyMeQc03Q_front\n",
      "Predicted Meter: 11.0\n",
      "Ground Truth: 8.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: AT91nZn9t9ftyX4ZUaT7ig_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Rrfkhr-SlT5F6hHpq4CLPQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5Ey4TG-gAsmi1ua7pm6wkg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: Z4Mm-TnKHDlaZxWdKO_1hg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 19.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5l1iitQtnhauPWpB68_jFQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 7FeZIFjcQAL-3ci60J3EFQ_left\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8HdhRsrE8MmqEgcq3vttxw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: JwmZvLLBilTA-5jI2gTazw_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 19.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: NqpFTRtqj2fUyQyQYhFSzQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Ce0tHCxNMDi6wPRp-s47jw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: nVAA5-GdotO9RbO9NjI-qw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: QrMeDQ9jdGJJ0rV2PVJEiw_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 20.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8pEZHqbN5u8_yG8_dfXbwg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: 6-mgzznPhuvGSSjQkq6Jcw_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 13.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Pfii6WqCwWdlp5FC-V4-tg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 8b9HdmvIET8ZzN25BPoAqg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 6 \n",
      "Item ID: XBZ7vig2eHnbKujbK0YrKw_right\n",
      "Predicted Meter: 6.0\n",
      "Ground Truth: 3.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 7ek2uD1SadiiO7S_CiCaFQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: zSYaKhsUunxd2HieLw--Bw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ooonkaHPxwqhujFUqM5pxw_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: euF84E5dXEqouOs2QXcQvw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: sBvClBUQk7xVDK-zZ7cJsg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 24.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 6nJTO2TykG9p_u6nqNIDfw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: vIIbBr4Zyvw5iE2qnXkDFw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: QjGIJdW81n-QPSYKVx9yeg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Tn4uYOv0Lgp7BJQXxWgu0A_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 30.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: eK6GR-zlSKodjUThcJH4UA_left\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 18.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: MCsrah6QrlrSsMR4q-bdrg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: gyO5-qLWE4VT16crnReokw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: gcev0hxtltoqCuqDffc1Ig_left\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: QarynNyW6wNqfaYJwWl8mw_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 24.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: vqLP0uk2AgSU1smrbC9Kvg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 12.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: KcU4SrBPYpdOKOg1GG6tLQ_left\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 7.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: fq9dHETPobs-9ThuB39XIA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: De-ve_jLpQ2Qtp8TdV1B7w_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 0zUQyjBxNCgr2m5DcaFD7g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: 9aAQN3uUShfw9hrpyhlJPQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 19.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 23K2mFVzbr6lgTCY23RSyA_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: ZtEPmOuKRrXgxN530WjKcQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: MCT0I-phnpTIdJSHxPtY-g_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mgrFIGd_29iyc-W2Ss-5jw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mlYvnxD8afYF5Nk-OF586Q_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: TiowKAVmIDB9vomUrCEavA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 5SVYauUAV9ZXo2j86RG9Nw_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: Hb7GT5BfydzVAky33nEYWw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: n_-sAWzo-dL9XYZ3UzaYqA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 8IFkUwxQ62DDv-tOHhqTQg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: t-ObecRVp4gxHXU-c2LqWA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 19.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: yX3nYikBoHLy4CRAPIzBug_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: nwRZPegKQEcE9K_vk69Z9Q_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ysT0A7MmG8MHyY5MFjgfzg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: hUKSWoNyPXipTtKRMMVNpw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: P11gxo_aHViVXuN2TI1OHg_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 20.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: yk32zNW_DJiLkXyl-tAW1Q_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: rn5P8mSyhi_XnmRqx6nBKQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: f6f84yNmkf8dSKmA1WLL7g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 6rMd7Pu3dPDxfKH2hLr2cg_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: gfnR0b6W1zb84NAfdD8sLQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 21.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: IC6kW3S7XTym0qyTt0JbHQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: dONIwocp2GAJUXZYYG83Kw_right\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jzPv_XRZOHrODSl7I9CQ3g_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 26.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 3DIZja3YjsiL-kIvWohenw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 26.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: fPyAVSl8mmbPEKbvzZXbtQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 18.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mjFLZisPjatDeki9c5acEg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: SA7K9gTIMdwmXDTsDcBM6Q_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 19.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ELejaWw7AULkc0v0Of43yQ_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: bIHH-_IXF2ik1ynh9n06zQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mzltktb5OGPPKPAWlC_fCA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: A9S-KxBLUmMgIGQZMvhxBw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: gmliVFMV0b8_cmZ-QyDEAQ_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 7gGp2SI0dsnSkN-JuQiesw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4UYo98GXL__fsXn5Hx4CPQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: QArcg6Bp7lO81QVYjAfhPg_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 16.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: O45aphvvSoBaD8agtIVz7w_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 21.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _nYEhvKAIDtrvoRFpCSuBQ_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: gLMnHJfMVfS176MkMVYWxA_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 24.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: uixXcPpyT06jWktX7LvdUg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 2qEcuuJ-XtAJsGDEnh0VYg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 18.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1CFhl2zw8_wpjV8SaYekZA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 25.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: TrZtzGlvyG_QmyhBJBma4A_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: Y1OMmLWmRqjyAP7zn4TGNA_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 20.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: CzHuqJTBB29Mj10Tf-vG_A_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 3k16AWQgqv40UC3T2pxpRA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pksYc6IzkoN8GUhDj0LDpQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 9vadzEjIYIdbpVS1SXgiuA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 5NGOlsI3ydBDw0VOZ79c2A_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 24.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 9jetR7KxoqyH2uA45eUhZA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: fNup96_l6Q9_7sMN3jSYSA_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 17.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: StE2fFKWlxq5oOY9TLzqaQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 14.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: Qz18uRHUrVtSIBcwaI6big_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 26.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 7 \n",
      "Item ID: 1N4oepZ2Tdx0RiMNW70Emg_right\n",
      "Predicted Meter: 7.0\n",
      "Ground Truth: 7.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: Wwz8TuQs25BR7pV6ZLxHIA_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 21.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: w7E4-o_FBl46aJR4nygWKA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: EJyxn_BdvstB7aQW5qtXHA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: hPHfaOJAMuZoaAeHKwGt0Q_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Y2LqquXdxkG6CERz_G6Nlg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: VKDduK1sl3OF7ekMGjEI_Q_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pVT3i-VC8DKKHxxGzGM1Gw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: QByx_5dPkZWspXNMrVlJCQ_left\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 28.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: sAX1efN-2Q1WTVF2Slt0Vg_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 16.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: B2xQQNnGkZTxyQWXhWUjjA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: PSXKhfo_2-cixnRnrkWgug_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 60vORc94qejRLoePlhyhoA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: trCU9ky8rsxm4mMv4NGTxg_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: yqPszzxqxHCcIjL-v3WSWA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: LpCUToI7Cvgkq0ILdMjfqQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: h9fvBHcx4BJ4zNUEwixmOw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: AJz20_6wSjeKoUZmfq-X2A_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 18.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: i5WVC6hZreMrj25W7QzYRw_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 23.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ZdiVojc1dtotNExOp58x5A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 60vORc94qejRLoePlhyhoA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8vYyJMHE_ay2QBvq6RIX5g_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the electric charging station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ycFZ9QwrUeciEE2HSrFAeQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 12.0\n",
      "Error: 17.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1Y7B1JQtBHVe2iPrAiM-eg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 7UXQIVV4UHo3-oDPm7qELQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 22.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: axGFVJ1krhsn6mC28ooKVA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 2M7SYVOfLnMuDXYnW8FfEQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: MS8ZruXv6pKGYFtg62uMpg_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: q57H2cmymr1Ixjb9MbCfPQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: EdEUoTTAcuM9cNcu08a1nw_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: NkjfX-IG5Qw8M_p_clCO4A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dInyxmFH1E4YJXjzmHFDHg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: cTPFfgZ4KkUXKHzMddF7Bg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 22.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1LGPz7B3vJ2IT1Qm_2nytw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: JpCaP2v70FtqJJGeXyjDdw_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: KP7OmYZuuX5T0O8CQGFFWg_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 15.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: KtvPeGrsVIBkeHq8DsJfhQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 2pj56we2AFhPUcV36gq4dw_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: yKjJVY-QcL8B72FWucki9A_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: X7F2k-IYYxWQONqJvKFAUA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 7 \n",
      "Item ID: D-QBRj4cortWyDiYEUHvsw_right\n",
      "Predicted Meter: 7.0\n",
      "Ground Truth: 6.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: b9NFY5tRuunJ3jBmVf7UBA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dGxsDZMbA6DXA4d1Pq0Bjg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: ZpIKRM0lVXkIYHKNeJ-PSw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 21.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 1C1eS9jrHwDToiIteIZqgQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 17.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: luxAA4b_ND2ueb7anI88BA_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 16.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Qy7K-TboLcgUyUupDtMgKQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mqpRUiJoeyjpoVAjiEiKMQ_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: cE0sa5qCriI6GUBYMcyKeg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 25.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 25.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: sw8Il_kg3VTkg4hfRAqhgg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: wNMjdSqgpzj6j72V6oMMUg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: C72ymm34PyRc2OruySafpQ_left\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 15.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: tL1cMj27xoKEUPU8emSdSQ_right\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 22.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 1KKSCQJLKYDDK3KSdFkHdw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: l7wQW6Nrj2lN4nrgHrVA0g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "Results saved to llava1.5_no_finetune.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the finetuned model.\n",
    "new_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-custom\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "\n",
    "print(\"=== Inference using the Finetuned Model ===\")\n",
    "df_default_train = run_inference_on_dataset(new_model, processor, test_json_path, image_root, \"llava1.5_no_finetune\")\n",
    "del new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b20142b-8d6b-44e3-916e-09a5bfa21725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Finetuned Model ===\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: ugebwzaohO3D7XbW343_qA_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 30.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: qz33ZhqXW5DY-2hPzv2CMQ_back\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 10.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 27.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: Tx4CWkxiDU1xV7-uZ6lLrw_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 8QVoY6NmGZBiZz1qi5irCQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: r-yGTE7GDoTFE49DyCJOQw_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: eC7O22NYV9d6KWGMa4vR7A_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mGq1XR8eBPbK9_J0gOAOlQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 8oe-e2AHXuj3E1JMMp7LUQ_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Aita8sR2NtHUJE-mmnR5eA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: UFsdG3hTkVymziyC-ZxMYQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: R9dD-rTZG17YN-mnL9kvpQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 28.0\n",
      "Error: 16.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: iGoMMW3J_lxftnHeOXACmA_front\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 24.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: YJHBrKidMhT7l8QarqnQiQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: Q5uPvNi_9o7WZoOzLpPs3A_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 25.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 2k_tvKZMASA2E5VbB0GaXQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: eQ-gEUsyOXA85uoFC-ftWQ_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 28.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: BCLppoUZzUo1hHwOXlMFdw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 24.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: -3SAmGjbIQXzZTfUtGeakw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: WSAWFRhBUpcfb5K_IyDjmQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 15.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ls5vsLksz2FGrtiX4pXcjw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: _G_-fkVxInuOL_gh1TCkAw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: KsAhdawvyYxlqfej-gzUsA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 11.0\n",
      "Error: 18.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: lIJcDFhNquz9zvnRLHqWbA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 72ebTpipZnU1ZlSBp2nSuQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: A3DdT3R0Me5Thr0jZ3vqbA_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: s8b27kdyBAl_sotzHJ5wYA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 1TTgoWtPcUDu1ii-0vUysA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: xNuPeVv3Ean47MOZXJzdgQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 17.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: IM5Tg5Vs_XNKPB0Y6bXQJA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: wnCjh-4PWBDlednovnwurQ_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 20.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: UQu9TdfMPsz6HgCBXwm_OA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: JralPklJ9gCp4EA_RyeWRA_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: M9wYWkddYwPsS8bOAAnVQA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3cTQXFxHQ4AaC7aogs4uKg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: rdd9lAv469KKItvAGNOOJg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: XIaYmJKv1Oh2TzOBENycvA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: DGpCRwXAFtuzOCxiC3AJXQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Z_0D8JCx3LqmbelS6LwBlg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pvgzxAkbpGBsYQInYsWhgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 2lGYlEsaQ03StY5XLBIJlQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: YSHVBBGad1bvL78FosZqIw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: eb8MU6EB-Ab6zkw8w6l07Q_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 22.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: LHSWcIZo86wt0-3Axz6h_g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: lUCB-zSdG5v8e7f6yo9hFw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: mc_oZOlXyr9sItAXp-EEFQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Qo2aUtgdEnZ96pkpYNEmAg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: W1GOhAzbdnwjlJ-RrP8UDg_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: lRA5rE4hSeIS8cLCmczXQw_right\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 11.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: TmAJ0zQ2uIyhpj81qDsyHg_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 23.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: OaoCpdsxh259v77mvTPhLQ_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: wc0EvjsWIVV8WUXMYA9u4Q_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5Rl3jytWkaTOiWLr7PDwdQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 21 \n",
      "Item ID: cf8_ef6XCqNOI3lj5KzjOA_right\n",
      "Predicted Meter: 21.0\n",
      "Ground Truth: 23.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: AWdJTbKEf5HBdRXHzGGC3A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: eJIgtiIzNQ7478dhnPH2lQ_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 28.0\n",
      "Error: 14.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Cx59xrGyKeRhAqomop17yg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: qn-fWttcGKIJ7Zc4c1pkqw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: zSP4L1e2ilC2jV9kuwrNaw_right\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 20.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: jbUqNAyorVVwMczpYlOnug_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: jfz76Ye8P1tRIX5j6Y_MFw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: d4hQ_xl8nHeMaP6R97uNgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: n8NSRWP5PY_ECNUo4guX3g_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: J0RU4yu-NC93sJo4XZ20qw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 9WZaNAcZKK0CG_6Ti6MOBw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: u9Kokx_8X1UHcThQufdKBQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 16.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: N32bZK7jAraafCM7dRXRVg_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: q4OI0Scwi1i0HkqRTAJKKA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 12.0\n",
      "Error: 17.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: hx5M3hRQSuMVV3BzCAegCg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3ixcETgziLCGAjvOEqWM7g_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: OArBY4CDcYgtKL89eIzkWw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: xb9LiT2Y_dUww_PC0NOLOQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 15.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: iib8V4vSPpts_FtmuxH4tg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: 6v1-hhiayJy7DoBpfpN6wA_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 18.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _vO63qpalTD-pyBTLFdy1g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: qq8iXTbkO_iEK4mJLC1xgA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: SIQOuGqlTXsiqwfDq6zoCg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: eRQ_lSJa8rZ3LFZ9s36v7A_back\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 12.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ODpq7KBrQltTE1PM9XsymA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Uo4CGPMzPzMx-A8Mjp6ziw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: a3CD8WKIaMh74X_w1hp7sQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: dcRWrKzhakwQYNJVjRTTDw_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 25.0\n",
      "Error: 13.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ggLlWlPCXTY3fRqkhBUoLw_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: I4dohtV49xeb159_Ng8Umw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: W-gBkV3CvuaiXTp8ypzwJA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: QrzepgRmPP6RvB-5DCKDOw_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 21.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: KuSK5cvU7kUtZVVnQmfMMQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: jn4zEaguUF85vtddS9591A_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 16.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: 2-FSObqDy2OGHRS-oLXpIA_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 9.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: KxKRZzRg654ggxD9Un5qhw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pvA1fuCApUKCE1EAb1Xgig_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: Rv3VUBBBNctDraTzS2RI3g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 26.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 19vgVzfNilUW-ZOFDTBU3w_left\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 19.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: sW81gMtDmZH5rH6dKD2Kgg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: e72VAs__5et9iblG7Jzbkg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: JBh4Q90EGzF9bfNWNEx_yQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: UK2rWp3Bd4YrFtzB7sqlvA_front\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _O0jxrZYJf_QSDnbrH3_2g_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Ym3CPMFWgLQgwLP7MoZerw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: 8naUjoF8o0pkX_YlDQHcCQ_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: P46zszgViyt-C8o6lET3Ow_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 3owL9LAboiuqRM_8xI8c5w_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: a4pv7J1rC3HwrnQWaugEAA_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 20.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pahz2YZlAB_f80CoGzLtSA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: aniYGD6kiz9Gtf0l-70f2Q_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: TTV6SfcooODCtltjtgSdSg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: vcaFbHdSXrGksEiMGrQLrQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dWF-5O9XfAEky8SiZKOgRg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: MPBnrxKHyNuVDqVLQuyG9g_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: k2YBj5MKBV4ZN_iwZ4aCEQ_back\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: QsUUe_r6kLQGpz0mMQJItQ_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 14.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: cAjf-qb2WlKMgLqdL9nDKg_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 20.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Z53S5bnyH7mNGBg_vJQcmA_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: k2bp2EYvD4dBPteB1oLO8A_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: F5BsVFC7xaJOKxCpu8yTPw_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 18.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: WwPPUkMasXt-Z4ABU64n5Q_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Y-tv1UuQOqcdTwdkKu3ynA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: WEoRVaCevfKMUZ-ZrcT7cg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: DvhPeyRQJhMg3UHrlbW2-w_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 22.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Q2OBeuPzC1Q72afMqUePsg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: JE2OCpze2DtiqLnRi5HHJg_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 16.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: vTWkIglCRmG2TnGkIFHM7Q_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: jvZukHq03jbMHllXrubKrg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 18.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: XW-9W9p2AVcQ77RIlngbtw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: cFIOqI5tHirjVFr43ORP9A_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 18.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 3bxRhzHjh-cWBHE3fS-JcA_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 19.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: 7XSkktf9ACvkRIyMeQc03Q_front\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 8.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: AT91nZn9t9ftyX4ZUaT7ig_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Rrfkhr-SlT5F6hHpq4CLPQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5Ey4TG-gAsmi1ua7pm6wkg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: Z4Mm-TnKHDlaZxWdKO_1hg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 19.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 5l1iitQtnhauPWpB68_jFQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 7FeZIFjcQAL-3ci60J3EFQ_left\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8HdhRsrE8MmqEgcq3vttxw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: JwmZvLLBilTA-5jI2gTazw_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 19.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: NqpFTRtqj2fUyQyQYhFSzQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Ce0tHCxNMDi6wPRp-s47jw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: nVAA5-GdotO9RbO9NjI-qw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: QrMeDQ9jdGJJ0rV2PVJEiw_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 20.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8pEZHqbN5u8_yG8_dfXbwg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 6-mgzznPhuvGSSjQkq6Jcw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 13.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Pfii6WqCwWdlp5FC-V4-tg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 8b9HdmvIET8ZzN25BPoAqg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 6 \n",
      "Item ID: XBZ7vig2eHnbKujbK0YrKw_right\n",
      "Predicted Meter: 6.0\n",
      "Ground Truth: 3.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 7ek2uD1SadiiO7S_CiCaFQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: zSYaKhsUunxd2HieLw--Bw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ooonkaHPxwqhujFUqM5pxw_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: euF84E5dXEqouOs2QXcQvw_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: sBvClBUQk7xVDK-zZ7cJsg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 24.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 6nJTO2TykG9p_u6nqNIDfw_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 30.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: vIIbBr4Zyvw5iE2qnXkDFw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: QjGIJdW81n-QPSYKVx9yeg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 28.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: Tn4uYOv0Lgp7BJQXxWgu0A_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 30.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: eK6GR-zlSKodjUThcJH4UA_left\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 18.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: MCsrah6QrlrSsMR4q-bdrg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: gyO5-qLWE4VT16crnReokw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: gcev0hxtltoqCuqDffc1Ig_left\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: QarynNyW6wNqfaYJwWl8mw_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 24.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: vqLP0uk2AgSU1smrbC9Kvg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 12.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: KcU4SrBPYpdOKOg1GG6tLQ_left\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 7.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: fq9dHETPobs-9ThuB39XIA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: De-ve_jLpQ2Qtp8TdV1B7w_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 0zUQyjBxNCgr2m5DcaFD7g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: 9aAQN3uUShfw9hrpyhlJPQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 19.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 23K2mFVzbr6lgTCY23RSyA_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: ZtEPmOuKRrXgxN530WjKcQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: MCT0I-phnpTIdJSHxPtY-g_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mgrFIGd_29iyc-W2Ss-5jw_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mlYvnxD8afYF5Nk-OF586Q_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: TiowKAVmIDB9vomUrCEavA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 5SVYauUAV9ZXo2j86RG9Nw_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: Hb7GT5BfydzVAky33nEYWw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 28.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: n_-sAWzo-dL9XYZ3UzaYqA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 8IFkUwxQ62DDv-tOHhqTQg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: t-ObecRVp4gxHXU-c2LqWA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 19.0\n",
      "Error: 10.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: yX3nYikBoHLy4CRAPIzBug_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: nwRZPegKQEcE9K_vk69Z9Q_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ysT0A7MmG8MHyY5MFjgfzg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: hUKSWoNyPXipTtKRMMVNpw_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: P11gxo_aHViVXuN2TI1OHg_back\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 20.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: yk32zNW_DJiLkXyl-tAW1Q_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: rn5P8mSyhi_XnmRqx6nBKQ_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: f6f84yNmkf8dSKmA1WLL7g_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 21.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 6rMd7Pu3dPDxfKH2hLr2cg_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the vending machine away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: gfnR0b6W1zb84NAfdD8sLQ_right\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 21.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: IC6kW3S7XTym0qyTt0JbHQ_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: dONIwocp2GAJUXZYYG83Kw_right\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jzPv_XRZOHrODSl7I9CQ3g_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 26.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: 3DIZja3YjsiL-kIvWohenw_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 26.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: fPyAVSl8mmbPEKbvzZXbtQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 18.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mjFLZisPjatDeki9c5acEg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 20.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: SA7K9gTIMdwmXDTsDcBM6Q_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 19.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: ELejaWw7AULkc0v0Of43yQ_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: bIHH-_IXF2ik1ynh9n06zQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mzltktb5OGPPKPAWlC_fCA_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 23.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: A9S-KxBLUmMgIGQZMvhxBw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: gmliVFMV0b8_cmZ-QyDEAQ_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 7gGp2SI0dsnSkN-JuQiesw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 25.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4UYo98GXL__fsXn5Hx4CPQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: QArcg6Bp7lO81QVYjAfhPg_front\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 16.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: O45aphvvSoBaD8agtIVz7w_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 21.0\n",
      "Error: 6.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: _nYEhvKAIDtrvoRFpCSuBQ_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: gLMnHJfMVfS176MkMVYWxA_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 24.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: uixXcPpyT06jWktX7LvdUg_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 2qEcuuJ-XtAJsGDEnh0VYg_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 18.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1CFhl2zw8_wpjV8SaYekZA_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 25.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: TrZtzGlvyG_QmyhBJBma4A_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: Y1OMmLWmRqjyAP7zn4TGNA_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 20.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: CzHuqJTBB29Mj10Tf-vG_A_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 3k16AWQgqv40UC3T2pxpRA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 25.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pksYc6IzkoN8GUhDj0LDpQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 9vadzEjIYIdbpVS1SXgiuA_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: 5NGOlsI3ydBDw0VOZ79c2A_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 24.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: 9jetR7KxoqyH2uA45eUhZA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 13.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the atm away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: fNup96_l6Q9_7sMN3jSYSA_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 17.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: StE2fFKWlxq5oOY9TLzqaQ_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 14.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: Qz18uRHUrVtSIBcwaI6big_right\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 26.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 7 \n",
      "Item ID: 1N4oepZ2Tdx0RiMNW70Emg_right\n",
      "Predicted Meter: 7.0\n",
      "Ground Truth: 7.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 12 \n",
      "Item ID: Wwz8TuQs25BR7pV6ZLxHIA_left\n",
      "Predicted Meter: 12.0\n",
      "Ground Truth: 21.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: w7E4-o_FBl46aJR4nygWKA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: EJyxn_BdvstB7aQW5qtXHA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: hPHfaOJAMuZoaAeHKwGt0Q_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 23.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Y2LqquXdxkG6CERz_G6Nlg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: VKDduK1sl3OF7ekMGjEI_Q_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 25.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: pVT3i-VC8DKKHxxGzGM1Gw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: QByx_5dPkZWspXNMrVlJCQ_left\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 28.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: sAX1efN-2Q1WTVF2Slt0Vg_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 16.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: B2xQQNnGkZTxyQWXhWUjjA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 18.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: PSXKhfo_2-cixnRnrkWgug_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 20.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 60vORc94qejRLoePlhyhoA_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 27.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: trCU9ky8rsxm4mMv4NGTxg_left\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: yqPszzxqxHCcIjL-v3WSWA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: LpCUToI7Cvgkq0ILdMjfqQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: h9fvBHcx4BJ4zNUEwixmOw_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: AJz20_6wSjeKoUZmfq-X2A_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 18.0\n",
      "Error: 11.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: i5WVC6hZreMrj25W7QzYRw_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 23.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ZdiVojc1dtotNExOp58x5A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 60vORc94qejRLoePlhyhoA_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 27.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 8vYyJMHE_ay2QBvq6RIX5g_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the electric charging station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: ycFZ9QwrUeciEE2HSrFAeQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 12.0\n",
      "Error: 17.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1Y7B1JQtBHVe2iPrAiM-eg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 23 \n",
      "Item ID: 7UXQIVV4UHo3-oDPm7qELQ_right\n",
      "Predicted Meter: 23.0\n",
      "Ground Truth: 22.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: axGFVJ1krhsn6mC28ooKVA_front\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 29.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 2M7SYVOfLnMuDXYnW8FfEQ_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 24.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 30.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: MS8ZruXv6pKGYFtg62uMpg_back\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 27.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: q57H2cmymr1Ixjb9MbCfPQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: EdEUoTTAcuM9cNcu08a1nw_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 19.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: NkjfX-IG5Qw8M_p_clCO4A_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dInyxmFH1E4YJXjzmHFDHg_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: cTPFfgZ4KkUXKHzMddF7Bg_left\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 22.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: 1LGPz7B3vJ2IT1Qm_2nytw_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 28 \n",
      "Item ID: JpCaP2v70FtqJJGeXyjDdw_front\n",
      "Predicted Meter: 28.0\n",
      "Ground Truth: 19.0\n",
      "Error: 9.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: KP7OmYZuuX5T0O8CQGFFWg_back\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 15.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: KtvPeGrsVIBkeHq8DsJfhQ_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 28.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 2pj56we2AFhPUcV36gq4dw_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 22.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 10 \n",
      "Item ID: yKjJVY-QcL8B72FWucki9A_back\n",
      "Predicted Meter: 10.0\n",
      "Ground Truth: 7.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: X7F2k-IYYxWQONqJvKFAUA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 26.0\n",
      "Error: 2.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 7 \n",
      "Item ID: D-QBRj4cortWyDiYEUHvsw_right\n",
      "Predicted Meter: 7.0\n",
      "Ground Truth: 6.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: b9NFY5tRuunJ3jBmVf7UBA_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 21.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: dGxsDZMbA6DXA4d1Pq0Bjg_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: ZpIKRM0lVXkIYHKNeJ-PSw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 24.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_right\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 21.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: 1C1eS9jrHwDToiIteIZqgQ_right\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 17.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the large waste dumpster away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: luxAA4b_ND2ueb7anI88BA_back\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 16.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_back\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 21.0\n",
      "Error: 8.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: Qy7K-TboLcgUyUupDtMgKQ_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 26.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: mqpRUiJoeyjpoVAjiEiKMQ_front\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 22.0\n",
      "Error: 7.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 20 \n",
      "Item ID: cE0sa5qCriI6GUBYMcyKeg_right\n",
      "Predicted Meter: 20.0\n",
      "Ground Truth: 25.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 22 \n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_back\n",
      "Predicted Meter: 22.0\n",
      "Ground Truth: 25.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 24 \n",
      "Item ID: sw8Il_kg3VTkg4hfRAqhgg_left\n",
      "Predicted Meter: 24.0\n",
      "Ground Truth: 29.0\n",
      "Error: 5.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: wNMjdSqgpzj6j72V6oMMUg_right\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 29.0\n",
      "Error: 0.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the post box away from the camera in meters, rounded to the next meter? ASSISTANT: 14 \n",
      "Item ID: C72ymm34PyRc2OruySafpQ_left\n",
      "Predicted Meter: 14.0\n",
      "Ground Truth: 15.0\n",
      "Error: 1.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 18 \n",
      "Item ID: tL1cMj27xoKEUPU8emSdSQ_right\n",
      "Predicted Meter: 18.0\n",
      "Ground Truth: 22.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 27 \n",
      "Item ID: 1KKSCQJLKYDDK3KSdFkHdw_right\n",
      "Predicted Meter: 27.0\n",
      "Ground Truth: 23.0\n",
      "Error: 4.0\n",
      "==================================================\n",
      "USER:  \n",
      "How far is the gas station away from the camera in meters, rounded to the next meter? ASSISTANT: 29 \n",
      "Item ID: l7wQW6Nrj2lN4nrgHrVA0g_left\n",
      "Predicted Meter: 29.0\n",
      "Ground Truth: 26.0\n",
      "Error: 3.0\n",
      "==================================================\n",
      "Results saved to res/llava1.5_finetune.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the finetuned model.\n",
    "new_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-custom\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "\n",
    "print(\"=== Inference using the Finetuned Model ===\")\n",
    "df_custom_train = run_inference_on_dataset(new_model, processor, test_json_path, image_root, \"llava1.5_finetune\")\n",
    "del new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729cdd9e-5aff-4e23-9155-655edae89617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:14<00:00,  4.82s/it]\n",
      "Loading adapter weights from /hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp led to unexpected keys not found in the model:  ['bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'regression_head.bias', 'regression_head.weight']. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Finetuned Model ===\n"
     ]
    }
   ],
   "source": [
    "# Load the finetuned model.\n",
    "new_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "\n",
    "print(\"=== Inference using the Finetuned Model ===\")\n",
    "#df_custom_train = run_inference_on_dataset(new_model, processor, test_json_path, image_root, \"inference_custom_finetune_exp\")\n",
    "#del new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a45558-615f-4d7f-ba3c-cc6a9e307450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlavaForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (k_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (o_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (up_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (down_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=11008, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51386e5b-2e1a-4333-afcb-41247f67349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlavaRegressionModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model  \n",
    "        self.regression_head = nn.Linear(4096, 1)\n",
    "        # Cast regression_head to the same dtype as the base model (likely float16)\n",
    "        self.regression_head = self.regression_head.to(next(base_model.parameters()).dtype)\n",
    "        \n",
    "        # Copy public attributes from base_model to self\n",
    "        for attr in dir(base_model):\n",
    "            if not attr.startswith('__') and not hasattr(self, attr):\n",
    "                try:\n",
    "                    setattr(self, attr, getattr(base_model, attr))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, pixel_values=None, **kwargs):\n",
    "        kwargs[\"output_hidden_states\"] = True\n",
    "        print(\"YES\")\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=pixel_values,\n",
    "            **kwargs\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        pooled = hidden_states.mean(dim=1)\n",
    "        regression_output = self.regression_head(pooled)\n",
    "        return regression_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc4e8bc-9bd6-41a4-876a-ebf9edc457cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_checkpoint(checkpoint):\n",
    "    new_checkpoint = {}\n",
    "    prefix_to_remove = \"base_model.model.\"\n",
    "    for key, value in checkpoint.items():\n",
    "        new_key = key\n",
    "        # Remove the prefix \"base_model.model.\" if present.\n",
    "        if new_key.startswith(prefix_to_remove):\n",
    "            new_key = new_key[len(prefix_to_remove):]\n",
    "        # Replace \"bruh_model\" with \"base_model\" at the beginning.\n",
    "        if new_key.startswith(\"bruh_model\"):\n",
    "            new_key = \"base_model\" + new_key[len(\"bruh_model\"):]\n",
    "        # Rename keys ending with \".weight\" to end with \".default.weight\"\n",
    "        # but skip keys that contain \"regression_head\".\n",
    "        if \"regression_head\" not in new_key and new_key.endswith(\".weight\") and not new_key.endswith(\".default.weight\"):\n",
    "            new_key = new_key[:-len(\".weight\")] + \".default.weight\"\n",
    "        new_checkpoint[new_key] = value\n",
    "    return new_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed6741d-cb75-445f-8450-9825bf86b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.39s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 11.38 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 31.42 GiB is allocated by PyTorch, and 9.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m finetuned_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m adapter_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test/adapter_model.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m old_model \u001b[38;5;241m=\u001b[39m \u001b[43mLlavaForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllava-hf/llava-1.5-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#low_cpu_mem_usage=True,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/hpi/fs00/scratch/liudvikas.zekas/.cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m---> 11\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m LlavaRegressionModel(old_model)\n\u001b[1;32m     15\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/modeling_utils.py:2958\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2954\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2955\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2957\u001b[0m         )\n\u001b[0;32m-> 2958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 903 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 11.38 MiB is free. Including non-PyTorch memory, this process has 31.72 GiB memory in use. Of the allocated memory 31.42 GiB is allocated by PyTorch, and 9.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test/adapter_model.safetensors\"\n",
    "\n",
    "old_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-1.5-7b-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #low_cpu_mem_usage=True,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "\n",
    "model = LlavaRegressionModel(old_model)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "finetuned_model = model.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7974ff3a-086b-4985-9e74-fb0a5a670e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp/checkpoint-1368'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp/checkpoint-1368'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllava-hf/llava-1.5-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m finetuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mLlavaForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinetuned_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Load the adapter checkpoint directly onto the GPU (cuda:0)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m adapter_checkpoint \u001b[38;5;241m=\u001b[39m load_file(adapter_model_path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/modeling_utils.py:3301\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3300\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 3301\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3311\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3316\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/utils/hub.py:469\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp/checkpoint-1368'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp/checkpoint-1368\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp/checkpoint-1368/adapter_model.safetensors\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)\n",
    "\n",
    "# Load the adapter checkpoint directly onto the GPU (cuda:0)\n",
    "adapter_checkpoint = load_file(adapter_model_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(adapter_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "remapped_checkpoint = remap_checkpoint(adapter_checkpoint)\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(remapped_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "regression_model = LlavaRegressionModel(finetuned_model)\n",
    "\n",
    "# Load the remapped state dict into the base model.\n",
    "regression_model.load_state_dict(remapped_checkpoint, strict=False)\n",
    "#regression_model.load_state_dict(adapter_checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04348f7-c4a5-459c-9663-ebac0f5a953e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys:\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "Checkpoint keys:\n",
      "language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_tower.vision_model.embeddings.class_embedding', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.pre_layrnorm.weight', 'vision_tower.vision_model.pre_layrnorm.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_tower.vision_model.post_layernorm.weight', 'vision_tower.vision_model.post_layernorm.bias', 'multi_modal_projector.linear_1.weight', 'multi_modal_projector.linear_1.bias', 'multi_modal_projector.linear_2.weight', 'multi_modal_projector.linear_2.bias', 'language_model.model.embed_tokens.weight', 'language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.0.input_layernorm.weight', 'language_model.model.layers.0.post_attention_layernorm.weight', 'language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.1.input_layernorm.weight', 'language_model.model.layers.1.post_attention_layernorm.weight', 'language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.2.input_layernorm.weight', 'language_model.model.layers.2.post_attention_layernorm.weight', 'language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.3.input_layernorm.weight', 'language_model.model.layers.3.post_attention_layernorm.weight', 'language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.4.input_layernorm.weight', 'language_model.model.layers.4.post_attention_layernorm.weight', 'language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.5.input_layernorm.weight', 'language_model.model.layers.5.post_attention_layernorm.weight', 'language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.6.input_layernorm.weight', 'language_model.model.layers.6.post_attention_layernorm.weight', 'language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.7.input_layernorm.weight', 'language_model.model.layers.7.post_attention_layernorm.weight', 'language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.8.input_layernorm.weight', 'language_model.model.layers.8.post_attention_layernorm.weight', 'language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.9.input_layernorm.weight', 'language_model.model.layers.9.post_attention_layernorm.weight', 'language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.10.input_layernorm.weight', 'language_model.model.layers.10.post_attention_layernorm.weight', 'language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.11.input_layernorm.weight', 'language_model.model.layers.11.post_attention_layernorm.weight', 'language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.12.input_layernorm.weight', 'language_model.model.layers.12.post_attention_layernorm.weight', 'language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.13.input_layernorm.weight', 'language_model.model.layers.13.post_attention_layernorm.weight', 'language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.14.input_layernorm.weight', 'language_model.model.layers.14.post_attention_layernorm.weight', 'language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.15.input_layernorm.weight', 'language_model.model.layers.15.post_attention_layernorm.weight', 'language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.16.input_layernorm.weight', 'language_model.model.layers.16.post_attention_layernorm.weight', 'language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.17.input_layernorm.weight', 'language_model.model.layers.17.post_attention_layernorm.weight', 'language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.18.input_layernorm.weight', 'language_model.model.layers.18.post_attention_layernorm.weight', 'language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.19.input_layernorm.weight', 'language_model.model.layers.19.post_attention_layernorm.weight', 'language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.20.input_layernorm.weight', 'language_model.model.layers.20.post_attention_layernorm.weight', 'language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.21.input_layernorm.weight', 'language_model.model.layers.21.post_attention_layernorm.weight', 'language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.22.input_layernorm.weight', 'language_model.model.layers.22.post_attention_layernorm.weight', 'language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.23.input_layernorm.weight', 'language_model.model.layers.23.post_attention_layernorm.weight', 'language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.24.input_layernorm.weight', 'language_model.model.layers.24.post_attention_layernorm.weight', 'language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.25.input_layernorm.weight', 'language_model.model.layers.25.post_attention_layernorm.weight', 'language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.26.input_layernorm.weight', 'language_model.model.layers.26.post_attention_layernorm.weight', 'language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.27.input_layernorm.weight', 'language_model.model.layers.27.post_attention_layernorm.weight', 'language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.28.input_layernorm.weight', 'language_model.model.layers.28.post_attention_layernorm.weight', 'language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.29.input_layernorm.weight', 'language_model.model.layers.29.post_attention_layernorm.weight', 'language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.30.input_layernorm.weight', 'language_model.model.layers.30.post_attention_layernorm.weight', 'language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.31.input_layernorm.weight', 'language_model.model.layers.31.post_attention_layernorm.weight', 'language_model.model.norm.weight', 'language_model.lm_head.weight'], unexpected_keys=['language_model.model.layers.0.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.weight'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False/adapter_model.safetensors\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)\n",
    "\n",
    "# Load the adapter checkpoint directly onto the GPU (cuda:0)\n",
    "adapter_checkpoint = load_file(adapter_model_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(adapter_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "remapped_checkpoint = remap_checkpoint(adapter_checkpoint)\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(remapped_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "# Load the remapped state dict into the base model.\n",
    "finetuned_model.load_state_dict(remapped_checkpoint, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6d7a3-f1aa-46a8-9dd2-d2aec7a125e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7723d351-b80e-46af-870c-18658fdaed46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys:\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False/adapter_model.safetensors\"\n",
    "\n",
    "# Load the adapter checkpoint directly onto the GPU (cuda:0)\n",
    "adapter_checkpoint = load_file(adapter_model_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(adapter_checkpoint.keys()):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b74bc89-3d6d-4047-aa90-d4a9fad71479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:08<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys:\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "Checkpoint keys:\n",
      "language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['vision_tower.vision_model.embeddings.class_embedding', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.pre_layrnorm.weight', 'vision_tower.vision_model.pre_layrnorm.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_tower.vision_model.post_layernorm.weight', 'vision_tower.vision_model.post_layernorm.bias', 'multi_modal_projector.linear_1.weight', 'multi_modal_projector.linear_1.bias', 'multi_modal_projector.linear_2.weight', 'multi_modal_projector.linear_2.bias', 'language_model.model.embed_tokens.weight', 'language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.0.input_layernorm.weight', 'language_model.model.layers.0.post_attention_layernorm.weight', 'language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.1.input_layernorm.weight', 'language_model.model.layers.1.post_attention_layernorm.weight', 'language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.2.input_layernorm.weight', 'language_model.model.layers.2.post_attention_layernorm.weight', 'language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.3.input_layernorm.weight', 'language_model.model.layers.3.post_attention_layernorm.weight', 'language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.4.input_layernorm.weight', 'language_model.model.layers.4.post_attention_layernorm.weight', 'language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.5.input_layernorm.weight', 'language_model.model.layers.5.post_attention_layernorm.weight', 'language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.6.input_layernorm.weight', 'language_model.model.layers.6.post_attention_layernorm.weight', 'language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.7.input_layernorm.weight', 'language_model.model.layers.7.post_attention_layernorm.weight', 'language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.8.input_layernorm.weight', 'language_model.model.layers.8.post_attention_layernorm.weight', 'language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.9.input_layernorm.weight', 'language_model.model.layers.9.post_attention_layernorm.weight', 'language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.10.input_layernorm.weight', 'language_model.model.layers.10.post_attention_layernorm.weight', 'language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.11.input_layernorm.weight', 'language_model.model.layers.11.post_attention_layernorm.weight', 'language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.12.input_layernorm.weight', 'language_model.model.layers.12.post_attention_layernorm.weight', 'language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.13.input_layernorm.weight', 'language_model.model.layers.13.post_attention_layernorm.weight', 'language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.14.input_layernorm.weight', 'language_model.model.layers.14.post_attention_layernorm.weight', 'language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.15.input_layernorm.weight', 'language_model.model.layers.15.post_attention_layernorm.weight', 'language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.16.input_layernorm.weight', 'language_model.model.layers.16.post_attention_layernorm.weight', 'language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.17.input_layernorm.weight', 'language_model.model.layers.17.post_attention_layernorm.weight', 'language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.18.input_layernorm.weight', 'language_model.model.layers.18.post_attention_layernorm.weight', 'language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.19.input_layernorm.weight', 'language_model.model.layers.19.post_attention_layernorm.weight', 'language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.20.input_layernorm.weight', 'language_model.model.layers.20.post_attention_layernorm.weight', 'language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.21.input_layernorm.weight', 'language_model.model.layers.21.post_attention_layernorm.weight', 'language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.22.input_layernorm.weight', 'language_model.model.layers.22.post_attention_layernorm.weight', 'language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.23.input_layernorm.weight', 'language_model.model.layers.23.post_attention_layernorm.weight', 'language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.24.input_layernorm.weight', 'language_model.model.layers.24.post_attention_layernorm.weight', 'language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.25.input_layernorm.weight', 'language_model.model.layers.25.post_attention_layernorm.weight', 'language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.26.input_layernorm.weight', 'language_model.model.layers.26.post_attention_layernorm.weight', 'language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.27.input_layernorm.weight', 'language_model.model.layers.27.post_attention_layernorm.weight', 'language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.28.input_layernorm.weight', 'language_model.model.layers.28.post_attention_layernorm.weight', 'language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.29.input_layernorm.weight', 'language_model.model.layers.29.post_attention_layernorm.weight', 'language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.30.input_layernorm.weight', 'language_model.model.layers.30.post_attention_layernorm.weight', 'language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.31.input_layernorm.weight', 'language_model.model.layers.31.post_attention_layernorm.weight', 'language_model.model.norm.weight', 'language_model.lm_head.weight'], unexpected_keys=['language_model.model.layers.0.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.weight'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False/adapter_model.safetensors\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)\n",
    "\n",
    "# Load the adapter checkpoint directly onto the GPU (cuda:0)\n",
    "adapter_checkpoint = load_file(adapter_model_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(adapter_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "remapped_checkpoint = remap_checkpoint(adapter_checkpoint)\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(remapped_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "# Load the remapped state dict into the base model.\n",
    "finetuned_model.load_state_dict(remapped_checkpoint, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28982dfb-6a36-45d4-9603-01b005864d07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:11<00:00,  3.84s/it]\n",
      "Loading adapter weights from /hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp led to unexpected keys not found in the model:  ['bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'regression_head.bias', 'regression_head.weight']. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys:\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.regression_head.bias\n",
      "base_model.model.regression_head.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight\n",
      "base_model.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight\n",
      "Checkpoint keys:\n",
      "bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight\n",
      "bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_B.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_A.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "regression_head.bias\n",
      "regression_head.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.vision_tower.vision_model.embeddings.class_embedding', 'base_model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'base_model.vision_tower.vision_model.embeddings.position_embedding.weight', 'base_model.vision_tower.vision_model.pre_layrnorm.weight', 'base_model.vision_tower.vision_model.pre_layrnorm.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'base_model.vision_tower.vision_model.post_layernorm.weight', 'base_model.vision_tower.vision_model.post_layernorm.bias', 'base_model.multi_modal_projector.linear_1.weight', 'base_model.multi_modal_projector.linear_1.bias', 'base_model.multi_modal_projector.linear_2.weight', 'base_model.multi_modal_projector.linear_2.bias', 'base_model.language_model.model.embed_tokens.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.input_layernorm.weight', 'base_model.language_model.model.layers.0.post_attention_layernorm.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.input_layernorm.weight', 'base_model.language_model.model.layers.1.post_attention_layernorm.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.input_layernorm.weight', 'base_model.language_model.model.layers.2.post_attention_layernorm.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.input_layernorm.weight', 'base_model.language_model.model.layers.3.post_attention_layernorm.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.input_layernorm.weight', 'base_model.language_model.model.layers.4.post_attention_layernorm.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.input_layernorm.weight', 'base_model.language_model.model.layers.5.post_attention_layernorm.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.input_layernorm.weight', 'base_model.language_model.model.layers.6.post_attention_layernorm.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.input_layernorm.weight', 'base_model.language_model.model.layers.7.post_attention_layernorm.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.input_layernorm.weight', 'base_model.language_model.model.layers.8.post_attention_layernorm.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.input_layernorm.weight', 'base_model.language_model.model.layers.9.post_attention_layernorm.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.input_layernorm.weight', 'base_model.language_model.model.layers.10.post_attention_layernorm.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.input_layernorm.weight', 'base_model.language_model.model.layers.11.post_attention_layernorm.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.input_layernorm.weight', 'base_model.language_model.model.layers.12.post_attention_layernorm.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.input_layernorm.weight', 'base_model.language_model.model.layers.13.post_attention_layernorm.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.input_layernorm.weight', 'base_model.language_model.model.layers.14.post_attention_layernorm.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.input_layernorm.weight', 'base_model.language_model.model.layers.15.post_attention_layernorm.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.input_layernorm.weight', 'base_model.language_model.model.layers.16.post_attention_layernorm.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.input_layernorm.weight', 'base_model.language_model.model.layers.17.post_attention_layernorm.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.input_layernorm.weight', 'base_model.language_model.model.layers.18.post_attention_layernorm.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.input_layernorm.weight', 'base_model.language_model.model.layers.19.post_attention_layernorm.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.input_layernorm.weight', 'base_model.language_model.model.layers.20.post_attention_layernorm.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.input_layernorm.weight', 'base_model.language_model.model.layers.21.post_attention_layernorm.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.input_layernorm.weight', 'base_model.language_model.model.layers.22.post_attention_layernorm.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.input_layernorm.weight', 'base_model.language_model.model.layers.23.post_attention_layernorm.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.input_layernorm.weight', 'base_model.language_model.model.layers.24.post_attention_layernorm.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.input_layernorm.weight', 'base_model.language_model.model.layers.25.post_attention_layernorm.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.input_layernorm.weight', 'base_model.language_model.model.layers.26.post_attention_layernorm.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.input_layernorm.weight', 'base_model.language_model.model.layers.27.post_attention_layernorm.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.input_layernorm.weight', 'base_model.language_model.model.layers.28.post_attention_layernorm.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.input_layernorm.weight', 'base_model.language_model.model.layers.29.post_attention_layernorm.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.input_layernorm.weight', 'base_model.language_model.model.layers.30.post_attention_layernorm.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.input_layernorm.weight', 'base_model.language_model.model.layers.31.post_attention_layernorm.weight', 'base_model.language_model.model.norm.weight', 'base_model.language_model.lm_head.weight', 'language_model.model.embed_tokens.weight', 'language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.0.input_layernorm.weight', 'language_model.model.layers.0.post_attention_layernorm.weight', 'language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.1.input_layernorm.weight', 'language_model.model.layers.1.post_attention_layernorm.weight', 'language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.2.input_layernorm.weight', 'language_model.model.layers.2.post_attention_layernorm.weight', 'language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.3.input_layernorm.weight', 'language_model.model.layers.3.post_attention_layernorm.weight', 'language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.4.input_layernorm.weight', 'language_model.model.layers.4.post_attention_layernorm.weight', 'language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.5.input_layernorm.weight', 'language_model.model.layers.5.post_attention_layernorm.weight', 'language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.6.input_layernorm.weight', 'language_model.model.layers.6.post_attention_layernorm.weight', 'language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.7.input_layernorm.weight', 'language_model.model.layers.7.post_attention_layernorm.weight', 'language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.8.input_layernorm.weight', 'language_model.model.layers.8.post_attention_layernorm.weight', 'language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.9.input_layernorm.weight', 'language_model.model.layers.9.post_attention_layernorm.weight', 'language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.10.input_layernorm.weight', 'language_model.model.layers.10.post_attention_layernorm.weight', 'language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.11.input_layernorm.weight', 'language_model.model.layers.11.post_attention_layernorm.weight', 'language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.12.input_layernorm.weight', 'language_model.model.layers.12.post_attention_layernorm.weight', 'language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.13.input_layernorm.weight', 'language_model.model.layers.13.post_attention_layernorm.weight', 'language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.14.input_layernorm.weight', 'language_model.model.layers.14.post_attention_layernorm.weight', 'language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.15.input_layernorm.weight', 'language_model.model.layers.15.post_attention_layernorm.weight', 'language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.16.input_layernorm.weight', 'language_model.model.layers.16.post_attention_layernorm.weight', 'language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.17.input_layernorm.weight', 'language_model.model.layers.17.post_attention_layernorm.weight', 'language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.18.input_layernorm.weight', 'language_model.model.layers.18.post_attention_layernorm.weight', 'language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.19.input_layernorm.weight', 'language_model.model.layers.19.post_attention_layernorm.weight', 'language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.20.input_layernorm.weight', 'language_model.model.layers.20.post_attention_layernorm.weight', 'language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.21.input_layernorm.weight', 'language_model.model.layers.21.post_attention_layernorm.weight', 'language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.22.input_layernorm.weight', 'language_model.model.layers.22.post_attention_layernorm.weight', 'language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.23.input_layernorm.weight', 'language_model.model.layers.23.post_attention_layernorm.weight', 'language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.24.input_layernorm.weight', 'language_model.model.layers.24.post_attention_layernorm.weight', 'language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.25.input_layernorm.weight', 'language_model.model.layers.25.post_attention_layernorm.weight', 'language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.26.input_layernorm.weight', 'language_model.model.layers.26.post_attention_layernorm.weight', 'language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.27.input_layernorm.weight', 'language_model.model.layers.27.post_attention_layernorm.weight', 'language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.28.input_layernorm.weight', 'language_model.model.layers.28.post_attention_layernorm.weight', 'language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.29.input_layernorm.weight', 'language_model.model.layers.29.post_attention_layernorm.weight', 'language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.30.input_layernorm.weight', 'language_model.model.layers.30.post_attention_layernorm.weight', 'language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'language_model.model.layers.31.input_layernorm.weight', 'language_model.model.layers.31.post_attention_layernorm.weight', 'language_model.model.norm.weight', 'language_model.lm_head.weight', 'multi_modal_projector.linear_1.weight', 'multi_modal_projector.linear_1.bias', 'multi_modal_projector.linear_2.weight', 'multi_modal_projector.linear_2.bias', 'vision_tower.vision_model.embeddings.class_embedding', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.pre_layrnorm.weight', 'vision_tower.vision_model.pre_layrnorm.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_tower.vision_model.post_layernorm.weight', 'vision_tower.vision_model.post_layernorm.bias'], unexpected_keys=['bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.0.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.0.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.0.mlp.up_proj.lora_A.weight', 'language_model.model.layers.0.mlp.up_proj.lora_B.weight', 'language_model.model.layers.0.mlp.down_proj.lora_A.weight', 'language_model.model.layers.0.mlp.down_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.1.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.1.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.1.mlp.up_proj.lora_A.weight', 'language_model.model.layers.1.mlp.up_proj.lora_B.weight', 'language_model.model.layers.1.mlp.down_proj.lora_A.weight', 'language_model.model.layers.1.mlp.down_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.2.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.2.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.2.mlp.up_proj.lora_A.weight', 'language_model.model.layers.2.mlp.up_proj.lora_B.weight', 'language_model.model.layers.2.mlp.down_proj.lora_A.weight', 'language_model.model.layers.2.mlp.down_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.3.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.3.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.3.mlp.up_proj.lora_A.weight', 'language_model.model.layers.3.mlp.up_proj.lora_B.weight', 'language_model.model.layers.3.mlp.down_proj.lora_A.weight', 'language_model.model.layers.3.mlp.down_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.4.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.4.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.4.mlp.up_proj.lora_A.weight', 'language_model.model.layers.4.mlp.up_proj.lora_B.weight', 'language_model.model.layers.4.mlp.down_proj.lora_A.weight', 'language_model.model.layers.4.mlp.down_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.5.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.5.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.5.mlp.up_proj.lora_A.weight', 'language_model.model.layers.5.mlp.up_proj.lora_B.weight', 'language_model.model.layers.5.mlp.down_proj.lora_A.weight', 'language_model.model.layers.5.mlp.down_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.6.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.6.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.6.mlp.up_proj.lora_A.weight', 'language_model.model.layers.6.mlp.up_proj.lora_B.weight', 'language_model.model.layers.6.mlp.down_proj.lora_A.weight', 'language_model.model.layers.6.mlp.down_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.7.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.7.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.7.mlp.up_proj.lora_A.weight', 'language_model.model.layers.7.mlp.up_proj.lora_B.weight', 'language_model.model.layers.7.mlp.down_proj.lora_A.weight', 'language_model.model.layers.7.mlp.down_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.8.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.8.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.8.mlp.up_proj.lora_A.weight', 'language_model.model.layers.8.mlp.up_proj.lora_B.weight', 'language_model.model.layers.8.mlp.down_proj.lora_A.weight', 'language_model.model.layers.8.mlp.down_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.9.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.9.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.9.mlp.up_proj.lora_A.weight', 'language_model.model.layers.9.mlp.up_proj.lora_B.weight', 'language_model.model.layers.9.mlp.down_proj.lora_A.weight', 'language_model.model.layers.9.mlp.down_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.10.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.10.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.10.mlp.up_proj.lora_A.weight', 'language_model.model.layers.10.mlp.up_proj.lora_B.weight', 'language_model.model.layers.10.mlp.down_proj.lora_A.weight', 'language_model.model.layers.10.mlp.down_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.11.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.11.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.11.mlp.up_proj.lora_A.weight', 'language_model.model.layers.11.mlp.up_proj.lora_B.weight', 'language_model.model.layers.11.mlp.down_proj.lora_A.weight', 'language_model.model.layers.11.mlp.down_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.12.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.12.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.12.mlp.up_proj.lora_A.weight', 'language_model.model.layers.12.mlp.up_proj.lora_B.weight', 'language_model.model.layers.12.mlp.down_proj.lora_A.weight', 'language_model.model.layers.12.mlp.down_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.13.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.13.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.13.mlp.up_proj.lora_A.weight', 'language_model.model.layers.13.mlp.up_proj.lora_B.weight', 'language_model.model.layers.13.mlp.down_proj.lora_A.weight', 'language_model.model.layers.13.mlp.down_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.14.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.14.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.14.mlp.up_proj.lora_A.weight', 'language_model.model.layers.14.mlp.up_proj.lora_B.weight', 'language_model.model.layers.14.mlp.down_proj.lora_A.weight', 'language_model.model.layers.14.mlp.down_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.15.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.15.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.15.mlp.up_proj.lora_A.weight', 'language_model.model.layers.15.mlp.up_proj.lora_B.weight', 'language_model.model.layers.15.mlp.down_proj.lora_A.weight', 'language_model.model.layers.15.mlp.down_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.16.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.16.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.16.mlp.up_proj.lora_A.weight', 'language_model.model.layers.16.mlp.up_proj.lora_B.weight', 'language_model.model.layers.16.mlp.down_proj.lora_A.weight', 'language_model.model.layers.16.mlp.down_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.17.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.17.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.17.mlp.up_proj.lora_A.weight', 'language_model.model.layers.17.mlp.up_proj.lora_B.weight', 'language_model.model.layers.17.mlp.down_proj.lora_A.weight', 'language_model.model.layers.17.mlp.down_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.18.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.18.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.18.mlp.up_proj.lora_A.weight', 'language_model.model.layers.18.mlp.up_proj.lora_B.weight', 'language_model.model.layers.18.mlp.down_proj.lora_A.weight', 'language_model.model.layers.18.mlp.down_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.19.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.19.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.19.mlp.up_proj.lora_A.weight', 'language_model.model.layers.19.mlp.up_proj.lora_B.weight', 'language_model.model.layers.19.mlp.down_proj.lora_A.weight', 'language_model.model.layers.19.mlp.down_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.20.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.20.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.20.mlp.up_proj.lora_A.weight', 'language_model.model.layers.20.mlp.up_proj.lora_B.weight', 'language_model.model.layers.20.mlp.down_proj.lora_A.weight', 'language_model.model.layers.20.mlp.down_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.21.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.21.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.21.mlp.up_proj.lora_A.weight', 'language_model.model.layers.21.mlp.up_proj.lora_B.weight', 'language_model.model.layers.21.mlp.down_proj.lora_A.weight', 'language_model.model.layers.21.mlp.down_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.22.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.22.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.22.mlp.up_proj.lora_A.weight', 'language_model.model.layers.22.mlp.up_proj.lora_B.weight', 'language_model.model.layers.22.mlp.down_proj.lora_A.weight', 'language_model.model.layers.22.mlp.down_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.23.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.23.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.23.mlp.up_proj.lora_A.weight', 'language_model.model.layers.23.mlp.up_proj.lora_B.weight', 'language_model.model.layers.23.mlp.down_proj.lora_A.weight', 'language_model.model.layers.23.mlp.down_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.24.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.24.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.24.mlp.up_proj.lora_A.weight', 'language_model.model.layers.24.mlp.up_proj.lora_B.weight', 'language_model.model.layers.24.mlp.down_proj.lora_A.weight', 'language_model.model.layers.24.mlp.down_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.25.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.25.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.25.mlp.up_proj.lora_A.weight', 'language_model.model.layers.25.mlp.up_proj.lora_B.weight', 'language_model.model.layers.25.mlp.down_proj.lora_A.weight', 'language_model.model.layers.25.mlp.down_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.26.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.26.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.26.mlp.up_proj.lora_A.weight', 'language_model.model.layers.26.mlp.up_proj.lora_B.weight', 'language_model.model.layers.26.mlp.down_proj.lora_A.weight', 'language_model.model.layers.26.mlp.down_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.27.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.27.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.27.mlp.up_proj.lora_A.weight', 'language_model.model.layers.27.mlp.up_proj.lora_B.weight', 'language_model.model.layers.27.mlp.down_proj.lora_A.weight', 'language_model.model.layers.27.mlp.down_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.28.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.28.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.28.mlp.up_proj.lora_A.weight', 'language_model.model.layers.28.mlp.up_proj.lora_B.weight', 'language_model.model.layers.28.mlp.down_proj.lora_A.weight', 'language_model.model.layers.28.mlp.down_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.29.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.29.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.29.mlp.up_proj.lora_A.weight', 'language_model.model.layers.29.mlp.up_proj.lora_B.weight', 'language_model.model.layers.29.mlp.down_proj.lora_A.weight', 'language_model.model.layers.29.mlp.down_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.30.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.30.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.30.mlp.up_proj.lora_A.weight', 'language_model.model.layers.30.mlp.up_proj.lora_B.weight', 'language_model.model.layers.30.mlp.down_proj.lora_A.weight', 'language_model.model.layers.30.mlp.down_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.q_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.k_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.v_proj.lora_B.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_A.weight', 'language_model.model.layers.31.self_attn.o_proj.lora_B.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_A.weight', 'language_model.model.layers.31.mlp.gate_proj.lora_B.weight', 'language_model.model.layers.31.mlp.up_proj.lora_A.weight', 'language_model.model.layers.31.mlp.up_proj.lora_B.weight', 'language_model.model.layers.31.mlp.down_proj.lora_A.weight', 'language_model.model.layers.31.mlp.down_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.weight'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp\"\n",
    "adapter_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-exp/adapter_model.safetensors\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)\n",
    "\n",
    "# Load the adapter checkpoint directly onto the GPU (cuda:0)\n",
    "adapter_checkpoint = load_file(adapter_model_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(adapter_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "remapped_checkpoint = remap_checkpoint(adapter_checkpoint)\n",
    "\n",
    "print(\"Checkpoint keys:\")\n",
    "for key in sorted(remapped_checkpoint.keys()):\n",
    "    print(key)\n",
    "\n",
    "regression_model = LlavaRegressionModel(finetuned_model).to(0)\n",
    "\n",
    "# Load the remapped state dict into the base model.\n",
    "regression_model.load_state_dict(remapped_checkpoint, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "271887c4-f514-40a9-a31d-eb433963faaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded keys:\n",
      "base_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "regression_head.bias\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "\n",
      "Missing keys:\n",
      "['base_model.vision_tower.vision_model.embeddings.class_embedding', 'base_model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'base_model.vision_tower.vision_model.embeddings.position_embedding.weight', 'base_model.vision_tower.vision_model.pre_layrnorm.weight', 'base_model.vision_tower.vision_model.pre_layrnorm.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.bias', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'base_model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'base_model.vision_tower.vision_model.post_layernorm.weight', 'base_model.vision_tower.vision_model.post_layernorm.bias', 'base_model.multi_modal_projector.linear_1.weight', 'base_model.multi_modal_projector.linear_1.bias', 'base_model.multi_modal_projector.linear_2.weight', 'base_model.multi_modal_projector.linear_2.bias', 'base_model.language_model.model.embed_tokens.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.0.input_layernorm.weight', 'base_model.language_model.model.layers.0.post_attention_layernorm.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.1.input_layernorm.weight', 'base_model.language_model.model.layers.1.post_attention_layernorm.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.2.input_layernorm.weight', 'base_model.language_model.model.layers.2.post_attention_layernorm.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.3.input_layernorm.weight', 'base_model.language_model.model.layers.3.post_attention_layernorm.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.4.input_layernorm.weight', 'base_model.language_model.model.layers.4.post_attention_layernorm.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.5.input_layernorm.weight', 'base_model.language_model.model.layers.5.post_attention_layernorm.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.6.input_layernorm.weight', 'base_model.language_model.model.layers.6.post_attention_layernorm.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.7.input_layernorm.weight', 'base_model.language_model.model.layers.7.post_attention_layernorm.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.8.input_layernorm.weight', 'base_model.language_model.model.layers.8.post_attention_layernorm.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.9.input_layernorm.weight', 'base_model.language_model.model.layers.9.post_attention_layernorm.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.10.input_layernorm.weight', 'base_model.language_model.model.layers.10.post_attention_layernorm.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.11.input_layernorm.weight', 'base_model.language_model.model.layers.11.post_attention_layernorm.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.12.input_layernorm.weight', 'base_model.language_model.model.layers.12.post_attention_layernorm.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.13.input_layernorm.weight', 'base_model.language_model.model.layers.13.post_attention_layernorm.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.14.input_layernorm.weight', 'base_model.language_model.model.layers.14.post_attention_layernorm.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.15.input_layernorm.weight', 'base_model.language_model.model.layers.15.post_attention_layernorm.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.16.input_layernorm.weight', 'base_model.language_model.model.layers.16.post_attention_layernorm.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.17.input_layernorm.weight', 'base_model.language_model.model.layers.17.post_attention_layernorm.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.18.input_layernorm.weight', 'base_model.language_model.model.layers.18.post_attention_layernorm.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.19.input_layernorm.weight', 'base_model.language_model.model.layers.19.post_attention_layernorm.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.20.input_layernorm.weight', 'base_model.language_model.model.layers.20.post_attention_layernorm.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.21.input_layernorm.weight', 'base_model.language_model.model.layers.21.post_attention_layernorm.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.22.input_layernorm.weight', 'base_model.language_model.model.layers.22.post_attention_layernorm.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.23.input_layernorm.weight', 'base_model.language_model.model.layers.23.post_attention_layernorm.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.24.input_layernorm.weight', 'base_model.language_model.model.layers.24.post_attention_layernorm.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.25.input_layernorm.weight', 'base_model.language_model.model.layers.25.post_attention_layernorm.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.26.input_layernorm.weight', 'base_model.language_model.model.layers.26.post_attention_layernorm.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.27.input_layernorm.weight', 'base_model.language_model.model.layers.27.post_attention_layernorm.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.28.input_layernorm.weight', 'base_model.language_model.model.layers.28.post_attention_layernorm.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.29.input_layernorm.weight', 'base_model.language_model.model.layers.29.post_attention_layernorm.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.30.input_layernorm.weight', 'base_model.language_model.model.layers.30.post_attention_layernorm.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'base_model.language_model.model.layers.31.input_layernorm.weight', 'base_model.language_model.model.layers.31.post_attention_layernorm.weight', 'base_model.language_model.model.norm.weight', 'base_model.language_model.lm_head.weight', 'regression_head.weight', 'language_model.model.embed_tokens.weight', 'language_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.0.mlp.up_proj.base_layer.weight', 'language_model.model.layers.0.mlp.down_proj.base_layer.weight', 'language_model.model.layers.0.input_layernorm.weight', 'language_model.model.layers.0.post_attention_layernorm.weight', 'language_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.1.mlp.up_proj.base_layer.weight', 'language_model.model.layers.1.mlp.down_proj.base_layer.weight', 'language_model.model.layers.1.input_layernorm.weight', 'language_model.model.layers.1.post_attention_layernorm.weight', 'language_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.2.mlp.up_proj.base_layer.weight', 'language_model.model.layers.2.mlp.down_proj.base_layer.weight', 'language_model.model.layers.2.input_layernorm.weight', 'language_model.model.layers.2.post_attention_layernorm.weight', 'language_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.3.mlp.up_proj.base_layer.weight', 'language_model.model.layers.3.mlp.down_proj.base_layer.weight', 'language_model.model.layers.3.input_layernorm.weight', 'language_model.model.layers.3.post_attention_layernorm.weight', 'language_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.4.mlp.up_proj.base_layer.weight', 'language_model.model.layers.4.mlp.down_proj.base_layer.weight', 'language_model.model.layers.4.input_layernorm.weight', 'language_model.model.layers.4.post_attention_layernorm.weight', 'language_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.5.mlp.up_proj.base_layer.weight', 'language_model.model.layers.5.mlp.down_proj.base_layer.weight', 'language_model.model.layers.5.input_layernorm.weight', 'language_model.model.layers.5.post_attention_layernorm.weight', 'language_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.6.mlp.up_proj.base_layer.weight', 'language_model.model.layers.6.mlp.down_proj.base_layer.weight', 'language_model.model.layers.6.input_layernorm.weight', 'language_model.model.layers.6.post_attention_layernorm.weight', 'language_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.7.mlp.up_proj.base_layer.weight', 'language_model.model.layers.7.mlp.down_proj.base_layer.weight', 'language_model.model.layers.7.input_layernorm.weight', 'language_model.model.layers.7.post_attention_layernorm.weight', 'language_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.8.mlp.up_proj.base_layer.weight', 'language_model.model.layers.8.mlp.down_proj.base_layer.weight', 'language_model.model.layers.8.input_layernorm.weight', 'language_model.model.layers.8.post_attention_layernorm.weight', 'language_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.9.mlp.up_proj.base_layer.weight', 'language_model.model.layers.9.mlp.down_proj.base_layer.weight', 'language_model.model.layers.9.input_layernorm.weight', 'language_model.model.layers.9.post_attention_layernorm.weight', 'language_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.10.mlp.up_proj.base_layer.weight', 'language_model.model.layers.10.mlp.down_proj.base_layer.weight', 'language_model.model.layers.10.input_layernorm.weight', 'language_model.model.layers.10.post_attention_layernorm.weight', 'language_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.11.mlp.up_proj.base_layer.weight', 'language_model.model.layers.11.mlp.down_proj.base_layer.weight', 'language_model.model.layers.11.input_layernorm.weight', 'language_model.model.layers.11.post_attention_layernorm.weight', 'language_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.12.mlp.up_proj.base_layer.weight', 'language_model.model.layers.12.mlp.down_proj.base_layer.weight', 'language_model.model.layers.12.input_layernorm.weight', 'language_model.model.layers.12.post_attention_layernorm.weight', 'language_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.13.mlp.up_proj.base_layer.weight', 'language_model.model.layers.13.mlp.down_proj.base_layer.weight', 'language_model.model.layers.13.input_layernorm.weight', 'language_model.model.layers.13.post_attention_layernorm.weight', 'language_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.14.mlp.up_proj.base_layer.weight', 'language_model.model.layers.14.mlp.down_proj.base_layer.weight', 'language_model.model.layers.14.input_layernorm.weight', 'language_model.model.layers.14.post_attention_layernorm.weight', 'language_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.15.mlp.up_proj.base_layer.weight', 'language_model.model.layers.15.mlp.down_proj.base_layer.weight', 'language_model.model.layers.15.input_layernorm.weight', 'language_model.model.layers.15.post_attention_layernorm.weight', 'language_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.16.mlp.up_proj.base_layer.weight', 'language_model.model.layers.16.mlp.down_proj.base_layer.weight', 'language_model.model.layers.16.input_layernorm.weight', 'language_model.model.layers.16.post_attention_layernorm.weight', 'language_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.17.mlp.up_proj.base_layer.weight', 'language_model.model.layers.17.mlp.down_proj.base_layer.weight', 'language_model.model.layers.17.input_layernorm.weight', 'language_model.model.layers.17.post_attention_layernorm.weight', 'language_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.18.mlp.up_proj.base_layer.weight', 'language_model.model.layers.18.mlp.down_proj.base_layer.weight', 'language_model.model.layers.18.input_layernorm.weight', 'language_model.model.layers.18.post_attention_layernorm.weight', 'language_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.19.mlp.up_proj.base_layer.weight', 'language_model.model.layers.19.mlp.down_proj.base_layer.weight', 'language_model.model.layers.19.input_layernorm.weight', 'language_model.model.layers.19.post_attention_layernorm.weight', 'language_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.20.mlp.up_proj.base_layer.weight', 'language_model.model.layers.20.mlp.down_proj.base_layer.weight', 'language_model.model.layers.20.input_layernorm.weight', 'language_model.model.layers.20.post_attention_layernorm.weight', 'language_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.21.mlp.up_proj.base_layer.weight', 'language_model.model.layers.21.mlp.down_proj.base_layer.weight', 'language_model.model.layers.21.input_layernorm.weight', 'language_model.model.layers.21.post_attention_layernorm.weight', 'language_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.22.mlp.up_proj.base_layer.weight', 'language_model.model.layers.22.mlp.down_proj.base_layer.weight', 'language_model.model.layers.22.input_layernorm.weight', 'language_model.model.layers.22.post_attention_layernorm.weight', 'language_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.23.mlp.up_proj.base_layer.weight', 'language_model.model.layers.23.mlp.down_proj.base_layer.weight', 'language_model.model.layers.23.input_layernorm.weight', 'language_model.model.layers.23.post_attention_layernorm.weight', 'language_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.24.mlp.up_proj.base_layer.weight', 'language_model.model.layers.24.mlp.down_proj.base_layer.weight', 'language_model.model.layers.24.input_layernorm.weight', 'language_model.model.layers.24.post_attention_layernorm.weight', 'language_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.25.mlp.up_proj.base_layer.weight', 'language_model.model.layers.25.mlp.down_proj.base_layer.weight', 'language_model.model.layers.25.input_layernorm.weight', 'language_model.model.layers.25.post_attention_layernorm.weight', 'language_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.26.mlp.up_proj.base_layer.weight', 'language_model.model.layers.26.mlp.down_proj.base_layer.weight', 'language_model.model.layers.26.input_layernorm.weight', 'language_model.model.layers.26.post_attention_layernorm.weight', 'language_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.27.mlp.up_proj.base_layer.weight', 'language_model.model.layers.27.mlp.down_proj.base_layer.weight', 'language_model.model.layers.27.input_layernorm.weight', 'language_model.model.layers.27.post_attention_layernorm.weight', 'language_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.28.mlp.up_proj.base_layer.weight', 'language_model.model.layers.28.mlp.down_proj.base_layer.weight', 'language_model.model.layers.28.input_layernorm.weight', 'language_model.model.layers.28.post_attention_layernorm.weight', 'language_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.29.mlp.up_proj.base_layer.weight', 'language_model.model.layers.29.mlp.down_proj.base_layer.weight', 'language_model.model.layers.29.input_layernorm.weight', 'language_model.model.layers.29.post_attention_layernorm.weight', 'language_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.30.mlp.up_proj.base_layer.weight', 'language_model.model.layers.30.mlp.down_proj.base_layer.weight', 'language_model.model.layers.30.input_layernorm.weight', 'language_model.model.layers.30.post_attention_layernorm.weight', 'language_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'language_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'language_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'language_model.model.layers.31.mlp.up_proj.base_layer.weight', 'language_model.model.layers.31.mlp.down_proj.base_layer.weight', 'language_model.model.layers.31.input_layernorm.weight', 'language_model.model.layers.31.post_attention_layernorm.weight', 'language_model.model.norm.weight', 'language_model.lm_head.weight', 'multi_modal_projector.linear_1.weight', 'multi_modal_projector.linear_1.bias', 'multi_modal_projector.linear_2.weight', 'multi_modal_projector.linear_2.bias', 'vision_tower.vision_model.embeddings.class_embedding', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.pre_layrnorm.weight', 'vision_tower.vision_model.pre_layrnorm.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.12.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.13.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.14.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.15.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.16.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.17.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.18.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.19.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.20.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.21.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.22.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc1.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.weight', 'vision_tower.vision_model.encoder.layers.23.mlp.fc2.base_layer.bias', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vision_tower.vision_model.post_layernorm.weight', 'vision_tower.vision_model.post_layernorm.bias']\n",
      "\n",
      "Unexpected keys in the checkpoint:\n",
      "['regression_head.default.weight']\n"
     ]
    }
   ],
   "source": [
    "# Load the regression head state dict and capture the result.\n",
    "incompat_keys = regression_model.load_state_dict(remapped_checkpoint, strict=False)\n",
    "\n",
    "# Get all keys expected by the regression head.\n",
    "expected_keys = set(regression_model.state_dict().keys())\n",
    "\n",
    "# The keys that were successfully loaded are those that are in expected_keys but not in missing_keys.\n",
    "loaded_keys = expected_keys - set(incompat_keys.missing_keys)\n",
    "\n",
    "print(\"Successfully loaded keys:\")\n",
    "for key in sorted(loaded_keys):\n",
    "    print(key)\n",
    "\n",
    "print(\"\\nMissing keys:\")\n",
    "print(incompat_keys.missing_keys)\n",
    "\n",
    "print(\"\\nUnexpected keys in the checkpoint:\")\n",
    "print(incompat_keys.unexpected_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf608800-c586-4438-82e7-b3a6f20092e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0031,  0.0051,  0.0101,  ..., -0.0048, -0.0114, -0.0093]],\n",
       "       dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.regression_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a2d5ce3-7d42-41e1-8bbf-e508f672ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "del finetuned_model\n",
    "del regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8129de7f-31f3-46f1-9c10-a389772a3702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:03<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlavaForConditionalGeneration(\n",
      "  (vision_tower): CLIPVisionModel(\n",
      "    (vision_model): CLIPVisionTransformer(\n",
      "      (embeddings): CLIPVisionEmbeddings(\n",
      "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "        (position_embedding): Embedding(577, 1024)\n",
      "      )\n",
      "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder): CLIPEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x CLIPEncoderLayer(\n",
      "            (self_attn): CLIPSdpaAttention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): CLIPMLP(\n",
      "              (activation_fn): QuickGELUActivation()\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (multi_modal_projector): LlavaMultiModalProjector(\n",
      "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELUActivation()\n",
      "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaSdpaAttention(\n",
      "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from /hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test led to unexpected keys not found in the model:  ['base_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight']. \n",
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/modeling_utils.py:4779: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3733]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.373291015625\n",
      "Item ID: ugebwzaohO3D7XbW343_qA_back\n",
      "Predicted Meter: 0.373291015625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.626708984375\n",
      "==================================================\n",
      "tensor([[0.7969]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.796875\n",
      "Item ID: qz33ZhqXW5DY-2hPzv2CMQ_back\n",
      "Predicted Meter: 0.796875\n",
      "Ground Truth: 10.0\n",
      "Error: 9.203125\n",
      "==================================================\n",
      "tensor([[0.4827]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.482666015625\n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_right\n",
      "Predicted Meter: 0.482666015625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.517333984375\n",
      "==================================================\n",
      "tensor([[0.1749]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.1749267578125\n",
      "Item ID: Tx4CWkxiDU1xV7-uZ6lLrw_right\n",
      "Predicted Meter: 0.1749267578125\n",
      "Ground Truth: 25.0\n",
      "Error: 24.8250732421875\n",
      "==================================================\n",
      "tensor([[0.5581]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55810546875\n",
      "Item ID: 8QVoY6NmGZBiZz1qi5irCQ_left\n",
      "Predicted Meter: 0.55810546875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.44189453125\n",
      "==================================================\n",
      "tensor([[0.8188]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.81884765625\n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 0.81884765625\n",
      "Ground Truth: 24.0\n",
      "Error: 23.18115234375\n",
      "==================================================\n",
      "tensor([[0.4827]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.482666015625\n",
      "Item ID: r-yGTE7GDoTFE49DyCJOQw_front\n",
      "Predicted Meter: 0.482666015625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.517333984375\n",
      "==================================================\n",
      "tensor([[0.4373]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.437255859375\n",
      "Item ID: eC7O22NYV9d6KWGMa4vR7A_front\n",
      "Predicted Meter: 0.437255859375\n",
      "Ground Truth: 21.0\n",
      "Error: 20.562744140625\n",
      "==================================================\n",
      "tensor([[0.3916]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.3916015625\n",
      "Item ID: mGq1XR8eBPbK9_J0gOAOlQ_back\n",
      "Predicted Meter: 0.3916015625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.6083984375\n",
      "==================================================\n",
      "tensor([[0.3188]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.31884765625\n",
      "Item ID: 8oe-e2AHXuj3E1JMMp7LUQ_back\n",
      "Predicted Meter: 0.31884765625\n",
      "Ground Truth: 20.0\n",
      "Error: 19.68115234375\n",
      "==================================================\n",
      "tensor([[0.4995]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.49951171875\n",
      "Item ID: Aita8sR2NtHUJE-mmnR5eA_right\n",
      "Predicted Meter: 0.49951171875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.50048828125\n",
      "==================================================\n",
      "tensor([[0.3164]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.31640625\n",
      "Item ID: UFsdG3hTkVymziyC-ZxMYQ_left\n",
      "Predicted Meter: 0.31640625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.68359375\n",
      "==================================================\n",
      "tensor([[0.3142]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.314208984375\n",
      "Item ID: R9dD-rTZG17YN-mnL9kvpQ_right\n",
      "Predicted Meter: 0.314208984375\n",
      "Ground Truth: 28.0\n",
      "Error: 27.685791015625\n",
      "==================================================\n",
      "tensor([[0.3391]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.339111328125\n",
      "Item ID: iGoMMW3J_lxftnHeOXACmA_front\n",
      "Predicted Meter: 0.339111328125\n",
      "Ground Truth: 24.0\n",
      "Error: 23.660888671875\n",
      "==================================================\n",
      "tensor([[0.5825]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.58251953125\n",
      "Item ID: YJHBrKidMhT7l8QarqnQiQ_right\n",
      "Predicted Meter: 0.58251953125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.41748046875\n",
      "==================================================\n",
      "tensor([[0.2052]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2052001953125\n",
      "Item ID: Q5uPvNi_9o7WZoOzLpPs3A_right\n",
      "Predicted Meter: 0.2052001953125\n",
      "Ground Truth: 25.0\n",
      "Error: 24.7947998046875\n",
      "==================================================\n",
      "tensor([[0.3225]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.322509765625\n",
      "Item ID: 2k_tvKZMASA2E5VbB0GaXQ_back\n",
      "Predicted Meter: 0.322509765625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.677490234375\n",
      "==================================================\n",
      "tensor([[0.4006]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.400634765625\n",
      "Item ID: eQ-gEUsyOXA85uoFC-ftWQ_right\n",
      "Predicted Meter: 0.400634765625\n",
      "Ground Truth: 28.0\n",
      "Error: 27.599365234375\n",
      "==================================================\n",
      "tensor([[0.4446]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.444580078125\n",
      "Item ID: BCLppoUZzUo1hHwOXlMFdw_right\n",
      "Predicted Meter: 0.444580078125\n",
      "Ground Truth: 24.0\n",
      "Error: 23.555419921875\n",
      "==================================================\n",
      "tensor([[0.1669]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.1668701171875\n",
      "Item ID: -3SAmGjbIQXzZTfUtGeakw_right\n",
      "Predicted Meter: 0.1668701171875\n",
      "Ground Truth: 22.0\n",
      "Error: 21.8331298828125\n",
      "==================================================\n",
      "tensor([[-0.0570]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: -0.056976318359375\n",
      "Item ID: WSAWFRhBUpcfb5K_IyDjmQ_right\n",
      "Predicted Meter: -0.056976318359375\n",
      "Ground Truth: 15.0\n",
      "Error: 15.056976318359375\n",
      "==================================================\n",
      "tensor([[0.5889]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5888671875\n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_back\n",
      "Predicted Meter: 0.5888671875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.4111328125\n",
      "==================================================\n",
      "tensor([[0.4924]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.492431640625\n",
      "Item ID: ls5vsLksz2FGrtiX4pXcjw_back\n",
      "Predicted Meter: 0.492431640625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.507568359375\n",
      "==================================================\n",
      "tensor([[0.4646]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.464599609375\n",
      "Item ID: _G_-fkVxInuOL_gh1TCkAw_right\n",
      "Predicted Meter: 0.464599609375\n",
      "Ground Truth: 19.0\n",
      "Error: 18.535400390625\n",
      "==================================================\n",
      "tensor([[0.4023]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.40234375\n",
      "Item ID: KsAhdawvyYxlqfej-gzUsA_front\n",
      "Predicted Meter: 0.40234375\n",
      "Ground Truth: 11.0\n",
      "Error: 10.59765625\n",
      "==================================================\n",
      "tensor([[0.6846]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6845703125\n",
      "Item ID: lIJcDFhNquz9zvnRLHqWbA_back\n",
      "Predicted Meter: 0.6845703125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.3154296875\n",
      "==================================================\n",
      "tensor([[0.3770]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.376953125\n",
      "Item ID: 72ebTpipZnU1ZlSBp2nSuQ_right\n",
      "Predicted Meter: 0.376953125\n",
      "Ground Truth: 23.0\n",
      "Error: 22.623046875\n",
      "==================================================\n",
      "tensor([[0.5146]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5146484375\n",
      "Item ID: A3DdT3R0Me5Thr0jZ3vqbA_right\n",
      "Predicted Meter: 0.5146484375\n",
      "Ground Truth: 21.0\n",
      "Error: 20.4853515625\n",
      "==================================================\n",
      "tensor([[0.8721]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.8720703125\n",
      "Item ID: s8b27kdyBAl_sotzHJ5wYA_right\n",
      "Predicted Meter: 0.8720703125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.1279296875\n",
      "==================================================\n",
      "tensor([[0.3931]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.39306640625\n",
      "Item ID: 1TTgoWtPcUDu1ii-0vUysA_right\n",
      "Predicted Meter: 0.39306640625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.60693359375\n",
      "==================================================\n",
      "tensor([[0.5312]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.53125\n",
      "Item ID: xNuPeVv3Ean47MOZXJzdgQ_left\n",
      "Predicted Meter: 0.53125\n",
      "Ground Truth: 17.0\n",
      "Error: 16.46875\n",
      "==================================================\n",
      "tensor([[0.5610]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.56103515625\n",
      "Item ID: IM5Tg5Vs_XNKPB0Y6bXQJA_right\n",
      "Predicted Meter: 0.56103515625\n",
      "Ground Truth: 24.0\n",
      "Error: 23.43896484375\n",
      "==================================================\n",
      "tensor([[0.1643]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.164306640625\n",
      "Item ID: wnCjh-4PWBDlednovnwurQ_front\n",
      "Predicted Meter: 0.164306640625\n",
      "Ground Truth: 20.0\n",
      "Error: 19.835693359375\n",
      "==================================================\n",
      "tensor([[0.3289]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.328857421875\n",
      "Item ID: UQu9TdfMPsz6HgCBXwm_OA_right\n",
      "Predicted Meter: 0.328857421875\n",
      "Ground Truth: 28.0\n",
      "Error: 27.671142578125\n",
      "==================================================\n",
      "tensor([[0.4202]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.420166015625\n",
      "Item ID: JralPklJ9gCp4EA_RyeWRA_front\n",
      "Predicted Meter: 0.420166015625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.579833984375\n",
      "==================================================\n",
      "tensor([[0.3479]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.347900390625\n",
      "Item ID: M9wYWkddYwPsS8bOAAnVQA_front\n",
      "Predicted Meter: 0.347900390625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.652099609375\n",
      "==================================================\n",
      "tensor([[0.5176]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.517578125\n",
      "Item ID: 3cTQXFxHQ4AaC7aogs4uKg_front\n",
      "Predicted Meter: 0.517578125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.482421875\n",
      "==================================================\n",
      "tensor([[0.4927]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.49267578125\n",
      "Item ID: rdd9lAv469KKItvAGNOOJg_right\n",
      "Predicted Meter: 0.49267578125\n",
      "Ground Truth: 25.0\n",
      "Error: 24.50732421875\n",
      "==================================================\n",
      "tensor([[0.3218]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.32177734375\n",
      "Item ID: XIaYmJKv1Oh2TzOBENycvA_right\n",
      "Predicted Meter: 0.32177734375\n",
      "Ground Truth: 28.0\n",
      "Error: 27.67822265625\n",
      "==================================================\n",
      "tensor([[0.4707]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.470703125\n",
      "Item ID: DGpCRwXAFtuzOCxiC3AJXQ_right\n",
      "Predicted Meter: 0.470703125\n",
      "Ground Truth: 20.0\n",
      "Error: 19.529296875\n",
      "==================================================\n",
      "tensor([[0.5439]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5439453125\n",
      "Item ID: Z_0D8JCx3LqmbelS6LwBlg_right\n",
      "Predicted Meter: 0.5439453125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.4560546875\n",
      "==================================================\n",
      "tensor([[0.6763]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.67626953125\n",
      "Item ID: pvgzxAkbpGBsYQInYsWhgg_right\n",
      "Predicted Meter: 0.67626953125\n",
      "Ground Truth: 27.0\n",
      "Error: 26.32373046875\n",
      "==================================================\n",
      "tensor([[0.4673]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.46728515625\n",
      "Item ID: 2lGYlEsaQ03StY5XLBIJlQ_right\n",
      "Predicted Meter: 0.46728515625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.53271484375\n",
      "==================================================\n",
      "tensor([[0.5342]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5341796875\n",
      "Item ID: YSHVBBGad1bvL78FosZqIw_left\n",
      "Predicted Meter: 0.5341796875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.4658203125\n",
      "==================================================\n",
      "tensor([[0.5205]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5205078125\n",
      "Item ID: eb8MU6EB-Ab6zkw8w6l07Q_right\n",
      "Predicted Meter: 0.5205078125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.4794921875\n",
      "==================================================\n",
      "tensor([[0.5820]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.58203125\n",
      "Item ID: LHSWcIZo86wt0-3Axz6h_g_right\n",
      "Predicted Meter: 0.58203125\n",
      "Ground Truth: 20.0\n",
      "Error: 19.41796875\n",
      "==================================================\n",
      "tensor([[0.5801]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.580078125\n",
      "Item ID: lUCB-zSdG5v8e7f6yo9hFw_right\n",
      "Predicted Meter: 0.580078125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.419921875\n",
      "==================================================\n",
      "tensor([[0.7935]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.79345703125\n",
      "Item ID: mc_oZOlXyr9sItAXp-EEFQ_right\n",
      "Predicted Meter: 0.79345703125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.20654296875\n",
      "==================================================\n",
      "tensor([[0.4341]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.43408203125\n",
      "Item ID: Qo2aUtgdEnZ96pkpYNEmAg_front\n",
      "Predicted Meter: 0.43408203125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.56591796875\n",
      "==================================================\n",
      "tensor([[0.2476]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.24755859375\n",
      "Item ID: W1GOhAzbdnwjlJ-RrP8UDg_back\n",
      "Predicted Meter: 0.24755859375\n",
      "Ground Truth: 21.0\n",
      "Error: 20.75244140625\n",
      "==================================================\n",
      "tensor([[0.4407]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.440673828125\n",
      "Item ID: lRA5rE4hSeIS8cLCmczXQw_right\n",
      "Predicted Meter: 0.440673828125\n",
      "Ground Truth: 11.0\n",
      "Error: 10.559326171875\n",
      "==================================================\n",
      "tensor([[0.4287]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4287109375\n",
      "Item ID: TmAJ0zQ2uIyhpj81qDsyHg_right\n",
      "Predicted Meter: 0.4287109375\n",
      "Ground Truth: 23.0\n",
      "Error: 22.5712890625\n",
      "==================================================\n",
      "tensor([[0.3916]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.3916015625\n",
      "Item ID: OaoCpdsxh259v77mvTPhLQ_front\n",
      "Predicted Meter: 0.3916015625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.6083984375\n",
      "==================================================\n",
      "tensor([[0.3755]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.37548828125\n",
      "Item ID: wc0EvjsWIVV8WUXMYA9u4Q_left\n",
      "Predicted Meter: 0.37548828125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.62451171875\n",
      "==================================================\n",
      "tensor([[0.5737]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.57373046875\n",
      "Item ID: 5Rl3jytWkaTOiWLr7PDwdQ_left\n",
      "Predicted Meter: 0.57373046875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.42626953125\n",
      "==================================================\n",
      "tensor([[0.5415]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.54150390625\n",
      "Item ID: cf8_ef6XCqNOI3lj5KzjOA_right\n",
      "Predicted Meter: 0.54150390625\n",
      "Ground Truth: 23.0\n",
      "Error: 22.45849609375\n",
      "==================================================\n",
      "tensor([[0.3125]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.3125\n",
      "Item ID: AWdJTbKEf5HBdRXHzGGC3A_left\n",
      "Predicted Meter: 0.3125\n",
      "Ground Truth: 24.0\n",
      "Error: 23.6875\n",
      "==================================================\n",
      "tensor([[0.3127]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.312744140625\n",
      "Item ID: eJIgtiIzNQ7478dhnPH2lQ_back\n",
      "Predicted Meter: 0.312744140625\n",
      "Ground Truth: 28.0\n",
      "Error: 27.687255859375\n",
      "==================================================\n",
      "tensor([[0.6099]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.60986328125\n",
      "Item ID: Cx59xrGyKeRhAqomop17yg_left\n",
      "Predicted Meter: 0.60986328125\n",
      "Ground Truth: 25.0\n",
      "Error: 24.39013671875\n",
      "==================================================\n",
      "tensor([[0.5464]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.54638671875\n",
      "Item ID: qn-fWttcGKIJ7Zc4c1pkqw_left\n",
      "Predicted Meter: 0.54638671875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.45361328125\n",
      "==================================================\n",
      "tensor([[0.3989]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.39892578125\n",
      "Item ID: zSP4L1e2ilC2jV9kuwrNaw_right\n",
      "Predicted Meter: 0.39892578125\n",
      "Ground Truth: 20.0\n",
      "Error: 19.60107421875\n",
      "==================================================\n",
      "tensor([[0.4956]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.49560546875\n",
      "Item ID: jbUqNAyorVVwMczpYlOnug_left\n",
      "Predicted Meter: 0.49560546875\n",
      "Ground Truth: 7.0\n",
      "Error: 6.50439453125\n",
      "==================================================\n",
      "tensor([[0.7222]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.72216796875\n",
      "Item ID: jfz76Ye8P1tRIX5j6Y_MFw_left\n",
      "Predicted Meter: 0.72216796875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.27783203125\n",
      "==================================================\n",
      "tensor([[0.8271]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.8271484375\n",
      "Item ID: d4hQ_xl8nHeMaP6R97uNgg_right\n",
      "Predicted Meter: 0.8271484375\n",
      "Ground Truth: 25.0\n",
      "Error: 24.1728515625\n",
      "==================================================\n",
      "tensor([[0.3784]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.37841796875\n",
      "Item ID: n8NSRWP5PY_ECNUo4guX3g_right\n",
      "Predicted Meter: 0.37841796875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.62158203125\n",
      "==================================================\n",
      "tensor([[0.4670]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.467041015625\n",
      "Item ID: J0RU4yu-NC93sJo4XZ20qw_back\n",
      "Predicted Meter: 0.467041015625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.532958984375\n",
      "==================================================\n",
      "tensor([[0.4973]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.497314453125\n",
      "Item ID: 9WZaNAcZKK0CG_6Ti6MOBw_front\n",
      "Predicted Meter: 0.497314453125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.502685546875\n",
      "==================================================\n",
      "tensor([[0.2030]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2030029296875\n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_back\n",
      "Predicted Meter: 0.2030029296875\n",
      "Ground Truth: 28.0\n",
      "Error: 27.7969970703125\n",
      "==================================================\n",
      "tensor([[0.7476]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.74755859375\n",
      "Item ID: u9Kokx_8X1UHcThQufdKBQ_right\n",
      "Predicted Meter: 0.74755859375\n",
      "Ground Truth: 16.0\n",
      "Error: 15.25244140625\n",
      "==================================================\n",
      "tensor([[0.5664]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.56640625\n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_right\n",
      "Predicted Meter: 0.56640625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.43359375\n",
      "==================================================\n",
      "tensor([[0.4248]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4248046875\n",
      "Item ID: N32bZK7jAraafCM7dRXRVg_front\n",
      "Predicted Meter: 0.4248046875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.5751953125\n",
      "==================================================\n",
      "tensor([[0.3210]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.321044921875\n",
      "Item ID: q4OI0Scwi1i0HkqRTAJKKA_front\n",
      "Predicted Meter: 0.321044921875\n",
      "Ground Truth: 12.0\n",
      "Error: 11.678955078125\n",
      "==================================================\n",
      "tensor([[0.4846]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.484619140625\n",
      "Item ID: hx5M3hRQSuMVV3BzCAegCg_left\n",
      "Predicted Meter: 0.484619140625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.515380859375\n",
      "==================================================\n",
      "tensor([[0.5820]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.58203125\n",
      "Item ID: 3ixcETgziLCGAjvOEqWM7g_back\n",
      "Predicted Meter: 0.58203125\n",
      "Ground Truth: 23.0\n",
      "Error: 22.41796875\n",
      "==================================================\n",
      "tensor([[0.7168]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.716796875\n",
      "Item ID: OArBY4CDcYgtKL89eIzkWw_right\n",
      "Predicted Meter: 0.716796875\n",
      "Ground Truth: 18.0\n",
      "Error: 17.283203125\n",
      "==================================================\n",
      "tensor([[0.3569]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.35693359375\n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_back\n",
      "Predicted Meter: 0.35693359375\n",
      "Ground Truth: 18.0\n",
      "Error: 17.64306640625\n",
      "==================================================\n",
      "tensor([[0.6802]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.68017578125\n",
      "Item ID: xb9LiT2Y_dUww_PC0NOLOQ_right\n",
      "Predicted Meter: 0.68017578125\n",
      "Ground Truth: 15.0\n",
      "Error: 14.31982421875\n",
      "==================================================\n",
      "tensor([[0.5840]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.583984375\n",
      "Item ID: iib8V4vSPpts_FtmuxH4tg_right\n",
      "Predicted Meter: 0.583984375\n",
      "Ground Truth: 30.0\n",
      "Error: 29.416015625\n",
      "==================================================\n",
      "tensor([[0.4929]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.492919921875\n",
      "Item ID: 6v1-hhiayJy7DoBpfpN6wA_front\n",
      "Predicted Meter: 0.492919921875\n",
      "Ground Truth: 18.0\n",
      "Error: 17.507080078125\n",
      "==================================================\n",
      "tensor([[0.3083]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.308349609375\n",
      "Item ID: _vO63qpalTD-pyBTLFdy1g_left\n",
      "Predicted Meter: 0.308349609375\n",
      "Ground Truth: 25.0\n",
      "Error: 24.691650390625\n",
      "==================================================\n",
      "tensor([[0.5981]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.59814453125\n",
      "Item ID: qq8iXTbkO_iEK4mJLC1xgA_right\n",
      "Predicted Meter: 0.59814453125\n",
      "Ground Truth: 30.0\n",
      "Error: 29.40185546875\n",
      "==================================================\n",
      "tensor([[0.4866]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.486572265625\n",
      "Item ID: SIQOuGqlTXsiqwfDq6zoCg_back\n",
      "Predicted Meter: 0.486572265625\n",
      "Ground Truth: 20.0\n",
      "Error: 19.513427734375\n",
      "==================================================\n",
      "tensor([[0.3293]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.329345703125\n",
      "Item ID: eRQ_lSJa8rZ3LFZ9s36v7A_back\n",
      "Predicted Meter: 0.329345703125\n",
      "Ground Truth: 12.0\n",
      "Error: 11.670654296875\n",
      "==================================================\n",
      "tensor([[0.6270]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.626953125\n",
      "Item ID: ODpq7KBrQltTE1PM9XsymA_right\n",
      "Predicted Meter: 0.626953125\n",
      "Ground Truth: 27.0\n",
      "Error: 26.373046875\n",
      "==================================================\n",
      "tensor([[0.5542]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55419921875\n",
      "Item ID: JtyeoGH-BUUewIwbHElEew_back\n",
      "Predicted Meter: 0.55419921875\n",
      "Ground Truth: 22.0\n",
      "Error: 21.44580078125\n",
      "==================================================\n",
      "tensor([[0.5518]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5517578125\n",
      "Item ID: Uo4CGPMzPzMx-A8Mjp6ziw_left\n",
      "Predicted Meter: 0.5517578125\n",
      "Ground Truth: 25.0\n",
      "Error: 24.4482421875\n",
      "==================================================\n",
      "tensor([[0.5845]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.58447265625\n",
      "Item ID: a3CD8WKIaMh74X_w1hp7sQ_right\n",
      "Predicted Meter: 0.58447265625\n",
      "Ground Truth: 28.0\n",
      "Error: 27.41552734375\n",
      "==================================================\n",
      "tensor([[0.2307]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.230712890625\n",
      "Item ID: dcRWrKzhakwQYNJVjRTTDw_left\n",
      "Predicted Meter: 0.230712890625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.769287109375\n",
      "==================================================\n",
      "tensor([[0.5332]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.533203125\n",
      "Item ID: ggLlWlPCXTY3fRqkhBUoLw_back\n",
      "Predicted Meter: 0.533203125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.466796875\n",
      "==================================================\n",
      "tensor([[0.7046]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.70458984375\n",
      "Item ID: I4dohtV49xeb159_Ng8Umw_left\n",
      "Predicted Meter: 0.70458984375\n",
      "Ground Truth: 27.0\n",
      "Error: 26.29541015625\n",
      "==================================================\n",
      "tensor([[0.5752]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5751953125\n",
      "Item ID: W-gBkV3CvuaiXTp8ypzwJA_left\n",
      "Predicted Meter: 0.5751953125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.4248046875\n",
      "==================================================\n",
      "tensor([[0.3066]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.306640625\n",
      "Item ID: QrzepgRmPP6RvB-5DCKDOw_right\n",
      "Predicted Meter: 0.306640625\n",
      "Ground Truth: 21.0\n",
      "Error: 20.693359375\n",
      "==================================================\n",
      "tensor([[0.4153]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.415283203125\n",
      "Item ID: KuSK5cvU7kUtZVVnQmfMMQ_right\n",
      "Predicted Meter: 0.415283203125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.584716796875\n",
      "==================================================\n",
      "tensor([[0.3003]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.30029296875\n",
      "Item ID: jn4zEaguUF85vtddS9591A_front\n",
      "Predicted Meter: 0.30029296875\n",
      "Ground Truth: 16.0\n",
      "Error: 15.69970703125\n",
      "==================================================\n",
      "tensor([[0.5005]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.50048828125\n",
      "Item ID: 2-FSObqDy2OGHRS-oLXpIA_front\n",
      "Predicted Meter: 0.50048828125\n",
      "Ground Truth: 9.0\n",
      "Error: 8.49951171875\n",
      "==================================================\n",
      "tensor([[0.4500]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.449951171875\n",
      "Item ID: KxKRZzRg654ggxD9Un5qhw_right\n",
      "Predicted Meter: 0.449951171875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.550048828125\n",
      "==================================================\n",
      "tensor([[0.2886]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.28857421875\n",
      "Item ID: pvA1fuCApUKCE1EAb1Xgig_back\n",
      "Predicted Meter: 0.28857421875\n",
      "Ground Truth: 30.0\n",
      "Error: 29.71142578125\n",
      "==================================================\n",
      "tensor([[0.3875]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.387451171875\n",
      "Item ID: z3ndUO5NBsQdcR6Onfs8kw_front\n",
      "Predicted Meter: 0.387451171875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.612548828125\n",
      "==================================================\n",
      "tensor([[0.5396]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.53955078125\n",
      "Item ID: Rv3VUBBBNctDraTzS2RI3g_right\n",
      "Predicted Meter: 0.53955078125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.46044921875\n",
      "==================================================\n",
      "tensor([[0.3745]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.37451171875\n",
      "Item ID: 19vgVzfNilUW-ZOFDTBU3w_left\n",
      "Predicted Meter: 0.37451171875\n",
      "Ground Truth: 19.0\n",
      "Error: 18.62548828125\n",
      "==================================================\n",
      "tensor([[0.4873]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4873046875\n",
      "Item ID: sW81gMtDmZH5rH6dKD2Kgg_right\n",
      "Predicted Meter: 0.4873046875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.5126953125\n",
      "==================================================\n",
      "tensor([[0.1602]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.16015625\n",
      "Item ID: e72VAs__5et9iblG7Jzbkg_front\n",
      "Predicted Meter: 0.16015625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.83984375\n",
      "==================================================\n",
      "tensor([[0.3398]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.33984375\n",
      "Item ID: JBh4Q90EGzF9bfNWNEx_yQ_right\n",
      "Predicted Meter: 0.33984375\n",
      "Ground Truth: 25.0\n",
      "Error: 24.66015625\n",
      "==================================================\n",
      "tensor([[0.5415]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.54150390625\n",
      "Item ID: UK2rWp3Bd4YrFtzB7sqlvA_front\n",
      "Predicted Meter: 0.54150390625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.45849609375\n",
      "==================================================\n",
      "tensor([[0.5322]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5322265625\n",
      "Item ID: _O0jxrZYJf_QSDnbrH3_2g_front\n",
      "Predicted Meter: 0.5322265625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.4677734375\n",
      "==================================================\n",
      "tensor([[0.6479]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.64794921875\n",
      "Item ID: Ym3CPMFWgLQgwLP7MoZerw_right\n",
      "Predicted Meter: 0.64794921875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.35205078125\n",
      "==================================================\n",
      "tensor([[0.1193]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.11932373046875\n",
      "Item ID: 8naUjoF8o0pkX_YlDQHcCQ_left\n",
      "Predicted Meter: 0.11932373046875\n",
      "Ground Truth: 7.0\n",
      "Error: 6.88067626953125\n",
      "==================================================\n",
      "tensor([[0.6514]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6513671875\n",
      "Item ID: P46zszgViyt-C8o6lET3Ow_left\n",
      "Predicted Meter: 0.6513671875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.3486328125\n",
      "==================================================\n",
      "tensor([[0.5562]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55615234375\n",
      "Item ID: 3owL9LAboiuqRM_8xI8c5w_left\n",
      "Predicted Meter: 0.55615234375\n",
      "Ground Truth: 29.0\n",
      "Error: 28.44384765625\n",
      "==================================================\n",
      "tensor([[0.4382]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.438232421875\n",
      "Item ID: a4pv7J1rC3HwrnQWaugEAA_left\n",
      "Predicted Meter: 0.438232421875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.561767578125\n",
      "==================================================\n",
      "tensor([[0.6270]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.626953125\n",
      "Item ID: pahz2YZlAB_f80CoGzLtSA_left\n",
      "Predicted Meter: 0.626953125\n",
      "Ground Truth: 30.0\n",
      "Error: 29.373046875\n",
      "==================================================\n",
      "tensor([[0.5869]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5869140625\n",
      "Item ID: aniYGD6kiz9Gtf0l-70f2Q_left\n",
      "Predicted Meter: 0.5869140625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.4130859375\n",
      "==================================================\n",
      "tensor([[0.7144]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.71435546875\n",
      "Item ID: TTV6SfcooODCtltjtgSdSg_left\n",
      "Predicted Meter: 0.71435546875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.28564453125\n",
      "==================================================\n",
      "tensor([[0.5229]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52294921875\n",
      "Item ID: vcaFbHdSXrGksEiMGrQLrQ_right\n",
      "Predicted Meter: 0.52294921875\n",
      "Ground Truth: 21.0\n",
      "Error: 20.47705078125\n",
      "==================================================\n",
      "tensor([[0.4297]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4296875\n",
      "Item ID: dWF-5O9XfAEky8SiZKOgRg_front\n",
      "Predicted Meter: 0.4296875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.5703125\n",
      "==================================================\n",
      "tensor([[0.4617]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.461669921875\n",
      "Item ID: MPBnrxKHyNuVDqVLQuyG9g_front\n",
      "Predicted Meter: 0.461669921875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.538330078125\n",
      "==================================================\n",
      "tensor([[0.5298]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52978515625\n",
      "Item ID: k2YBj5MKBV4ZN_iwZ4aCEQ_back\n",
      "Predicted Meter: 0.52978515625\n",
      "Ground Truth: 13.0\n",
      "Error: 12.47021484375\n",
      "==================================================\n",
      "tensor([[0.5039]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.50390625\n",
      "Item ID: QsUUe_r6kLQGpz0mMQJItQ_back\n",
      "Predicted Meter: 0.50390625\n",
      "Ground Truth: 14.0\n",
      "Error: 13.49609375\n",
      "==================================================\n",
      "tensor([[0.4363]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.436279296875\n",
      "Item ID: cAjf-qb2WlKMgLqdL9nDKg_back\n",
      "Predicted Meter: 0.436279296875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.563720703125\n",
      "==================================================\n",
      "tensor([[0.5698]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.56982421875\n",
      "Item ID: Z53S5bnyH7mNGBg_vJQcmA_left\n",
      "Predicted Meter: 0.56982421875\n",
      "Ground Truth: 23.0\n",
      "Error: 22.43017578125\n",
      "==================================================\n",
      "tensor([[0.6978]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.69775390625\n",
      "Item ID: k2bp2EYvD4dBPteB1oLO8A_right\n",
      "Predicted Meter: 0.69775390625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.30224609375\n",
      "==================================================\n",
      "tensor([[0.3950]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.39501953125\n",
      "Item ID: F5BsVFC7xaJOKxCpu8yTPw_right\n",
      "Predicted Meter: 0.39501953125\n",
      "Ground Truth: 18.0\n",
      "Error: 17.60498046875\n",
      "==================================================\n",
      "tensor([[0.4932]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4931640625\n",
      "Item ID: WwPPUkMasXt-Z4ABU64n5Q_left\n",
      "Predicted Meter: 0.4931640625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.5068359375\n",
      "==================================================\n",
      "tensor([[0.4204]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.42041015625\n",
      "Item ID: Y-tv1UuQOqcdTwdkKu3ynA_back\n",
      "Predicted Meter: 0.42041015625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.57958984375\n",
      "==================================================\n",
      "tensor([[0.4343]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.434326171875\n",
      "Item ID: WEoRVaCevfKMUZ-ZrcT7cg_front\n",
      "Predicted Meter: 0.434326171875\n",
      "Ground Truth: 30.0\n",
      "Error: 29.565673828125\n",
      "==================================================\n",
      "tensor([[0.6406]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.640625\n",
      "Item ID: DvhPeyRQJhMg3UHrlbW2-w_right\n",
      "Predicted Meter: 0.640625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.359375\n",
      "==================================================\n",
      "tensor([[0.4487]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.44873046875\n",
      "Item ID: Q2OBeuPzC1Q72afMqUePsg_front\n",
      "Predicted Meter: 0.44873046875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.55126953125\n",
      "==================================================\n",
      "tensor([[0.4224]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.42236328125\n",
      "Item ID: JE2OCpze2DtiqLnRi5HHJg_right\n",
      "Predicted Meter: 0.42236328125\n",
      "Ground Truth: 16.0\n",
      "Error: 15.57763671875\n",
      "==================================================\n",
      "tensor([[0.2223]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2222900390625\n",
      "Item ID: vTWkIglCRmG2TnGkIFHM7Q_front\n",
      "Predicted Meter: 0.2222900390625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.7777099609375\n",
      "==================================================\n",
      "tensor([[0.5059]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.505859375\n",
      "Item ID: jvZukHq03jbMHllXrubKrg_left\n",
      "Predicted Meter: 0.505859375\n",
      "Ground Truth: 18.0\n",
      "Error: 17.494140625\n",
      "==================================================\n",
      "tensor([[0.2329]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.23291015625\n",
      "Item ID: XW-9W9p2AVcQ77RIlngbtw_right\n",
      "Predicted Meter: 0.23291015625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.76708984375\n",
      "==================================================\n",
      "tensor([[0.3933]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.393310546875\n",
      "Item ID: cFIOqI5tHirjVFr43ORP9A_front\n",
      "Predicted Meter: 0.393310546875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.606689453125\n",
      "==================================================\n",
      "tensor([[0.3613]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.361328125\n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_front\n",
      "Predicted Meter: 0.361328125\n",
      "Ground Truth: 18.0\n",
      "Error: 17.638671875\n",
      "==================================================\n",
      "tensor([[0.4424]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4423828125\n",
      "Item ID: 3bxRhzHjh-cWBHE3fS-JcA_right\n",
      "Predicted Meter: 0.4423828125\n",
      "Ground Truth: 19.0\n",
      "Error: 18.5576171875\n",
      "==================================================\n",
      "tensor([[0.4150]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4150390625\n",
      "Item ID: 7XSkktf9ACvkRIyMeQc03Q_front\n",
      "Predicted Meter: 0.4150390625\n",
      "Ground Truth: 8.0\n",
      "Error: 7.5849609375\n",
      "==================================================\n",
      "tensor([[0.6025]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6025390625\n",
      "Item ID: AT91nZn9t9ftyX4ZUaT7ig_back\n",
      "Predicted Meter: 0.6025390625\n",
      "Ground Truth: 19.0\n",
      "Error: 18.3974609375\n",
      "==================================================\n",
      "tensor([[0.5298]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52978515625\n",
      "Item ID: Rrfkhr-SlT5F6hHpq4CLPQ_right\n",
      "Predicted Meter: 0.52978515625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.47021484375\n",
      "==================================================\n",
      "tensor([[0.5249]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52490234375\n",
      "Item ID: 5Ey4TG-gAsmi1ua7pm6wkg_front\n",
      "Predicted Meter: 0.52490234375\n",
      "Ground Truth: 24.0\n",
      "Error: 23.47509765625\n",
      "==================================================\n",
      "tensor([[0.6494]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6494140625\n",
      "Item ID: Z4Mm-TnKHDlaZxWdKO_1hg_right\n",
      "Predicted Meter: 0.6494140625\n",
      "Ground Truth: 19.0\n",
      "Error: 18.3505859375\n",
      "==================================================\n",
      "tensor([[0.5771]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5771484375\n",
      "Item ID: 5l1iitQtnhauPWpB68_jFQ_left\n",
      "Predicted Meter: 0.5771484375\n",
      "Ground Truth: 27.0\n",
      "Error: 26.4228515625\n",
      "==================================================\n",
      "tensor([[0.3306]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.33056640625\n",
      "Item ID: 7FeZIFjcQAL-3ci60J3EFQ_left\n",
      "Predicted Meter: 0.33056640625\n",
      "Ground Truth: 21.0\n",
      "Error: 20.66943359375\n",
      "==================================================\n",
      "tensor([[0.5879]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.587890625\n",
      "Item ID: 8HdhRsrE8MmqEgcq3vttxw_right\n",
      "Predicted Meter: 0.587890625\n",
      "Ground Truth: 28.0\n",
      "Error: 27.412109375\n",
      "==================================================\n",
      "tensor([[0.4971]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4970703125\n",
      "Item ID: JwmZvLLBilTA-5jI2gTazw_front\n",
      "Predicted Meter: 0.4970703125\n",
      "Ground Truth: 19.0\n",
      "Error: 18.5029296875\n",
      "==================================================\n",
      "tensor([[0.2788]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.27880859375\n",
      "Item ID: NqpFTRtqj2fUyQyQYhFSzQ_right\n",
      "Predicted Meter: 0.27880859375\n",
      "Ground Truth: 29.0\n",
      "Error: 28.72119140625\n",
      "==================================================\n",
      "tensor([[0.5405]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.54052734375\n",
      "Item ID: Ce0tHCxNMDi6wPRp-s47jw_right\n",
      "Predicted Meter: 0.54052734375\n",
      "Ground Truth: 23.0\n",
      "Error: 22.45947265625\n",
      "==================================================\n",
      "tensor([[0.3972]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.397216796875\n",
      "Item ID: nVAA5-GdotO9RbO9NjI-qw_right\n",
      "Predicted Meter: 0.397216796875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.602783203125\n",
      "==================================================\n",
      "tensor([[0.3862]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.38623046875\n",
      "Item ID: QrMeDQ9jdGJJ0rV2PVJEiw_back\n",
      "Predicted Meter: 0.38623046875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.61376953125\n",
      "==================================================\n",
      "tensor([[0.4512]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.451171875\n",
      "Item ID: 8pEZHqbN5u8_yG8_dfXbwg_front\n",
      "Predicted Meter: 0.451171875\n",
      "Ground Truth: 27.0\n",
      "Error: 26.548828125\n",
      "==================================================\n",
      "tensor([[0.2133]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2132568359375\n",
      "Item ID: 6-mgzznPhuvGSSjQkq6Jcw_right\n",
      "Predicted Meter: 0.2132568359375\n",
      "Ground Truth: 13.0\n",
      "Error: 12.7867431640625\n",
      "==================================================\n",
      "tensor([[0.2583]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.25830078125\n",
      "Item ID: Pfii6WqCwWdlp5FC-V4-tg_right\n",
      "Predicted Meter: 0.25830078125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.74169921875\n",
      "==================================================\n",
      "tensor([[0.7188]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.71875\n",
      "Item ID: 8b9HdmvIET8ZzN25BPoAqg_right\n",
      "Predicted Meter: 0.71875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.28125\n",
      "==================================================\n",
      "tensor([[0.3838]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.3837890625\n",
      "Item ID: XBZ7vig2eHnbKujbK0YrKw_right\n",
      "Predicted Meter: 0.3837890625\n",
      "Ground Truth: 3.0\n",
      "Error: 2.6162109375\n",
      "==================================================\n",
      "tensor([[0.4321]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.43212890625\n",
      "Item ID: 7ek2uD1SadiiO7S_CiCaFQ_right\n",
      "Predicted Meter: 0.43212890625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.56787109375\n",
      "==================================================\n",
      "tensor([[0.2844]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.284423828125\n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_right\n",
      "Predicted Meter: 0.284423828125\n",
      "Ground Truth: 18.0\n",
      "Error: 17.715576171875\n",
      "==================================================\n",
      "tensor([[0.3438]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.34375\n",
      "Item ID: zSYaKhsUunxd2HieLw--Bw_back\n",
      "Predicted Meter: 0.34375\n",
      "Ground Truth: 23.0\n",
      "Error: 22.65625\n",
      "==================================================\n",
      "tensor([[0.3713]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.371337890625\n",
      "Item ID: ooonkaHPxwqhujFUqM5pxw_back\n",
      "Predicted Meter: 0.371337890625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.628662109375\n",
      "==================================================\n",
      "tensor([[0.6050]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.60498046875\n",
      "Item ID: jxLJB3l_o_cvFGl6JM__wQ_right\n",
      "Predicted Meter: 0.60498046875\n",
      "Ground Truth: 18.0\n",
      "Error: 17.39501953125\n",
      "==================================================\n",
      "tensor([[0.3928]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.392822265625\n",
      "Item ID: euF84E5dXEqouOs2QXcQvw_right\n",
      "Predicted Meter: 0.392822265625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.607177734375\n",
      "==================================================\n",
      "tensor([[0.4343]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.434326171875\n",
      "Item ID: sBvClBUQk7xVDK-zZ7cJsg_left\n",
      "Predicted Meter: 0.434326171875\n",
      "Ground Truth: 24.0\n",
      "Error: 23.565673828125\n",
      "==================================================\n",
      "tensor([[0.6655]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.66552734375\n",
      "Item ID: 6nJTO2TykG9p_u6nqNIDfw_left\n",
      "Predicted Meter: 0.66552734375\n",
      "Ground Truth: 30.0\n",
      "Error: 29.33447265625\n",
      "==================================================\n",
      "tensor([[0.5381]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5380859375\n",
      "Item ID: vIIbBr4Zyvw5iE2qnXkDFw_right\n",
      "Predicted Meter: 0.5380859375\n",
      "Ground Truth: 24.0\n",
      "Error: 23.4619140625\n",
      "==================================================\n",
      "tensor([[0.5049]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5048828125\n",
      "Item ID: QjGIJdW81n-QPSYKVx9yeg_left\n",
      "Predicted Meter: 0.5048828125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.4951171875\n",
      "==================================================\n",
      "tensor([[0.4302]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.43017578125\n",
      "Item ID: Tn4uYOv0Lgp7BJQXxWgu0A_right\n",
      "Predicted Meter: 0.43017578125\n",
      "Ground Truth: 30.0\n",
      "Error: 29.56982421875\n",
      "==================================================\n",
      "tensor([[0.3630]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.363037109375\n",
      "Item ID: eK6GR-zlSKodjUThcJH4UA_left\n",
      "Predicted Meter: 0.363037109375\n",
      "Ground Truth: 18.0\n",
      "Error: 17.636962890625\n",
      "==================================================\n",
      "tensor([[0.2266]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2265625\n",
      "Item ID: MCsrah6QrlrSsMR4q-bdrg_right\n",
      "Predicted Meter: 0.2265625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.7734375\n",
      "==================================================\n",
      "tensor([[0.4983]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.498291015625\n",
      "Item ID: gyO5-qLWE4VT16crnReokw_front\n",
      "Predicted Meter: 0.498291015625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.501708984375\n",
      "==================================================\n",
      "tensor([[0.5195]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.51953125\n",
      "Item ID: gcev0hxtltoqCuqDffc1Ig_left\n",
      "Predicted Meter: 0.51953125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.48046875\n",
      "==================================================\n",
      "tensor([[0.3396]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.339599609375\n",
      "Item ID: QarynNyW6wNqfaYJwWl8mw_left\n",
      "Predicted Meter: 0.339599609375\n",
      "Ground Truth: 24.0\n",
      "Error: 23.660400390625\n",
      "==================================================\n",
      "tensor([[0.2869]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.286865234375\n",
      "Item ID: vqLP0uk2AgSU1smrbC9Kvg_right\n",
      "Predicted Meter: 0.286865234375\n",
      "Ground Truth: 12.0\n",
      "Error: 11.713134765625\n",
      "==================================================\n",
      "tensor([[0.4834]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4833984375\n",
      "Item ID: KcU4SrBPYpdOKOg1GG6tLQ_left\n",
      "Predicted Meter: 0.4833984375\n",
      "Ground Truth: 7.0\n",
      "Error: 6.5166015625\n",
      "==================================================\n",
      "tensor([[0.6089]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.60888671875\n",
      "Item ID: fq9dHETPobs-9ThuB39XIA_left\n",
      "Predicted Meter: 0.60888671875\n",
      "Ground Truth: 28.0\n",
      "Error: 27.39111328125\n",
      "==================================================\n",
      "tensor([[0.3860]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.385986328125\n",
      "Item ID: De-ve_jLpQ2Qtp8TdV1B7w_back\n",
      "Predicted Meter: 0.385986328125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.614013671875\n",
      "==================================================\n",
      "tensor([[0.4966]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.49658203125\n",
      "Item ID: 0zUQyjBxNCgr2m5DcaFD7g_left\n",
      "Predicted Meter: 0.49658203125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.50341796875\n",
      "==================================================\n",
      "tensor([[0.4624]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.46240234375\n",
      "Item ID: 9aAQN3uUShfw9hrpyhlJPQ_right\n",
      "Predicted Meter: 0.46240234375\n",
      "Ground Truth: 19.0\n",
      "Error: 18.53759765625\n",
      "==================================================\n",
      "tensor([[0.5625]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5625\n",
      "Item ID: 23K2mFVzbr6lgTCY23RSyA_left\n",
      "Predicted Meter: 0.5625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.4375\n",
      "==================================================\n",
      "tensor([[0.3923]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.392333984375\n",
      "Item ID: ZtEPmOuKRrXgxN530WjKcQ_left\n",
      "Predicted Meter: 0.392333984375\n",
      "Ground Truth: 25.0\n",
      "Error: 24.607666015625\n",
      "==================================================\n",
      "tensor([[0.5010]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5009765625\n",
      "Item ID: MCT0I-phnpTIdJSHxPtY-g_right\n",
      "Predicted Meter: 0.5009765625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.4990234375\n",
      "==================================================\n",
      "tensor([[0.6177]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.61767578125\n",
      "Item ID: mgrFIGd_29iyc-W2Ss-5jw_right\n",
      "Predicted Meter: 0.61767578125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.38232421875\n",
      "==================================================\n",
      "tensor([[0.4290]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.428955078125\n",
      "Item ID: mlYvnxD8afYF5Nk-OF586Q_back\n",
      "Predicted Meter: 0.428955078125\n",
      "Ground Truth: 27.0\n",
      "Error: 26.571044921875\n",
      "==================================================\n",
      "tensor([[0.3655]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.365478515625\n",
      "Item ID: TiowKAVmIDB9vomUrCEavA_back\n",
      "Predicted Meter: 0.365478515625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.634521484375\n",
      "==================================================\n",
      "tensor([[0.6558]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.65576171875\n",
      "Item ID: 5SVYauUAV9ZXo2j86RG9Nw_right\n",
      "Predicted Meter: 0.65576171875\n",
      "Ground Truth: 19.0\n",
      "Error: 18.34423828125\n",
      "==================================================\n",
      "tensor([[0.5752]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5751953125\n",
      "Item ID: Hb7GT5BfydzVAky33nEYWw_right\n",
      "Predicted Meter: 0.5751953125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.4248046875\n",
      "==================================================\n",
      "tensor([[0.5488]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.548828125\n",
      "Item ID: n_-sAWzo-dL9XYZ3UzaYqA_front\n",
      "Predicted Meter: 0.548828125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.451171875\n",
      "==================================================\n",
      "tensor([[0.5356]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.53564453125\n",
      "Item ID: 8IFkUwxQ62DDv-tOHhqTQg_right\n",
      "Predicted Meter: 0.53564453125\n",
      "Ground Truth: 23.0\n",
      "Error: 22.46435546875\n",
      "==================================================\n",
      "tensor([[0.4031]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.403076171875\n",
      "Item ID: t-ObecRVp4gxHXU-c2LqWA_right\n",
      "Predicted Meter: 0.403076171875\n",
      "Ground Truth: 19.0\n",
      "Error: 18.596923828125\n",
      "==================================================\n",
      "tensor([[0.5742]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.57421875\n",
      "Item ID: yX3nYikBoHLy4CRAPIzBug_left\n",
      "Predicted Meter: 0.57421875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.42578125\n",
      "==================================================\n",
      "tensor([[0.5400]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5400390625\n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_left\n",
      "Predicted Meter: 0.5400390625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.4599609375\n",
      "==================================================\n",
      "tensor([[0.6113]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.611328125\n",
      "Item ID: nwRZPegKQEcE9K_vk69Z9Q_left\n",
      "Predicted Meter: 0.611328125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.388671875\n",
      "==================================================\n",
      "tensor([[0.3645]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.364501953125\n",
      "Item ID: ysT0A7MmG8MHyY5MFjgfzg_left\n",
      "Predicted Meter: 0.364501953125\n",
      "Ground Truth: 30.0\n",
      "Error: 29.635498046875\n",
      "==================================================\n",
      "tensor([[0.4492]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.44921875\n",
      "Item ID: hUKSWoNyPXipTtKRMMVNpw_left\n",
      "Predicted Meter: 0.44921875\n",
      "Ground Truth: 22.0\n",
      "Error: 21.55078125\n",
      "==================================================\n",
      "tensor([[0.3240]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.323974609375\n",
      "Item ID: P11gxo_aHViVXuN2TI1OHg_back\n",
      "Predicted Meter: 0.323974609375\n",
      "Ground Truth: 20.0\n",
      "Error: 19.676025390625\n",
      "==================================================\n",
      "tensor([[0.3906]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.390625\n",
      "Item ID: yk32zNW_DJiLkXyl-tAW1Q_front\n",
      "Predicted Meter: 0.390625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.609375\n",
      "==================================================\n",
      "tensor([[0.5376]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.53759765625\n",
      "Item ID: rn5P8mSyhi_XnmRqx6nBKQ_left\n",
      "Predicted Meter: 0.53759765625\n",
      "Ground Truth: 23.0\n",
      "Error: 22.46240234375\n",
      "==================================================\n",
      "tensor([[0.4543]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.454345703125\n",
      "Item ID: f6f84yNmkf8dSKmA1WLL7g_right\n",
      "Predicted Meter: 0.454345703125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.545654296875\n",
      "==================================================\n",
      "tensor([[0.4355]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.435546875\n",
      "Item ID: 6rMd7Pu3dPDxfKH2hLr2cg_back\n",
      "Predicted Meter: 0.435546875\n",
      "Ground Truth: 13.0\n",
      "Error: 12.564453125\n",
      "==================================================\n",
      "tensor([[0.2365]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2364501953125\n",
      "Item ID: gfnR0b6W1zb84NAfdD8sLQ_right\n",
      "Predicted Meter: 0.2364501953125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.7635498046875\n",
      "==================================================\n",
      "tensor([[0.3372]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.337158203125\n",
      "Item ID: IC6kW3S7XTym0qyTt0JbHQ_left\n",
      "Predicted Meter: 0.337158203125\n",
      "Ground Truth: 30.0\n",
      "Error: 29.662841796875\n",
      "==================================================\n",
      "tensor([[0.3308]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.330810546875\n",
      "Item ID: dONIwocp2GAJUXZYYG83Kw_right\n",
      "Predicted Meter: 0.330810546875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.669189453125\n",
      "==================================================\n",
      "tensor([[0.5015]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.50146484375\n",
      "Item ID: jzPv_XRZOHrODSl7I9CQ3g_right\n",
      "Predicted Meter: 0.50146484375\n",
      "Ground Truth: 26.0\n",
      "Error: 25.49853515625\n",
      "==================================================\n",
      "tensor([[0.4824]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.482421875\n",
      "Item ID: 3DIZja3YjsiL-kIvWohenw_right\n",
      "Predicted Meter: 0.482421875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.517578125\n",
      "==================================================\n",
      "tensor([[0.5317]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.53173828125\n",
      "Item ID: fPyAVSl8mmbPEKbvzZXbtQ_right\n",
      "Predicted Meter: 0.53173828125\n",
      "Ground Truth: 18.0\n",
      "Error: 17.46826171875\n",
      "==================================================\n",
      "tensor([[0.3269]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.326904296875\n",
      "Item ID: mjFLZisPjatDeki9c5acEg_back\n",
      "Predicted Meter: 0.326904296875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.673095703125\n",
      "==================================================\n",
      "tensor([[0.4653]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.46533203125\n",
      "Item ID: SA7K9gTIMdwmXDTsDcBM6Q_right\n",
      "Predicted Meter: 0.46533203125\n",
      "Ground Truth: 19.0\n",
      "Error: 18.53466796875\n",
      "==================================================\n",
      "tensor([[0.5049]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5048828125\n",
      "Item ID: ELejaWw7AULkc0v0Of43yQ_left\n",
      "Predicted Meter: 0.5048828125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.4951171875\n",
      "==================================================\n",
      "tensor([[0.5586]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55859375\n",
      "Item ID: bIHH-_IXF2ik1ynh9n06zQ_right\n",
      "Predicted Meter: 0.55859375\n",
      "Ground Truth: 22.0\n",
      "Error: 21.44140625\n",
      "==================================================\n",
      "tensor([[0.3530]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.35302734375\n",
      "Item ID: mzltktb5OGPPKPAWlC_fCA_back\n",
      "Predicted Meter: 0.35302734375\n",
      "Ground Truth: 23.0\n",
      "Error: 22.64697265625\n",
      "==================================================\n",
      "tensor([[0.8193]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.8193359375\n",
      "Item ID: BBpzL8ql3kRAEMJpc1_HGw_right\n",
      "Predicted Meter: 0.8193359375\n",
      "Ground Truth: 24.0\n",
      "Error: 23.1806640625\n",
      "==================================================\n",
      "tensor([[0.4990]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4990234375\n",
      "Item ID: A9S-KxBLUmMgIGQZMvhxBw_front\n",
      "Predicted Meter: 0.4990234375\n",
      "Ground Truth: 28.0\n",
      "Error: 27.5009765625\n",
      "==================================================\n",
      "tensor([[0.3923]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.392333984375\n",
      "Item ID: gmliVFMV0b8_cmZ-QyDEAQ_front\n",
      "Predicted Meter: 0.392333984375\n",
      "Ground Truth: 19.0\n",
      "Error: 18.607666015625\n",
      "==================================================\n",
      "tensor([[0.4690]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.468994140625\n",
      "Item ID: 7gGp2SI0dsnSkN-JuQiesw_back\n",
      "Predicted Meter: 0.468994140625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.531005859375\n",
      "==================================================\n",
      "tensor([[0.3074]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.307373046875\n",
      "Item ID: 4UYo98GXL__fsXn5Hx4CPQ_back\n",
      "Predicted Meter: 0.307373046875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.692626953125\n",
      "==================================================\n",
      "tensor([[0.2954]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.29541015625\n",
      "Item ID: QArcg6Bp7lO81QVYjAfhPg_front\n",
      "Predicted Meter: 0.29541015625\n",
      "Ground Truth: 16.0\n",
      "Error: 15.70458984375\n",
      "==================================================\n",
      "tensor([[0.5820]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.58203125\n",
      "Item ID: O45aphvvSoBaD8agtIVz7w_right\n",
      "Predicted Meter: 0.58203125\n",
      "Ground Truth: 21.0\n",
      "Error: 20.41796875\n",
      "==================================================\n",
      "tensor([[0.3499]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.349853515625\n",
      "Item ID: _nYEhvKAIDtrvoRFpCSuBQ_front\n",
      "Predicted Meter: 0.349853515625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.650146484375\n",
      "==================================================\n",
      "tensor([[0.3081]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.30810546875\n",
      "Item ID: gLMnHJfMVfS176MkMVYWxA_left\n",
      "Predicted Meter: 0.30810546875\n",
      "Ground Truth: 24.0\n",
      "Error: 23.69189453125\n",
      "==================================================\n",
      "tensor([[0.5791]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5791015625\n",
      "Item ID: uixXcPpyT06jWktX7LvdUg_right\n",
      "Predicted Meter: 0.5791015625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.4208984375\n",
      "==================================================\n",
      "tensor([[0.5088]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5087890625\n",
      "Item ID: 2qEcuuJ-XtAJsGDEnh0VYg_right\n",
      "Predicted Meter: 0.5087890625\n",
      "Ground Truth: 23.0\n",
      "Error: 22.4912109375\n",
      "==================================================\n",
      "tensor([[0.4146]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.41455078125\n",
      "Item ID: kzpGP0MnxjLXTR0OLJsUWg_left\n",
      "Predicted Meter: 0.41455078125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.58544921875\n",
      "==================================================\n",
      "tensor([[0.1285]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.1285400390625\n",
      "Item ID: h_pdMobutR1b38Ek1Yf24Q_front\n",
      "Predicted Meter: 0.1285400390625\n",
      "Ground Truth: 18.0\n",
      "Error: 17.8714599609375\n",
      "==================================================\n",
      "tensor([[0.6328]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6328125\n",
      "Item ID: 1CFhl2zw8_wpjV8SaYekZA_right\n",
      "Predicted Meter: 0.6328125\n",
      "Ground Truth: 27.0\n",
      "Error: 26.3671875\n",
      "==================================================\n",
      "tensor([[0.3823]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.38232421875\n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_right\n",
      "Predicted Meter: 0.38232421875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.61767578125\n",
      "==================================================\n",
      "tensor([[0.7637]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.763671875\n",
      "Item ID: TrZtzGlvyG_QmyhBJBma4A_right\n",
      "Predicted Meter: 0.763671875\n",
      "Ground Truth: 21.0\n",
      "Error: 20.236328125\n",
      "==================================================\n",
      "tensor([[0.5967]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5966796875\n",
      "Item ID: Y1OMmLWmRqjyAP7zn4TGNA_right\n",
      "Predicted Meter: 0.5966796875\n",
      "Ground Truth: 20.0\n",
      "Error: 19.4033203125\n",
      "==================================================\n",
      "tensor([[0.6367]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.63671875\n",
      "Item ID: CzHuqJTBB29Mj10Tf-vG_A_left\n",
      "Predicted Meter: 0.63671875\n",
      "Ground Truth: 24.0\n",
      "Error: 23.36328125\n",
      "==================================================\n",
      "tensor([[0.3455]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.345458984375\n",
      "Item ID: 3k16AWQgqv40UC3T2pxpRA_right\n",
      "Predicted Meter: 0.345458984375\n",
      "Ground Truth: 25.0\n",
      "Error: 24.654541015625\n",
      "==================================================\n",
      "tensor([[0.5132]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.51318359375\n",
      "Item ID: pksYc6IzkoN8GUhDj0LDpQ_right\n",
      "Predicted Meter: 0.51318359375\n",
      "Ground Truth: 27.0\n",
      "Error: 26.48681640625\n",
      "==================================================\n",
      "tensor([[0.1863]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.186279296875\n",
      "Item ID: 9vadzEjIYIdbpVS1SXgiuA_front\n",
      "Predicted Meter: 0.186279296875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.813720703125\n",
      "==================================================\n",
      "tensor([[0.7256]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.7255859375\n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_right\n",
      "Predicted Meter: 0.7255859375\n",
      "Ground Truth: 30.0\n",
      "Error: 29.2744140625\n",
      "==================================================\n",
      "tensor([[0.4011]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.401123046875\n",
      "Item ID: 5NGOlsI3ydBDw0VOZ79c2A_right\n",
      "Predicted Meter: 0.401123046875\n",
      "Ground Truth: 24.0\n",
      "Error: 23.598876953125\n",
      "==================================================\n",
      "tensor([[0.6035]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.603515625\n",
      "Item ID: 9jetR7KxoqyH2uA45eUhZA_right\n",
      "Predicted Meter: 0.603515625\n",
      "Ground Truth: 13.0\n",
      "Error: 12.396484375\n",
      "==================================================\n",
      "tensor([[0.0552]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.055206298828125\n",
      "Item ID: fNup96_l6Q9_7sMN3jSYSA_back\n",
      "Predicted Meter: 0.055206298828125\n",
      "Ground Truth: 17.0\n",
      "Error: 16.944793701171875\n",
      "==================================================\n",
      "tensor([[0.1074]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.10736083984375\n",
      "Item ID: StE2fFKWlxq5oOY9TLzqaQ_right\n",
      "Predicted Meter: 0.10736083984375\n",
      "Ground Truth: 14.0\n",
      "Error: 13.89263916015625\n",
      "==================================================\n",
      "tensor([[0.4077]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.40771484375\n",
      "Item ID: Qz18uRHUrVtSIBcwaI6big_right\n",
      "Predicted Meter: 0.40771484375\n",
      "Ground Truth: 26.0\n",
      "Error: 25.59228515625\n",
      "==================================================\n",
      "tensor([[0.2130]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.2130126953125\n",
      "Item ID: 1N4oepZ2Tdx0RiMNW70Emg_right\n",
      "Predicted Meter: 0.2130126953125\n",
      "Ground Truth: 7.0\n",
      "Error: 6.7869873046875\n",
      "==================================================\n",
      "tensor([[0.3472]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.34716796875\n",
      "Item ID: Wwz8TuQs25BR7pV6ZLxHIA_left\n",
      "Predicted Meter: 0.34716796875\n",
      "Ground Truth: 21.0\n",
      "Error: 20.65283203125\n",
      "==================================================\n",
      "tensor([[0.5625]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5625\n",
      "Item ID: w7E4-o_FBl46aJR4nygWKA_left\n",
      "Predicted Meter: 0.5625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.4375\n",
      "==================================================\n",
      "tensor([[0.5581]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55810546875\n",
      "Item ID: EJyxn_BdvstB7aQW5qtXHA_right\n",
      "Predicted Meter: 0.55810546875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.44189453125\n",
      "==================================================\n",
      "tensor([[0.7275]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.7275390625\n",
      "Item ID: hPHfaOJAMuZoaAeHKwGt0Q_right\n",
      "Predicted Meter: 0.7275390625\n",
      "Ground Truth: 23.0\n",
      "Error: 22.2724609375\n",
      "==================================================\n",
      "tensor([[0.3992]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.399169921875\n",
      "Item ID: Y2LqquXdxkG6CERz_G6Nlg_left\n",
      "Predicted Meter: 0.399169921875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.600830078125\n",
      "==================================================\n",
      "tensor([[0.5947]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5947265625\n",
      "Item ID: VKDduK1sl3OF7ekMGjEI_Q_right\n",
      "Predicted Meter: 0.5947265625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.4052734375\n",
      "==================================================\n",
      "tensor([[0.5186]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5185546875\n",
      "Item ID: pVT3i-VC8DKKHxxGzGM1Gw_front\n",
      "Predicted Meter: 0.5185546875\n",
      "Ground Truth: 22.0\n",
      "Error: 21.4814453125\n",
      "==================================================\n",
      "tensor([[0.5137]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.513671875\n",
      "Item ID: QByx_5dPkZWspXNMrVlJCQ_left\n",
      "Predicted Meter: 0.513671875\n",
      "Ground Truth: 28.0\n",
      "Error: 27.486328125\n",
      "==================================================\n",
      "tensor([[0.5601]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.56005859375\n",
      "Item ID: sAX1efN-2Q1WTVF2Slt0Vg_right\n",
      "Predicted Meter: 0.56005859375\n",
      "Ground Truth: 16.0\n",
      "Error: 15.43994140625\n",
      "==================================================\n",
      "tensor([[0.5298]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52978515625\n",
      "Item ID: B2xQQNnGkZTxyQWXhWUjjA_right\n",
      "Predicted Meter: 0.52978515625\n",
      "Ground Truth: 18.0\n",
      "Error: 17.47021484375\n",
      "==================================================\n",
      "tensor([[0.4666]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.466552734375\n",
      "Item ID: zlVVWK2209dwiSv-jkQ7mA_right\n",
      "Predicted Meter: 0.466552734375\n",
      "Ground Truth: 18.0\n",
      "Error: 17.533447265625\n",
      "==================================================\n",
      "tensor([[0.5444]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.54443359375\n",
      "Item ID: PSXKhfo_2-cixnRnrkWgug_right\n",
      "Predicted Meter: 0.54443359375\n",
      "Ground Truth: 20.0\n",
      "Error: 19.45556640625\n",
      "==================================================\n",
      "tensor([[0.4702]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.47021484375\n",
      "Item ID: 60vORc94qejRLoePlhyhoA_left\n",
      "Predicted Meter: 0.47021484375\n",
      "Ground Truth: 27.0\n",
      "Error: 26.52978515625\n",
      "==================================================\n",
      "tensor([[0.3945]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.39453125\n",
      "Item ID: trCU9ky8rsxm4mMv4NGTxg_left\n",
      "Predicted Meter: 0.39453125\n",
      "Ground Truth: 19.0\n",
      "Error: 18.60546875\n",
      "==================================================\n",
      "tensor([[0.6250]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.625\n",
      "Item ID: yqPszzxqxHCcIjL-v3WSWA_right\n",
      "Predicted Meter: 0.625\n",
      "Ground Truth: 24.0\n",
      "Error: 23.375\n",
      "==================================================\n",
      "tensor([[0.4275]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.427490234375\n",
      "Item ID: LpCUToI7Cvgkq0ILdMjfqQ_right\n",
      "Predicted Meter: 0.427490234375\n",
      "Ground Truth: 24.0\n",
      "Error: 23.572509765625\n",
      "==================================================\n",
      "tensor([[0.5498]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5498046875\n",
      "Item ID: h9fvBHcx4BJ4zNUEwixmOw_back\n",
      "Predicted Meter: 0.5498046875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.4501953125\n",
      "==================================================\n",
      "tensor([[0.3843]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.38427734375\n",
      "Item ID: AJz20_6wSjeKoUZmfq-X2A_right\n",
      "Predicted Meter: 0.38427734375\n",
      "Ground Truth: 18.0\n",
      "Error: 17.61572265625\n",
      "==================================================\n",
      "tensor([[0.6528]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.65283203125\n",
      "Item ID: i5WVC6hZreMrj25W7QzYRw_back\n",
      "Predicted Meter: 0.65283203125\n",
      "Ground Truth: 23.0\n",
      "Error: 22.34716796875\n",
      "==================================================\n",
      "tensor([[0.7051]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.705078125\n",
      "Item ID: ZdiVojc1dtotNExOp58x5A_left\n",
      "Predicted Meter: 0.705078125\n",
      "Ground Truth: 26.0\n",
      "Error: 25.294921875\n",
      "==================================================\n",
      "tensor([[0.5781]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.578125\n",
      "Item ID: 60vORc94qejRLoePlhyhoA_right\n",
      "Predicted Meter: 0.578125\n",
      "Ground Truth: 27.0\n",
      "Error: 26.421875\n",
      "==================================================\n",
      "tensor([[0.4431]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.443115234375\n",
      "Item ID: 8vYyJMHE_ay2QBvq6RIX5g_back\n",
      "Predicted Meter: 0.443115234375\n",
      "Ground Truth: 28.0\n",
      "Error: 27.556884765625\n",
      "==================================================\n",
      "tensor([[0.2634]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.263427734375\n",
      "Item ID: ycFZ9QwrUeciEE2HSrFAeQ_right\n",
      "Predicted Meter: 0.263427734375\n",
      "Ground Truth: 12.0\n",
      "Error: 11.736572265625\n",
      "==================================================\n",
      "tensor([[0.2505]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.25048828125\n",
      "Item ID: 1Y7B1JQtBHVe2iPrAiM-eg_front\n",
      "Predicted Meter: 0.25048828125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.74951171875\n",
      "==================================================\n",
      "tensor([[0.6143]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6142578125\n",
      "Item ID: 7UXQIVV4UHo3-oDPm7qELQ_right\n",
      "Predicted Meter: 0.6142578125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.3857421875\n",
      "==================================================\n",
      "tensor([[0.4719]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.471923828125\n",
      "Item ID: axGFVJ1krhsn6mC28ooKVA_front\n",
      "Predicted Meter: 0.471923828125\n",
      "Ground Truth: 29.0\n",
      "Error: 28.528076171875\n",
      "==================================================\n",
      "tensor([[0.4712]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.47119140625\n",
      "Item ID: 2M7SYVOfLnMuDXYnW8FfEQ_back\n",
      "Predicted Meter: 0.47119140625\n",
      "Ground Truth: 24.0\n",
      "Error: 23.52880859375\n",
      "==================================================\n",
      "tensor([[0.6665]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.66650390625\n",
      "Item ID: 4K-t0ms7NlOyQIs6n4V0hg_back\n",
      "Predicted Meter: 0.66650390625\n",
      "Ground Truth: 30.0\n",
      "Error: 29.33349609375\n",
      "==================================================\n",
      "tensor([[0.4768]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.476806640625\n",
      "Item ID: MS8ZruXv6pKGYFtg62uMpg_back\n",
      "Predicted Meter: 0.476806640625\n",
      "Ground Truth: 27.0\n",
      "Error: 26.523193359375\n",
      "==================================================\n",
      "tensor([[0.6045]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6044921875\n",
      "Item ID: q57H2cmymr1Ixjb9MbCfPQ_right\n",
      "Predicted Meter: 0.6044921875\n",
      "Ground Truth: 23.0\n",
      "Error: 22.3955078125\n",
      "==================================================\n",
      "tensor([[0.6147]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.61474609375\n",
      "Item ID: EdEUoTTAcuM9cNcu08a1nw_left\n",
      "Predicted Meter: 0.61474609375\n",
      "Ground Truth: 19.0\n",
      "Error: 18.38525390625\n",
      "==================================================\n",
      "tensor([[0.4836]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.483642578125\n",
      "Item ID: NkjfX-IG5Qw8M_p_clCO4A_left\n",
      "Predicted Meter: 0.483642578125\n",
      "Ground Truth: 28.0\n",
      "Error: 27.516357421875\n",
      "==================================================\n",
      "tensor([[0.5186]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5185546875\n",
      "Item ID: dInyxmFH1E4YJXjzmHFDHg_left\n",
      "Predicted Meter: 0.5185546875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.4814453125\n",
      "==================================================\n",
      "tensor([[0.6113]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.611328125\n",
      "Item ID: cTPFfgZ4KkUXKHzMddF7Bg_left\n",
      "Predicted Meter: 0.611328125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.388671875\n",
      "==================================================\n",
      "tensor([[0.4048]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.40478515625\n",
      "Item ID: 1LGPz7B3vJ2IT1Qm_2nytw_front\n",
      "Predicted Meter: 0.40478515625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.59521484375\n",
      "==================================================\n",
      "tensor([[0.5059]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.505859375\n",
      "Item ID: JpCaP2v70FtqJJGeXyjDdw_front\n",
      "Predicted Meter: 0.505859375\n",
      "Ground Truth: 19.0\n",
      "Error: 18.494140625\n",
      "==================================================\n",
      "tensor([[0.5522]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.55224609375\n",
      "Item ID: KP7OmYZuuX5T0O8CQGFFWg_back\n",
      "Predicted Meter: 0.55224609375\n",
      "Ground Truth: 15.0\n",
      "Error: 14.44775390625\n",
      "==================================================\n",
      "tensor([[0.5088]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.5087890625\n",
      "Item ID: KtvPeGrsVIBkeHq8DsJfhQ_right\n",
      "Predicted Meter: 0.5087890625\n",
      "Ground Truth: 28.0\n",
      "Error: 27.4912109375\n",
      "==================================================\n",
      "tensor([[0.9048]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.90478515625\n",
      "Item ID: 2pj56we2AFhPUcV36gq4dw_left\n",
      "Predicted Meter: 0.90478515625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.09521484375\n",
      "==================================================\n",
      "tensor([[0.4539]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.453857421875\n",
      "Item ID: yKjJVY-QcL8B72FWucki9A_back\n",
      "Predicted Meter: 0.453857421875\n",
      "Ground Truth: 7.0\n",
      "Error: 6.546142578125\n",
      "==================================================\n",
      "tensor([[0.3423]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.34228515625\n",
      "Item ID: X7F2k-IYYxWQONqJvKFAUA_right\n",
      "Predicted Meter: 0.34228515625\n",
      "Ground Truth: 26.0\n",
      "Error: 25.65771484375\n",
      "==================================================\n",
      "tensor([[0.2144]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.21435546875\n",
      "Item ID: D-QBRj4cortWyDiYEUHvsw_right\n",
      "Predicted Meter: 0.21435546875\n",
      "Ground Truth: 6.0\n",
      "Error: 5.78564453125\n",
      "==================================================\n",
      "tensor([[0.7227]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.72265625\n",
      "Item ID: b9NFY5tRuunJ3jBmVf7UBA_right\n",
      "Predicted Meter: 0.72265625\n",
      "Ground Truth: 21.0\n",
      "Error: 20.27734375\n",
      "==================================================\n",
      "tensor([[0.6118]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.61181640625\n",
      "Item ID: dGxsDZMbA6DXA4d1Pq0Bjg_front\n",
      "Predicted Meter: 0.61181640625\n",
      "Ground Truth: 22.0\n",
      "Error: 21.38818359375\n",
      "==================================================\n",
      "tensor([[0.5220]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.52197265625\n",
      "Item ID: ZpIKRM0lVXkIYHKNeJ-PSw_right\n",
      "Predicted Meter: 0.52197265625\n",
      "Ground Truth: 24.0\n",
      "Error: 23.47802734375\n",
      "==================================================\n",
      "tensor([[0.4673]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.46728515625\n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_right\n",
      "Predicted Meter: 0.46728515625\n",
      "Ground Truth: 21.0\n",
      "Error: 20.53271484375\n",
      "==================================================\n",
      "tensor([[0.6328]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.6328125\n",
      "Item ID: 1C1eS9jrHwDToiIteIZqgQ_right\n",
      "Predicted Meter: 0.6328125\n",
      "Ground Truth: 17.0\n",
      "Error: 16.3671875\n",
      "==================================================\n",
      "tensor([[0.3232]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.3232421875\n",
      "Item ID: luxAA4b_ND2ueb7anI88BA_back\n",
      "Predicted Meter: 0.3232421875\n",
      "Ground Truth: 16.0\n",
      "Error: 15.6767578125\n",
      "==================================================\n",
      "tensor([[0.3140]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.31396484375\n",
      "Item ID: Pplmiyt2a4ebn8hP0nc70A_back\n",
      "Predicted Meter: 0.31396484375\n",
      "Ground Truth: 21.0\n",
      "Error: 20.68603515625\n",
      "==================================================\n",
      "tensor([[0.5659]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.56591796875\n",
      "Item ID: Qy7K-TboLcgUyUupDtMgKQ_right\n",
      "Predicted Meter: 0.56591796875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.43408203125\n",
      "==================================================\n",
      "tensor([[0.3469]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.346923828125\n",
      "Item ID: mqpRUiJoeyjpoVAjiEiKMQ_front\n",
      "Predicted Meter: 0.346923828125\n",
      "Ground Truth: 22.0\n",
      "Error: 21.653076171875\n",
      "==================================================\n",
      "tensor([[0.2815]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.281494140625\n",
      "Item ID: cE0sa5qCriI6GUBYMcyKeg_right\n",
      "Predicted Meter: 0.281494140625\n",
      "Ground Truth: 25.0\n",
      "Error: 24.718505859375\n",
      "==================================================\n",
      "tensor([[0.4824]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.482421875\n",
      "Item ID: jU6X-KpYz18pt96XJ-YoeQ_back\n",
      "Predicted Meter: 0.482421875\n",
      "Ground Truth: 25.0\n",
      "Error: 24.517578125\n",
      "==================================================\n",
      "tensor([[0.4170]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.4169921875\n",
      "Item ID: sw8Il_kg3VTkg4hfRAqhgg_left\n",
      "Predicted Meter: 0.4169921875\n",
      "Ground Truth: 29.0\n",
      "Error: 28.5830078125\n",
      "==================================================\n",
      "tensor([[0.7119]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.7119140625\n",
      "Item ID: wNMjdSqgpzj6j72V6oMMUg_right\n",
      "Predicted Meter: 0.7119140625\n",
      "Ground Truth: 29.0\n",
      "Error: 28.2880859375\n",
      "==================================================\n",
      "tensor([[0.2329]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.23291015625\n",
      "Item ID: C72ymm34PyRc2OruySafpQ_left\n",
      "Predicted Meter: 0.23291015625\n",
      "Ground Truth: 15.0\n",
      "Error: 14.76708984375\n",
      "==================================================\n",
      "tensor([[0.3201]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.320068359375\n",
      "Item ID: tL1cMj27xoKEUPU8emSdSQ_right\n",
      "Predicted Meter: 0.320068359375\n",
      "Ground Truth: 22.0\n",
      "Error: 21.679931640625\n",
      "==================================================\n",
      "tensor([[0.3518]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.351806640625\n",
      "Item ID: 1KKSCQJLKYDDK3KSdFkHdw_right\n",
      "Predicted Meter: 0.351806640625\n",
      "Ground Truth: 23.0\n",
      "Error: 22.648193359375\n",
      "==================================================\n",
      "tensor([[0.8198]], device='cuda:0', dtype=torch.float16)\n",
      "torch.Size([1, 1])\n",
      "Predicted meter: 0.81982421875\n",
      "Item ID: l7wQW6Nrj2lN4nrgHrVA0g_left\n",
      "Predicted Meter: 0.81982421875\n",
      "Ground Truth: 26.0\n",
      "Error: 25.18017578125\n",
      "==================================================\n",
      "Results saved to inference_custom_finetune.csv\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "cache_dir = \"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    "finetuned_model_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "# Load the finetuned model (adapter weights load into the base model with hierarchical keys).\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-1.5-7b-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir\n",
    ").to(0)\n",
    "\n",
    "print(finetuned_model)\n",
    "\n",
    "finetuned_model.load_adapter(\"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test\")\n",
    "regression_model = LlavaRegressionModel(finetuned_model).to(0)\n",
    "\n",
    "results = run_inference_on_dataset(\n",
    "    regression_model,\n",
    "    processor,\n",
    "    test_json_path,\n",
    "    image_root,\n",
    "    \"inference_custom_finetune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53130a89-1b6a-4aa6-b021-55d820987ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "could not find MARK",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dic \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test/adapter_model.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/serialization.py:1495\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1494\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/torch/serialization.py:1744\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1739\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1740\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1742\u001b[0m     )\n\u001b[0;32m-> 1744\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: could not find MARK"
     ]
    }
   ],
   "source": [
    "dic = torch.load(\"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test/adapter_model.safetensors\", weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40df7d18-ba9a-4ade-bd37-24addf6f941a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "Loading adapter weights from /hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test led to unexpected keys not found in the model:  ['base_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight']. \n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlavaForConditionalGeneration(\n",
      "  (vision_tower): CLIPVisionModel(\n",
      "    (vision_model): CLIPVisionTransformer(\n",
      "      (embeddings): CLIPVisionEmbeddings(\n",
      "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "        (position_embedding): Embedding(577, 1024)\n",
      "      )\n",
      "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder): CLIPEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x CLIPEncoderLayer(\n",
      "            (self_attn): CLIPSdpaAttention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): CLIPMLP(\n",
      "              (activation_fn): QuickGELUActivation()\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (multi_modal_projector): LlavaMultiModalProjector(\n",
      "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELUActivation()\n",
      "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaSdpaAttention(\n",
      "            (q_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (k_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (v_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (o_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (up_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (down_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=11008, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n",
      "LlavaForConditionalGeneration(\n",
      "  (vision_tower): CLIPVisionModel(\n",
      "    (vision_model): CLIPVisionTransformer(\n",
      "      (embeddings): CLIPVisionEmbeddings(\n",
      "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "        (position_embedding): Embedding(577, 1024)\n",
      "      )\n",
      "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder): CLIPEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x CLIPEncoderLayer(\n",
      "            (self_attn): CLIPSdpaAttention(\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): CLIPMLP(\n",
      "              (activation_fn): QuickGELUActivation()\n",
      "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            )\n",
      "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (multi_modal_projector): LlavaMultiModalProjector(\n",
      "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELUActivation()\n",
      "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaSdpaAttention(\n",
      "            (q_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (k_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (v_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (o_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (up_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (down_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=11008, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "finetuned_model1 = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ")\n",
    "finetuned_model2 = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-custom\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ")\n",
    "print(finetuned_model1)\n",
    "print(finetuned_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214475c-f71a-43cd-bc3a-b8882e6b90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finetuned model as usual.\n",
    "finetuned_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-test\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ").to(0)\n",
    "\n",
    "# Extract the base model (which now has the adapter weights properly loaded)\n",
    "base_model = finetuned_model.base_model\n",
    "\n",
    "# Wrap the base model in your flattened regression model.\n",
    "regression_model = LlavaRegressionModel(base_model).to(0)\n",
    "\n",
    "# Now run inference using your regression_model.\n",
    "print(\"=== Inference using the Finetuned Regression Model ===\")\n",
    "df_custom_train = run_inference_on_dataset(\n",
    "    regression_model,\n",
    "    processor,\n",
    "    test_json_path,\n",
    "    image_root,\n",
    "    \"inference_custom_finetune\"\n",
    ")\n",
    "\n",
    "# Optionally, clean up.\n",
    "del finetuned_model, regression_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b382d142-9ae2-449d-b28c-ac203e0e4cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Finetuned Regression Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LlavaCausalLMOutputWithPast' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Now run inference using your regression_model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Inference using the Finetuned Regression Model ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m df_custom_train \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregression_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_json_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minference_custom_finetune_BRUH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 112\u001b[0m, in \u001b[0;36mrun_inference_on_dataset\u001b[0;34m(model, processor, dataset_path, image_root, save_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Run inference using the regression head.\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m predicted_meter \u001b[38;5;241m=\u001b[39m \u001b[43minference_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted meter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_meter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Extract ground truth meter from the ground truth text.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m, in \u001b[0;36minference_image\u001b[0;34m(model, processor, image_path, human_text)\u001b[0m\n\u001b[1;32m     63\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Assuming the output is a tensor of shape (batch_size, 1), convert it to a float.\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m predicted_meter \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_meter\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LlavaCausalLMOutputWithPast' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "regression_model = model.to(0)\n",
    "\n",
    "# Now run inference using your regression_model.\n",
    "print(\"=== Inference using the Finetuned Regression Model ===\")\n",
    "df_custom_train = run_inference_on_dataset(\n",
    "    regression_model,\n",
    "    processor,\n",
    "    test_json_path,\n",
    "    image_root,\n",
    "    \"inference_custom_finetune_BRUH\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102b987f-ce5f-4a48-b1e4-004686c84f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inference using the Finetuned Regression Model ===\n",
      "Predicted meter: 16.6875\n",
      "Item ID: YeeOSjXEgLAKHQEV8zyT8Q_right\n",
      "Predicted Meter: 16.6875\n",
      "Ground Truth: 20.0\n",
      "Error: 3.3125\n",
      "==================================================\n",
      "Predicted meter: 16.125\n",
      "Item ID: RypdZclJzYYuJ9lrRJB97w_left\n",
      "Predicted Meter: 16.125\n",
      "Ground Truth: 21.0\n",
      "Error: 4.875\n",
      "==================================================\n",
      "Predicted meter: 17.65625\n",
      "Item ID: if_6Golbk4UT-lUBDpzmJg_right\n",
      "Predicted Meter: 17.65625\n",
      "Ground Truth: 28.0\n",
      "Error: 10.34375\n",
      "==================================================\n",
      "Predicted meter: 17.0\n",
      "Item ID: 2QJJIdNRdpXXRcTbY5LzWA_right\n",
      "Predicted Meter: 17.0\n",
      "Ground Truth: 29.0\n",
      "Error: 12.0\n",
      "==================================================\n",
      "Predicted meter: 16.046875\n",
      "Item ID: 51dJTqrKEv54IA11ZYtLvg_back\n",
      "Predicted Meter: 16.046875\n",
      "Ground Truth: 25.0\n",
      "Error: 8.953125\n",
      "==================================================\n",
      "Predicted meter: 18.15625\n",
      "Item ID: KD0EjEFJVvU_nX9Vlk2pQQ_front\n",
      "Predicted Meter: 18.15625\n",
      "Ground Truth: 28.0\n",
      "Error: 9.84375\n",
      "==================================================\n",
      "Predicted meter: 15.71875\n",
      "Item ID: VIQ_5CQZtl5hvS4FSVF79g_right\n",
      "Predicted Meter: 15.71875\n",
      "Ground Truth: 21.0\n",
      "Error: 5.28125\n",
      "==================================================\n",
      "Predicted meter: 15.765625\n",
      "Item ID: OA6YEEF9yFSiwDJmnpW-vA_back\n",
      "Predicted Meter: 15.765625\n",
      "Ground Truth: 29.0\n",
      "Error: 13.234375\n",
      "==================================================\n",
      "Predicted meter: 17.03125\n",
      "Item ID: jt1_xHG8VwfeKTq0woQURw_front\n",
      "Predicted Meter: 17.03125\n",
      "Ground Truth: 29.0\n",
      "Error: 11.96875\n",
      "==================================================\n",
      "Predicted meter: 17.890625\n",
      "Item ID: 5bboCI1ew_yTNAjZl9AShw_back\n",
      "Predicted Meter: 17.890625\n",
      "Ground Truth: 20.0\n",
      "Error: 2.109375\n",
      "==================================================\n",
      "Predicted meter: 15.625\n",
      "Item ID: uZviMwRtEEKJszJuXCsWag_left\n",
      "Predicted Meter: 15.625\n",
      "Ground Truth: 30.0\n",
      "Error: 14.375\n",
      "==================================================\n",
      "Predicted meter: 16.09375\n",
      "Item ID: -cPRMHADLCA9oiYu4G5NiQ_right\n",
      "Predicted Meter: 16.09375\n",
      "Ground Truth: 29.0\n",
      "Error: 12.90625\n",
      "==================================================\n",
      "Predicted meter: 16.796875\n",
      "Item ID: 3q8cZ15NP1MePKuTy_8Ewg_right\n",
      "Predicted Meter: 16.796875\n",
      "Ground Truth: 29.0\n",
      "Error: 12.203125\n",
      "==================================================\n",
      "Predicted meter: 15.8515625\n",
      "Item ID: 4JSVBoSgdanbcDDpTIb7zQ_back\n",
      "Predicted Meter: 15.8515625\n",
      "Ground Truth: 25.0\n",
      "Error: 9.1484375\n",
      "==================================================\n",
      "Predicted meter: 17.828125\n",
      "Item ID: u2S-OoVhBoS8vspW3698cw_left\n",
      "Predicted Meter: 17.828125\n",
      "Ground Truth: 29.0\n",
      "Error: 11.171875\n",
      "==================================================\n",
      "Predicted meter: 17.953125\n",
      "Item ID: jZy16XlQZfXpFO06Nxf8hw_back\n",
      "Predicted Meter: 17.953125\n",
      "Ground Truth: 27.0\n",
      "Error: 9.046875\n",
      "==================================================\n",
      "Predicted meter: 16.34375\n",
      "Item ID: bxqA6mVaEWuyJ2iEcn2D6w_left\n",
      "Predicted Meter: 16.34375\n",
      "Ground Truth: 25.0\n",
      "Error: 8.65625\n",
      "==================================================\n",
      "Predicted meter: 16.546875\n",
      "Item ID: StE2fFKWlxq5oOY9TLzqaQ_front\n",
      "Predicted Meter: 16.546875\n",
      "Ground Truth: 14.0\n",
      "Error: 2.546875\n",
      "==================================================\n",
      "Predicted meter: 16.84375\n",
      "Item ID: TDmGgyX3H6a0b7Ul9wsCyw_front\n",
      "Predicted Meter: 16.84375\n",
      "Ground Truth: 27.0\n",
      "Error: 10.15625\n",
      "==================================================\n",
      "Predicted meter: 17.875\n",
      "Item ID: oQBRmAbStMOP7eHcnuWDew_front\n",
      "Predicted Meter: 17.875\n",
      "Ground Truth: 29.0\n",
      "Error: 11.125\n",
      "==================================================\n",
      "Predicted meter: 15.46875\n",
      "Item ID: WPY6c9KfWW05qxkZWM9frg_left\n",
      "Predicted Meter: 15.46875\n",
      "Ground Truth: 24.0\n",
      "Error: 8.53125\n",
      "==================================================\n",
      "Predicted meter: 16.703125\n",
      "Item ID: rGiWpR2ZaxLoU3H1m2eicA_right\n",
      "Predicted Meter: 16.703125\n",
      "Ground Truth: 26.0\n",
      "Error: 9.296875\n",
      "==================================================\n",
      "Predicted meter: 16.5625\n",
      "Item ID: mlbCVU97bM-rhqoo6ZXYMg_left\n",
      "Predicted Meter: 16.5625\n",
      "Ground Truth: 29.0\n",
      "Error: 12.4375\n",
      "==================================================\n",
      "Predicted meter: 16.296875\n",
      "Item ID: tAe4VgAEwbeG5gbfSsJPpw_front\n",
      "Predicted Meter: 16.296875\n",
      "Ground Truth: 25.0\n",
      "Error: 8.703125\n",
      "==================================================\n",
      "Predicted meter: 16.59375\n",
      "Item ID: YagfDlvCdeTtJoOkSrM00Q_right\n",
      "Predicted Meter: 16.59375\n",
      "Ground Truth: 15.0\n",
      "Error: 1.59375\n",
      "==================================================\n",
      "Predicted meter: 16.03125\n",
      "Item ID: nT44nrlGmX-Qw34LF1TFbg_left\n",
      "Predicted Meter: 16.03125\n",
      "Ground Truth: 24.0\n",
      "Error: 7.96875\n",
      "==================================================\n",
      "Predicted meter: 16.546875\n",
      "Item ID: Or2XJIVgOPWxLLAg-k54Wg_right\n",
      "Predicted Meter: 16.546875\n",
      "Ground Truth: 28.0\n",
      "Error: 11.453125\n",
      "==================================================\n",
      "Predicted meter: 15.375\n",
      "Item ID: euF84E5dXEqouOs2QXcQvw_right\n",
      "Predicted Meter: 15.375\n",
      "Ground Truth: 25.0\n",
      "Error: 9.625\n",
      "==================================================\n",
      "Predicted meter: 16.78125\n",
      "Item ID: TCpuNST0_K8vh4aJ6utJvg_right\n",
      "Predicted Meter: 16.78125\n",
      "Ground Truth: 28.0\n",
      "Error: 11.21875\n",
      "==================================================\n",
      "Predicted meter: 14.2109375\n",
      "Item ID: IwKQ_8sO_ZzxNPhDaJS8Vg_right\n",
      "Predicted Meter: 14.2109375\n",
      "Ground Truth: 9.0\n",
      "Error: 5.2109375\n",
      "==================================================\n",
      "Predicted meter: 17.34375\n",
      "Item ID: zXTfl8Adu4D7RmdLc6xXkg_front\n",
      "Predicted Meter: 17.34375\n",
      "Ground Truth: 28.0\n",
      "Error: 10.65625\n",
      "==================================================\n",
      "Predicted meter: 17.203125\n",
      "Item ID: RXKI93qBTczzhdPzgZf1PA_right\n",
      "Predicted Meter: 17.203125\n",
      "Ground Truth: 28.0\n",
      "Error: 10.796875\n",
      "==================================================\n",
      "Predicted meter: 16.421875\n",
      "Item ID: 34rhcF7_5z_xCF7rHKL4Ug_right\n",
      "Predicted Meter: 16.421875\n",
      "Ground Truth: 25.0\n",
      "Error: 8.578125\n",
      "==================================================\n",
      "Predicted meter: 14.546875\n",
      "Item ID: 6CA9s-KtfO7uBjJqaWhoEQ_right\n",
      "Predicted Meter: 14.546875\n",
      "Ground Truth: 5.0\n",
      "Error: 9.546875\n",
      "==================================================\n",
      "Predicted meter: 17.171875\n",
      "Item ID: hm8yRhRJak6Yuw2JFio42A_left\n",
      "Predicted Meter: 17.171875\n",
      "Ground Truth: 25.0\n",
      "Error: 7.828125\n",
      "==================================================\n",
      "Predicted meter: 17.203125\n",
      "Item ID: kxgQmAM7xv9plJ2K11j1Tg_right\n",
      "Predicted Meter: 17.203125\n",
      "Ground Truth: 22.0\n",
      "Error: 4.796875\n",
      "==================================================\n",
      "Predicted meter: 16.171875\n",
      "Item ID: 57FhbQ2hjn6JpnzLXRecKg_left\n",
      "Predicted Meter: 16.171875\n",
      "Ground Truth: 23.0\n",
      "Error: 6.828125\n",
      "==================================================\n",
      "Predicted meter: 16.453125\n",
      "Item ID: MsbhU5SGNyqB8C5DuICXMQ_right\n",
      "Predicted Meter: 16.453125\n",
      "Ground Truth: 30.0\n",
      "Error: 13.546875\n",
      "==================================================\n",
      "Predicted meter: 16.609375\n",
      "Item ID: RSR1DzDlgf3rVtObvLuQKg_right\n",
      "Predicted Meter: 16.609375\n",
      "Ground Truth: 30.0\n",
      "Error: 13.390625\n",
      "==================================================\n",
      "Predicted meter: 16.984375\n",
      "Item ID: _6-fn5H10MP8-bg4vuGznQ_back\n",
      "Predicted Meter: 16.984375\n",
      "Ground Truth: 14.0\n",
      "Error: 2.984375\n",
      "==================================================\n",
      "Predicted meter: 15.6328125\n",
      "Item ID: 8RBXq6bQYWlSXkXNftC6hw_right\n",
      "Predicted Meter: 15.6328125\n",
      "Ground Truth: 26.0\n",
      "Error: 10.3671875\n",
      "==================================================\n",
      "Predicted meter: 15.6484375\n",
      "Item ID: PvfZG6umCnqZ7SRu3zPcFQ_right\n",
      "Predicted Meter: 15.6484375\n",
      "Ground Truth: 26.0\n",
      "Error: 10.3515625\n",
      "==================================================\n",
      "Predicted meter: 15.9765625\n",
      "Item ID: lF1tj14eY8kjmHDTvuVz1Q_right\n",
      "Predicted Meter: 15.9765625\n",
      "Ground Truth: 13.0\n",
      "Error: 2.9765625\n",
      "==================================================\n",
      "Predicted meter: 16.625\n",
      "Item ID: 5Oo42sVBuFcZ-Cw33NpzAg_left\n",
      "Predicted Meter: 16.625\n",
      "Ground Truth: 29.0\n",
      "Error: 12.375\n",
      "==================================================\n",
      "Predicted meter: 16.609375\n",
      "Item ID: JiOXB5fY6rGY76hPZ3bOpg_left\n",
      "Predicted Meter: 16.609375\n",
      "Ground Truth: 21.0\n",
      "Error: 4.390625\n",
      "==================================================\n",
      "Predicted meter: 16.5\n",
      "Item ID: PC1HeH4xIVOiEMuE9aLK7w_right\n",
      "Predicted Meter: 16.5\n",
      "Ground Truth: 27.0\n",
      "Error: 10.5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now run inference using your regression_model.\n",
    "print(\"=== Inference using the Finetuned Regression Model ===\")\n",
    "df_custom_train = run_inference_on_dataset(\n",
    "    regression_model,\n",
    "    processor,\n",
    "    test_json_path,\n",
    "    image_root,\n",
    "    \"inference_custom_finetune_BRUH\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88f9f42f-5681-4228-9067-1c0670f61d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.964163822525597)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_custom_train['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30aea4f0-13c0-4842-835c-15044d3f8cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.419795221843\n",
      "4.273037542662116\n",
      "3.7610921501706485\n"
     ]
    }
   ],
   "source": [
    "print(df_no_train['error'].mean())\n",
    "print(df_default_train['error'].mean())\n",
    "print(df_custom_train['error'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa3f94a0-065d-4619-90d0-353e827561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del finetuned_model\n",
    "del regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804dabf8-666f-4c7c-8903-0e6a043fb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, PreTrainedTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a7948d-519d-4620-982e-b8821723f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.76it/s]\n",
      "Loading adapter weights from /hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp led to unexpected keys not found in the model:  ['bruh_model.language_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight', 'bruh_model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight', 'regression_head.bias', 'regression_head.weight']. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlavaForConditionalGeneration(\n",
      "  (vision_tower): CLIPVisionModel(\n",
      "    (vision_model): CLIPVisionTransformer(\n",
      "      (embeddings): CLIPVisionEmbeddings(\n",
      "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "        (position_embedding): Embedding(577, 1024)\n",
      "      )\n",
      "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (encoder): CLIPEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x CLIPEncoderLayer(\n",
      "            (self_attn): CLIPSdpaAttention(\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (out_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): CLIPMLP(\n",
      "              (activation_fn): QuickGELUActivation()\n",
      "              (fc1): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (fc2): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (multi_modal_projector): LlavaMultiModalProjector(\n",
      "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (act): GELUActivation()\n",
      "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (language_model): LlamaForCausalLM(\n",
      "    (model): LlamaModel(\n",
      "      (embed_tokens): Embedding(32064, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x LlamaDecoderLayer(\n",
      "          (self_attn): LlamaSdpaAttention(\n",
      "            (q_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (k_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (v_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (o_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (rotary_emb): LlamaRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): LlamaMLP(\n",
      "            (gate_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (up_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (down_proj): lora.Linear(\n",
      "              (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Dropout(p=0.05, inplace=False)\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=11008, out_features=8, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
      "  )\n",
      ")\n",
      "Loading LoRA weights...\n",
      "Merging LoRA weights...\n",
      "Model is loaded...\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", add_eos_token=True)\n",
    "tokenizer = processor.tokenizer\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=\"/hpi/fs00/scratch/liudvikas.zekas/.cache\"\n",
    ")\n",
    "config = AutoConfig.from_pretrained(\"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp\")\n",
    "\n",
    "#model, tokenizer, processor, config = loader.load(args.load_model)\n",
    "print(model)\n",
    "\n",
    "print(\"Loading LoRA weights...\")\n",
    "model = PeftModel.from_pretrained(model, \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/llava-1.5-7b_lora-True_qlora-False-acc-exp\")\n",
    "print(\"Merging LoRA weights...\")\n",
    "model = model.merge_and_unload()\n",
    "print(\"Model is loaded...\")\n",
    "#model.save_pretrained(model_save_path)\n",
    "\n",
    "#tokenizer.save_pretrained(model_save_path)\n",
    "#processor.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5adc6d1-a644-4357-990e-d04c1485f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-06 03:00:49,456] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.6\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.2.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/hpi/fs00/home/liudvikas.zekas/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/integrations/peft.py:397: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'active_adapters' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/hpi/fs00/scratch/liudvikas.zekas/checkpoints/new_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(model_save_path)\n\u001b[1;32m      5\u001b[0m processor\u001b[38;5;241m.\u001b[39msave_pretrained(model_save_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/modeling_utils.py:2636\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _hf_peft_config_loaded:\n\u001b[1;32m   2633\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2634\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2635\u001b[0m     )\n\u001b[0;32m-> 2636\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_to_save\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adapter_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_peft_format:\n\u001b[1;32m   2639\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2640\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2641\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/integrations/peft.py:423\u001b[0m, in \u001b[0;36mPeftAdapterMixin.get_adapter_state_dict\u001b[0;34m(self, adapter_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peft_model_state_dict\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m     adapter_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m adapter_state_dict \u001b[38;5;241m=\u001b[39m get_peft_model_state_dict(\u001b[38;5;28mself\u001b[39m, adapter_name\u001b[38;5;241m=\u001b[39madapter_name)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adapter_state_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/integrations/peft.py:401\u001b[0m, in \u001b[0;36mPeftAdapterMixin.active_adapter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactive_adapter\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    397\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `active_adapter` method is deprecated and will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/lmms-finetune/lib/python3.10/site-packages/transformers/integrations/peft.py:391\u001b[0m, in \u001b[0;36mPeftAdapterMixin.active_adapters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# For previous PEFT versions\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mactive_adapters\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    392\u001b[0m     active_adapters \u001b[38;5;241m=\u001b[39m [active_adapters]\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m active_adapters\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'active_adapters' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model_save_path = \"/hpi/fs00/scratch/liudvikas.zekas/checkpoints/new_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "processor.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37166247-c9d1-4f02-9c8e-46a9b546a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlavaForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a040f6-24dc-48fd-8790-083dd24d1622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
